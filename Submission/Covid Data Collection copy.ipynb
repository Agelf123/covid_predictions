{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import geopandas\n",
    "import operator\n",
    "from prettytable import PrettyTable\n",
    "import time\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv'\n",
    "covid_county = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are pulling in data from usafactsstatic.com, that gives us information on how many covid cases each county had per day starting in late February. This data is updated daily but for the purpouses of this project, we collected data until May, 8th. Some of the issues with this dataset could be that for each state there are some cases that are unallocated to a county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = covid_county# rename dataframe to df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_county = df.drop(df[(df['County Name'] == 'Statewide Unallocated')].index)# drop unallocated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_county['total_covid']  = df['5/8/20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(covid_county,columns = ['County Name','State','total_covid','countyFIPS'])\n",
    "#segment the data into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We segmented the data and only kept these the columns with countyname, state, all the covid cases in each county until May 8th and the county fips. This is a unique federal id given to each county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips = pd.read_csv('../../data/uszips.csv')# import zip code data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe has zip codes for every county in the U.S. That we can merge the hospital data with the zip codes and get the proper county for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals = pd.read_csv('../../data/Hospitals.csv')\n",
    "hospitals.columns = hospitals.columns.str.replace('ZIP','zip')# replace the name of the zip column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe, has every hospital in the U.S by county. We can add them to our dataframe and get a better sense of health resources for each county in the U.S.A This will help ful in understanding how counties can deal with a covid outbreak and a natural disastor at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = pd.merge(hospitals,zips,on='zip')\n",
    "med.columns = med.columns.str.replace('county_name','County')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merged these dataframes on the zip code  column and created one dataframe that has both zip code and county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "med['County'] = [i + \" \" + \"County\" for i in med['County']]# add the word county to the county list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryehgelfand/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/aryehgelfand/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "parishes = med.loc[med['STATE'] == 'LA']\n",
    "parishes['County'] = parishes['County'] + ' Parish'# for counties in Lousiana we need we need to add parish instead of County\n",
    "parishes['STATE'] = 'LA'\n",
    "(med.loc[med['STATE'] == 'LA']) = parishes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add the word parish to the counties in Louisiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_beds = med.groupby('County')['BEDS'].sum()# add up all the hospital beds in each county\n",
    "med_hospitals = (med.groupby('County')['NAME']).value_counts().groupby('County').sum()#add up all the # hospitals in each county \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created new columns with the number of beds and hospitals in each county, that way we can use this data in our predictive model. This will help us measure the potential impact of covid-19 and a simulatanous natural disastor on health resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = pd.read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imported covid data by county including cases and deaths per county for every county in the U.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties.drop(columns=['date'],inplace=True)#drop the date column, this the date the data was gathered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties.columns = counties.columns.str.replace('county','County Name')# replace county name to conform to our hospital dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_counties_cases = counties.groupby('County Name')['cases'].sum()# add up all cases for each county\n",
    "grouped_counties_deaths = counties.groupby('County Name')['deaths'].sum()# add all deaths for every county"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added up all deaths for every county and cases for county by grouping our dataframe by county and then adding up all deaths and cases for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_cases = pd.merge(grouped_counties_cases,grouped_counties_deaths,on='County Name')# merge county and cases on County name\n",
    "df = pd.merge(df,county_cases,left_on='County Name',right_on = 'County Name',how='left')# merge the original dataframe with the combined cases and deaths dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added the county cases and deaths to the dataframe that had hospital data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "df.columns = df.columns.str.replace('County Name','County')# conformed the county column to the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df,med_beds,left_on='County',right_on = 'County',how='left')# merge the amount of beds per county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df,med_hospitals,left_on='County',right_on = 'County',how='left')# merge the amount of hospitals per county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace('NAME','# hospitals')# change the name of this column to a more descriptive name\n",
    "df.columns = df.columns.str.replace('BEDS','hospital_beds')# change the name of the beds column to a more descriptive name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataframe with covid data, hospitals, # of beds per county that we can input into our predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: column count mismatch (153 + 895 != 7147)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "health_workers = pd.read_sas('/Users/aryehgelfand/Downloads/AHRF_2018-2019_SAS/ahrf2019.sas7bdat',encoding = \"ISO-8859-1\") # imported healthcare resurces data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imported a dataset that has healthcare resources and demographic informations and we can use this to predict whether a county is a likely hotspot for covid-19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_csv('../../data/health_resource.csv')# imported codes for understanding data columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imported a dataset that has codes that explain each dataset. That way, we can use each column to interpret our health resource data and understand what each column is saying without having to lookup each code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIELD</th>\n",
       "      <th>YEAR OF DATA</th>\n",
       "      <th>VARIABLE NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F00001</td>\n",
       "      <td></td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F00002</td>\n",
       "      <td></td>\n",
       "      <td>Header - FIPS St &amp; Cty Code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F00003</td>\n",
       "      <td></td>\n",
       "      <td>Entity of File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F00004</td>\n",
       "      <td></td>\n",
       "      <td>Secondary Entity Of File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F00005</td>\n",
       "      <td></td>\n",
       "      <td>Date of File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>F15338-09</td>\n",
       "      <td>2009</td>\n",
       "      <td>Days w/8-hr Avg Ozone ovr NAAQS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8002</th>\n",
       "      <td>F15338-08</td>\n",
       "      <td>2008</td>\n",
       "      <td>Days w/8-hr Avg Ozone ovr NAAQS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8003</th>\n",
       "      <td>F15338-07</td>\n",
       "      <td>2007</td>\n",
       "      <td>Days w/8-hr Avg Ozone ovr NAAQS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8004</th>\n",
       "      <td>F15338-06</td>\n",
       "      <td>2006</td>\n",
       "      <td>Days w/8-hr Avg Ozone ovr NAAQS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8005</th>\n",
       "      <td>F00811-76</td>\n",
       "      <td>1976</td>\n",
       "      <td>Elevation Feet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7315 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FIELD YEAR OF DATA                     VARIABLE NAME\n",
       "1      F00001                    Blank                          \n",
       "2      F00002                    Header - FIPS St & Cty Code    \n",
       "3      F00003                    Entity of File                 \n",
       "4      F00004                    Secondary Entity Of File       \n",
       "5      F00005                    Date of File                   \n",
       "...           ...          ...                               ...\n",
       "8001   F15338-09          2009   Days w/8-hr Avg Ozone ovr NAAQS\n",
       "8002   F15338-08          2008   Days w/8-hr Avg Ozone ovr NAAQS\n",
       "8003   F15338-07          2007   Days w/8-hr Avg Ozone ovr NAAQS\n",
       "8004   F15338-06          2006   Days w/8-hr Avg Ozone ovr NAAQS\n",
       "8005   F00811-76          1976   Elevation Feet                 \n",
       "\n",
       "[7315 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.dropna(inplace=True)\n",
    "codes.drop(columns=['COL-COL'])# drop col-col column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes['FIELD'] = codes['FIELD'].str.replace('F','f')# conform codes df to healthcare df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_dict_keys = {i.strip() for i in codes['FIELD']}# strip white space\n",
    "codes_dict_values = {i.strip() for i in codes['VARIABLE NAME']}# strip white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_dict = dict(zip(codes_dict_keys,codes_dict_values))# put codes in a dictionary\n",
    "codes_dict_keys = {key.replace('-',''): key for key in codes_dict.keys()}# take out dash\n",
    "codes_dict = dict(zip(codes_dict_keys,codes_dict_values))# put codes and meaning into a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_workers.columns = health_workers.columns.map(codes_dict)# convert healthcare codes to their meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our healthcare resources data has the columns as labels instead of a code that we would have had to lookup each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_workers.columns.values[8] = \"State\"# rename the eight column with state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_workers.columns.values[9] = \"County\"# rename county colum with county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_workers =  health_workers.loc[:, health_workers.columns.notnull()]# take out columns that are empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a huge datframe with over 2k pieces of health data about each county and we have each column correctly labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df,health_workers,left_on='County',right_on = 'County',how='left')# merge it onto our original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0,inplace=True)# fill null with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)# drop duplicates from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(\"State_x\",'State')# make sure that state columns is correectly labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(df.loc[df['State'] == 'AK'].index, inplace=True)\n",
    "df.drop(df.loc[df['State'] == 'HI'].index, inplace=True)\n",
    "df.drop(df.loc[df['State'] == 'PR'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='County Name',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataframe without counties outside the contigous U.S and without dupicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryehgelfand/opt/anaconda3/lib/python3.7/site-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[:, ~df.columns.str.contains('Pop')]# taking columns that have the word pop in it.\n",
    "df = df.loc[:, ~df.columns.str.contains('ins')]# taking columns that have the word ins in it.\n",
    "df = df.loc[:, ~df.columns.str.contains('Pers')]# taking columns that have the word pers in it.\n",
    "df = df.loc[:, ~df.columns.str.contains('Persons')]# taking columns that have the word persons in it.\n",
    "df = df.loc[:, ~df.columns.str.contains('Hsehlds')]\n",
    "df = df.loc[:, ~df.columns.str.contains('persons')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Pov')]\n",
    "df = df.loc[:, ~df.columns.str.contains('families')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Division')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Stat')]\n",
    "df = df.loc[:, ~df.columns.str.contains('HPSA')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Contiguous')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Family')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Lab')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Housing')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Salaried')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Code')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Workers')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Financial')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Unemployed')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Births')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Poverty')]\n",
    "df = df.loc[:, ~df.columns.str.contains('HlthIns')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Units')]\n",
    "df = df.loc[:, ~df.columns.str.contains('w/HlthIns')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Medicaid')]\n",
    "df = df.loc[:, ~df.columns.str.contains('5-Yr')]\n",
    "df = df.loc[:, ~df.columns.str.contains('3-Yr')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Hispanic/Lat')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Non-Hisp')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Ins')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Families')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Hispanic')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Asian')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Households')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Race')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Workers')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Wrkrs')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Hispanic/Latino')]\n",
    "df = df.loc[:, ~df.columns.str.contains('White')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Labor')]\n",
    "df = df.loc[:, ~df.columns.str.contains('HHld')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Labor')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Rce')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Hsp/Lat')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Units')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Age')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Insurance')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Parent')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Income')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Births')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Black/Afican')]\n",
    "df = df.loc[:, ~df.columns.str.contains('American')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Ratio')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Air')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Median')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Hsp')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Txc')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Coll-Hisp/Lat')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Land')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Expenses')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Hhlds')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Unspecified')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Yrs')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Accreditation')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Administration')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Inc')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Percent')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Employed')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Number')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Civilian')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Enrollees')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Costs')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Based')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Expenses')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Payroll')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Area')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Divorced')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Administrat')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Cst')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Recipients')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Work')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Marketplc')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Expenditure(1000\\'\\s)')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Research')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Teaching')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Trainees')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Resident')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Residents')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Date')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Emission')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Graduates')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Beneficiaries')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Unemployment')]\n",
    "df = df.loc[:, ~df.columns.str.contains('Diploma')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our over 2k columns have too much info\n",
    "rmation because we also have census information that we have collected, so we need to remove any columns that relate to demographic information. By, going through the column names, I was able to take out columns that contained certain words and avoid having duplicate information in our dataset. This got our column names down to under 1k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_final = df[['County','total_covid','countyFIPS','cases','deaths','hospital_beds','# hospitals']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to segment our data even further by only keeping columns that have a specific medical resource in them and futher get the amout of columns down from 1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df.loc[:, df.columns.str.contains('Total')]# get columns that have th total\n",
    "beds = df.loc[:, df.columns.str.contains('Beds')]# get the amount of beds columns\n",
    "MD = df.loc[:, df.columns.str.contains('M.D')]# get the amount of M.D related columns\n",
    "hos =  df.loc[:, df.columns.str.contains('Hosp')]\n",
    "PA = df.loc[:, df.columns.str.contains('Physician Assistants')]\n",
    "nurses = df.loc[:, df.columns.str.contains('Nurses')]\n",
    "nurse = df.loc[:, df.columns.str.contains('Nurse')]\n",
    "DO = df.loc[:, df.columns.str.contains('DO')]\n",
    "surgery = df.loc[:, df.columns.str.contains('Surgery')]\n",
    "rt = df.loc[:, df.columns.str.contains('Respiratory Therapists')]\n",
    "psych = df.loc[:, df.columns.str.contains('Psychiatry')]\n",
    "nur = df.loc[:, df.columns.str.contains('Nurs')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to merge these segmented columns with the final one and get only thes important 600 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = health_final.merge(\n",
    "        total, how=\"left\", left_index=True, right_index=True# merge each of these segmented columns onto each other\n",
    "    )\n",
    "df2 = df1.merge(\n",
    "        beds, how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "df3 = df2.merge(\n",
    "        MD, how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "df4 = df3.merge(\n",
    "        hos, how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "df5 = df4.merge(\n",
    "        PA, how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "df6 = df5.merge(\n",
    "        nurses, how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "df7= df6.merge(\n",
    "        nurse, how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "df8= df7.merge(\n",
    "        DO, how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "df9= df8.merge(\n",
    "        surgery, how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "df10= df9.merge(\n",
    "        rt, how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "df11= df10.merge(\n",
    "        psych, how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "df13= df11.merge(\n",
    "        nur, how=\"left\", left_index=True, right_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryehgelfand/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:4494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "health_final = df13# make this merged column with only these segmented columns and our original data related to covid\n",
    "\n",
    "health_final.drop_duplicates(inplace=True)\n",
    "\n",
    "health_final.fillna(0,inplace=True)\n",
    "\n",
    "health_final = health_final.loc[:,~health_final.columns.duplicated()]\n",
    "\n",
    "health_final['County'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up with a column with all of our desired data only about 640 features. We know that these relate only to specific medical resources or covid related data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#health_final.to_csv('health_resources.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
