{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our client wants to try to predict COVID-19 hotspots based on demographics and has asked us to build a predictive model that could predict if a county is a COVID-19 hotspot.  Since we are cautious about trying to predict an ongoing problem with many changes in real-time data, we informed that if our models don't meet a __.95 accuracy score or better__ that they should only use the model for interpretive purposes and not predictive purposes.  While the client understands the low likelihood of building a predictive model under this criteria, they gave us the budget to proceed anyway.\n",
    "\n",
    "We defined a \"COVID-19 hotspot\" as a county in the contiguous US that has a rate of infected residents per capita that is higher than one standard deviation for the mean.  This actually presents an interesting situation where we already know that our baseline model will have an accuracy rate of .7625.  Due to this, we will only consider our model interpretable if we can beat the baseline accuracy.\n",
    "\n",
    "We are viewing this as a classification problem and will look to run Logistic Regression, KNN, Support Vector Machine, Decision Tree Classifier, Bagging Classifier,Random Forest, and AdaBoost models in order to see if it's possible to predict COVID-19 hotspots based on county demographic data.\n",
    "\n",
    "To reiterate, our goal for the model to be considered predictive is a __.95 accuracy score or better__, and our goal for the model to be considered interpretable is a __.7626 accuracy score or better__.  This is to ensure that we are held to high standards when it comes to predicting an ongoing pandemic, but also ensures that we can interpret the findings if we are performing better than average.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.base import TransformerMixin # from Mahdi\n",
    "\n",
    "import regex as re\n",
    "\n",
    "random_state = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data was pulled on May 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv('~/downloads/new_beds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Master was the result of all of our cleaned dataframes merged into one, however we found some more specific area data after the fact, which is why we read in a separate dataframe.  We will have to do a little more cleaning, but master will remain as our Master dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "area = pd.read_csv('~/downloads/area_ready.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>total_area</th>\n",
       "      <th>land_area</th>\n",
       "      <th>water_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autauga county</td>\n",
       "      <td>1513895194</td>\n",
       "      <td>1539602155</td>\n",
       "      <td>2.570696e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baldwin county</td>\n",
       "      <td>2984648805</td>\n",
       "      <td>4117625664</td>\n",
       "      <td>1.132977e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barbour county</td>\n",
       "      <td>2241636927</td>\n",
       "      <td>2292160140</td>\n",
       "      <td>5.052321e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bibb county</td>\n",
       "      <td>1602558222</td>\n",
       "      <td>1612159622</td>\n",
       "      <td>9.601400e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blount county</td>\n",
       "      <td>1655136409</td>\n",
       "      <td>1670127873</td>\n",
       "      <td>1.499146e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           county  total_area   land_area    water_area\n",
       "0  autauga county  1513895194  1539602155  2.570696e+07\n",
       "1  baldwin county  2984648805  4117625664  1.132977e+09\n",
       "2  barbour county  2241636927  2292160140  5.052321e+07\n",
       "3     bibb county  1602558222  1612159622  9.601400e+06\n",
       "4   blount county  1655136409  1670127873  1.499146e+07"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area = area.drop(columns = 'Unnamed: 0')\n",
    "# csv was created without index = False, so have to drop the first column\n",
    "area.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are still treated our master as the master, first, we're going to merge area and master and save over the master dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>county</th>\n",
       "      <th>total_area</th>\n",
       "      <th>land_area</th>\n",
       "      <th>water_area</th>\n",
       "      <th>county_x</th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>population</th>\n",
       "      <th>estimate!!race!!total population!!one race</th>\n",
       "      <th>...</th>\n",
       "      <th>cert nurse midwvs,ft oth emptyp_y</th>\n",
       "      <th>nursing facilities total beds</th>\n",
       "      <th>nurse practitioners_y</th>\n",
       "      <th>advpractnurs midwve,male w/npi</th>\n",
       "      <th>st_num</th>\n",
       "      <th>countyfips</th>\n",
       "      <th>beds</th>\n",
       "      <th>case_per_pop</th>\n",
       "      <th>beds_per_pop</th>\n",
       "      <th>beds_per_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>autauga county</td>\n",
       "      <td>1513895194</td>\n",
       "      <td>1539602155</td>\n",
       "      <td>2.570696e+07</td>\n",
       "      <td>autauga county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>55200</td>\n",
       "      <td>54170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>1.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>baldwin county</td>\n",
       "      <td>2984648805</td>\n",
       "      <td>4117625664</td>\n",
       "      <td>1.132977e+09</td>\n",
       "      <td>baldwin county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1003</td>\n",
       "      <td>208107</td>\n",
       "      <td>204535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>1.855769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>barbour county</td>\n",
       "      <td>2241636927</td>\n",
       "      <td>2292160140</td>\n",
       "      <td>5.052321e+07</td>\n",
       "      <td>barbour county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1005</td>\n",
       "      <td>25782</td>\n",
       "      <td>25429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1005</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>1.396226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bibb county</td>\n",
       "      <td>1602558222</td>\n",
       "      <td>1612159622</td>\n",
       "      <td>9.601400e+06</td>\n",
       "      <td>bibb county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1007</td>\n",
       "      <td>22527</td>\n",
       "      <td>22340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1007</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.795455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>blount county</td>\n",
       "      <td>1655136409</td>\n",
       "      <td>1670127873</td>\n",
       "      <td>1.499146e+07</td>\n",
       "      <td>blount county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1009</td>\n",
       "      <td>57645</td>\n",
       "      <td>56710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1009</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.568182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 853 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   key_0          county  total_area   land_area    water_area  \\\n",
       "0      0  autauga county  1513895194  1539602155  2.570696e+07   \n",
       "1      1  baldwin county  2984648805  4117625664  1.132977e+09   \n",
       "2      2  barbour county  2241636927  2292160140  5.052321e+07   \n",
       "3      3     bibb county  1602558222  1612159622  9.601400e+06   \n",
       "4      4   blount county  1655136409  1670127873  1.499146e+07   \n",
       "\n",
       "         county_x state    id  population  \\\n",
       "0  autauga county    AL  1001       55200   \n",
       "1  baldwin county    AL  1003      208107   \n",
       "2  barbour county    AL  1005       25782   \n",
       "3     bibb county    AL  1007       22527   \n",
       "4   blount county    AL  1009       57645   \n",
       "\n",
       "   estimate!!race!!total population!!one race  ...  \\\n",
       "0                                       54170  ...   \n",
       "1                                      204535  ...   \n",
       "2                                       25429  ...   \n",
       "3                                       22340  ...   \n",
       "4                                       56710  ...   \n",
       "\n",
       "   cert nurse midwvs,ft oth emptyp_y  nursing facilities total beds  \\\n",
       "0                                0.0                            0.0   \n",
       "1                                0.0                            0.0   \n",
       "2                                0.0                            0.0   \n",
       "3                                0.0                            0.0   \n",
       "4                                0.0                            0.0   \n",
       "\n",
       "   nurse practitioners_y  advpractnurs midwve,male w/npi  st_num  countyfips  \\\n",
       "0                    0.0                             0.0       1        1001   \n",
       "1                    0.0                             0.0       1        1003   \n",
       "2                    0.0                             0.0       1        1005   \n",
       "3                    0.0                             0.0       1        1007   \n",
       "4                    0.0                             0.0       1        1009   \n",
       "\n",
       "    beds  case_per_pop  beds_per_pop  beds_per_case  \n",
       "0   85.0      0.001214      0.001540       1.268657  \n",
       "1  386.0      0.000999      0.001855       1.855769  \n",
       "2   74.0      0.002056      0.002870       1.396226  \n",
       "3   35.0      0.001953      0.001554       0.795455  \n",
       "4   25.0      0.000763      0.000434       0.568182  \n",
       "\n",
       "[5 rows x 853 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master = pd.merge(area, master, how = 'left', on=area.index)\n",
    "\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we've cleaned, we still want to check our null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key_0                                  0\n",
       "# hosp w/diag radioisotope fac         0\n",
       "other spec, tot, pc, hosp res          0\n",
       "forensic path, pc, hosp ft stf         0\n",
       "# stng/lt hosps,100-199 beds_y         0\n",
       "                                    ... \n",
       "skilled nurs fac certified beds_x      0\n",
       "# stng/lt hosps,050-099 beds_x         0\n",
       "nursing home beds, st gen hosp_x       0\n",
       "water_area                             1\n",
       "beds_per_case                        103\n",
       "Length: 853, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to end up dropping beds per case when we set up our X & y variables because that would be technically leaking coronavirus data into our model, but for EDA purposes, it could be worth keeping around.  I'm more concerned investigating the water area null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>county</th>\n",
       "      <th>total_area</th>\n",
       "      <th>land_area</th>\n",
       "      <th>water_area</th>\n",
       "      <th>county_x</th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>population</th>\n",
       "      <th>estimate!!race!!total population!!one race</th>\n",
       "      <th>...</th>\n",
       "      <th>cert nurse midwvs,ft oth emptyp_y</th>\n",
       "      <th>nursing facilities total beds</th>\n",
       "      <th>nurse practitioners_y</th>\n",
       "      <th>advpractnurs midwve,male w/npi</th>\n",
       "      <th>st_num</th>\n",
       "      <th>countyfips</th>\n",
       "      <th>beds</th>\n",
       "      <th>case_per_pop</th>\n",
       "      <th>beds_per_pop</th>\n",
       "      <th>beds_per_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>greeley county</td>\n",
       "      <td>2016057907</td>\n",
       "      <td>2016057907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greeley county</td>\n",
       "      <td>KS</td>\n",
       "      <td>20071</td>\n",
       "      <td>1200</td>\n",
       "      <td>1179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20071</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 853 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     key_0          county  total_area   land_area  water_area  \\\n",
       "889    889  greeley county  2016057907  2016057907         NaN   \n",
       "\n",
       "           county_x state     id  population  \\\n",
       "889  greeley county    KS  20071        1200   \n",
       "\n",
       "     estimate!!race!!total population!!one race  ...  \\\n",
       "889                                        1179  ...   \n",
       "\n",
       "     cert nurse midwvs,ft oth emptyp_y  nursing facilities total beds  \\\n",
       "889                                0.0                            0.0   \n",
       "\n",
       "     nurse practitioners_y  advpractnurs midwve,male w/npi  st_num  \\\n",
       "889                    0.0                             0.0      20   \n",
       "\n",
       "     countyfips  beds  case_per_pop  beds_per_pop  beds_per_case  \n",
       "889       20071  18.0           0.0         0.015            inf  \n",
       "\n",
       "[1 rows x 853 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.loc[master['water_area'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>county</th>\n",
       "      <th>total_area</th>\n",
       "      <th>land_area</th>\n",
       "      <th>water_area</th>\n",
       "      <th>county_x</th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>population</th>\n",
       "      <th>estimate!!race!!total population!!one race</th>\n",
       "      <th>...</th>\n",
       "      <th>cert nurse midwvs,ft oth emptyp_y</th>\n",
       "      <th>nursing facilities total beds</th>\n",
       "      <th>nurse practitioners_y</th>\n",
       "      <th>advpractnurs midwve,male w/npi</th>\n",
       "      <th>st_num</th>\n",
       "      <th>countyfips</th>\n",
       "      <th>beds</th>\n",
       "      <th>case_per_pop</th>\n",
       "      <th>beds_per_pop</th>\n",
       "      <th>beds_per_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>2478</td>\n",
       "      <td>trousdale county</td>\n",
       "      <td>290182875</td>\n",
       "      <td>296143584</td>\n",
       "      <td>5960709.0</td>\n",
       "      <td>trousdale county</td>\n",
       "      <td>TN</td>\n",
       "      <td>47169</td>\n",
       "      <td>9573</td>\n",
       "      <td>9105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>47169</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.141544</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.018450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>lincoln county</td>\n",
       "      <td>1426848085</td>\n",
       "      <td>1454363491</td>\n",
       "      <td>27515406.0</td>\n",
       "      <td>lincoln county</td>\n",
       "      <td>AR</td>\n",
       "      <td>5079</td>\n",
       "      <td>13695</td>\n",
       "      <td>13622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>1794</td>\n",
       "      <td>dakota county</td>\n",
       "      <td>1327294423</td>\n",
       "      <td>1354269882</td>\n",
       "      <td>26975459.0</td>\n",
       "      <td>dakota county</td>\n",
       "      <td>NE</td>\n",
       "      <td>31043</td>\n",
       "      <td>20317</td>\n",
       "      <td>19820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>31043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>1332</td>\n",
       "      <td>nobles county</td>\n",
       "      <td>1832764854</td>\n",
       "      <td>1852080823</td>\n",
       "      <td>19315969.0</td>\n",
       "      <td>nobles county</td>\n",
       "      <td>MN</td>\n",
       "      <td>27105</td>\n",
       "      <td>21839</td>\n",
       "      <td>21450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>27105</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.053894</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.040782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>2397</td>\n",
       "      <td>bledsoe county</td>\n",
       "      <td>1051815457</td>\n",
       "      <td>1052644801</td>\n",
       "      <td>829344.0</td>\n",
       "      <td>bledsoe county</td>\n",
       "      <td>TN</td>\n",
       "      <td>47007</td>\n",
       "      <td>14602</td>\n",
       "      <td>14198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>47007</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.041364</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.041391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>2701</td>\n",
       "      <td>somervell county</td>\n",
       "      <td>468738044</td>\n",
       "      <td>482948955</td>\n",
       "      <td>14210911.0</td>\n",
       "      <td>somervell county</td>\n",
       "      <td>TX</td>\n",
       "      <td>48425</td>\n",
       "      <td>8743</td>\n",
       "      <td>8684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>48425</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>modoc county</td>\n",
       "      <td>9565374364</td>\n",
       "      <td>10225877677</td>\n",
       "      <td>660503313.0</td>\n",
       "      <td>modoc county</td>\n",
       "      <td>CA</td>\n",
       "      <td>6049</td>\n",
       "      <td>8938</td>\n",
       "      <td>8691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6049</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>2695</td>\n",
       "      <td>schleicher county</td>\n",
       "      <td>3394458666</td>\n",
       "      <td>3394546067</td>\n",
       "      <td>87401.0</td>\n",
       "      <td>schleicher county</td>\n",
       "      <td>TX</td>\n",
       "      <td>48413</td>\n",
       "      <td>3061</td>\n",
       "      <td>3060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>48413</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>2694</td>\n",
       "      <td>san saba county</td>\n",
       "      <td>2932146951</td>\n",
       "      <td>2940447162</td>\n",
       "      <td>8300211.0</td>\n",
       "      <td>san saba county</td>\n",
       "      <td>TX</td>\n",
       "      <td>48411</td>\n",
       "      <td>5962</td>\n",
       "      <td>5695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>48411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>3107</td>\n",
       "      <td>weston county</td>\n",
       "      <td>6205578618</td>\n",
       "      <td>6210804117</td>\n",
       "      <td>5225499.0</td>\n",
       "      <td>weston county</td>\n",
       "      <td>WY</td>\n",
       "      <td>56045</td>\n",
       "      <td>7100</td>\n",
       "      <td>6956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>56045</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3108 rows × 853 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_0             county  total_area    land_area   water_area  \\\n",
       "2478   2478   trousdale county   290182875    296143584    5960709.0   \n",
       "106     106     lincoln county  1426848085   1454363491   27515406.0   \n",
       "1794   1794      dakota county  1327294423   1354269882   26975459.0   \n",
       "1332   1332      nobles county  1832764854   1852080823   19315969.0   \n",
       "2397   2397     bledsoe county  1051815457   1052644801     829344.0   \n",
       "...     ...                ...         ...          ...          ...   \n",
       "2701   2701   somervell county   468738044    482948955   14210911.0   \n",
       "181     181       modoc county  9565374364  10225877677  660503313.0   \n",
       "2695   2695  schleicher county  3394458666   3394546067      87401.0   \n",
       "2694   2694    san saba county  2932146951   2940447162    8300211.0   \n",
       "3107   3107      weston county  6205578618   6210804117    5225499.0   \n",
       "\n",
       "               county_x state     id  population  \\\n",
       "2478   trousdale county    TN  47169        9573   \n",
       "106      lincoln county    AR   5079       13695   \n",
       "1794      dakota county    NE  31043       20317   \n",
       "1332      nobles county    MN  27105       21839   \n",
       "2397     bledsoe county    TN  47007       14602   \n",
       "...                 ...   ...    ...         ...   \n",
       "2701   somervell county    TX  48425        8743   \n",
       "181        modoc county    CA   6049        8938   \n",
       "2695  schleicher county    TX  48413        3061   \n",
       "2694    san saba county    TX  48411        5962   \n",
       "3107      weston county    WY  56045        7100   \n",
       "\n",
       "      estimate!!race!!total population!!one race  ...  \\\n",
       "2478                                        9105  ...   \n",
       "106                                        13622  ...   \n",
       "1794                                       19820  ...   \n",
       "1332                                       21450  ...   \n",
       "2397                                       14198  ...   \n",
       "...                                          ...  ...   \n",
       "2701                                        8684  ...   \n",
       "181                                         8691  ...   \n",
       "2695                                        3060  ...   \n",
       "2694                                        5695  ...   \n",
       "3107                                        6956  ...   \n",
       "\n",
       "      cert nurse midwvs,ft oth emptyp_y  nursing facilities total beds  \\\n",
       "2478                                0.0                            0.0   \n",
       "106                                 0.0                            0.0   \n",
       "1794                                0.0                            0.0   \n",
       "1332                                0.0                            0.0   \n",
       "2397                                0.0                            0.0   \n",
       "...                                 ...                            ...   \n",
       "2701                                0.0                            0.0   \n",
       "181                                 0.0                            0.0   \n",
       "2695                                0.0                            0.0   \n",
       "2694                                0.0                            0.0   \n",
       "3107                                0.0                            0.0   \n",
       "\n",
       "      nurse practitioners_y  advpractnurs midwve,male w/npi  st_num  \\\n",
       "2478                    0.0                             0.0      47   \n",
       "106                     0.0                             0.0       5   \n",
       "1794                    0.0                             0.0      31   \n",
       "1332                    0.0                             0.0      27   \n",
       "2397                    0.0                             0.0      47   \n",
       "...                     ...                             ...     ...   \n",
       "2701                    0.0                             0.0      48   \n",
       "181                     0.0                             0.0       6   \n",
       "2695                    0.0                             0.0      48   \n",
       "2694                    0.0                             0.0      48   \n",
       "3107                    0.0                             0.0      56   \n",
       "\n",
       "      countyfips  beds  case_per_pop  beds_per_pop  beds_per_case  \n",
       "2478       47169  25.0      0.141544      0.002612       0.018450  \n",
       "106         5079   0.0      0.066229      0.000000       0.000000  \n",
       "1794       31043   0.0      0.065118      0.000000       0.000000  \n",
       "1332       27105  48.0      0.053894      0.002198       0.040782  \n",
       "2397       47007  25.0      0.041364      0.001712       0.041391  \n",
       "...          ...   ...           ...           ...            ...  \n",
       "2701       48425  16.0      0.000000      0.001830            inf  \n",
       "181         6049  20.0      0.000000      0.002238            inf  \n",
       "2695       48413  14.0      0.000000      0.004574            inf  \n",
       "2694       48411   0.0      0.000000      0.000000            NaN  \n",
       "3107       56045  12.0      0.000000      0.001690            inf  \n",
       "\n",
       "[3108 rows x 853 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.sort_values(by = 'case_per_pop', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since total area for Greeley County equals land area, I'm going to impute 0 for water area in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['water_area'].replace({None: 0}, inplace = True)\n",
    "\n",
    "master['pop_density'] = master['population'] / master['total_area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The census data we collected is in total units, but we want to see if ratios might be a better predictor of hotspots than a total.  We do want to be able to feed both into our model.  To get started, we feature engineered a column for population density.  Next we want to create a for loop to loop through the all data columns and create ratios with the population as a denominator for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3108, 845)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cens = master[master.columns[8:]]\n",
    "cens.drop(columns = 'county_y', inplace = True) #ran code to find this as the only object column\n",
    "cens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obviously have a lot of columns, which will possibly lead to some overfit models.  We can address this in the modeling section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race ratio</th>\n",
       "      <th>estimate!!race!!total population!!two or more races ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race.1 ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race!!white ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race!!black or african american ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native!!cherokee tribal grouping ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native!!chippewa tribal grouping ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native!!navajo tribal grouping ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>nursing facilities total beds ratio</th>\n",
       "      <th>nurse practitioners_y ratio</th>\n",
       "      <th>advpractnurs midwve,male w/npi ratio</th>\n",
       "      <th>st_num ratio</th>\n",
       "      <th>countyfips ratio</th>\n",
       "      <th>beds ratio</th>\n",
       "      <th>case_per_pop ratio</th>\n",
       "      <th>beds_per_pop ratio</th>\n",
       "      <th>beds_per_case ratio</th>\n",
       "      <th>pop_density ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981341</td>\n",
       "      <td>0.018659</td>\n",
       "      <td>0.981341</td>\n",
       "      <td>0.768786</td>\n",
       "      <td>0.191395</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>2.198855e-08</td>\n",
       "      <td>2.789593e-08</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6.605477e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982836</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.982836</td>\n",
       "      <td>0.862662</td>\n",
       "      <td>0.094970</td>\n",
       "      <td>0.007314</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>4.802750e-09</td>\n",
       "      <td>8.912795e-09</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.350478e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986308</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.986308</td>\n",
       "      <td>0.473819</td>\n",
       "      <td>0.475758</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.038981</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>7.973384e-08</td>\n",
       "      <td>1.113265e-07</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>4.461026e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991699</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.991699</td>\n",
       "      <td>0.766547</td>\n",
       "      <td>0.222755</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.044702</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>8.670536e-08</td>\n",
       "      <td>6.897017e-08</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>6.240023e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983780</td>\n",
       "      <td>0.016220</td>\n",
       "      <td>0.983780</td>\n",
       "      <td>0.955052</td>\n",
       "      <td>0.014954</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.017504</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.324126e-08</td>\n",
       "      <td>7.523445e-09</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>6.041798e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 845 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population ratio  estimate!!race!!total population!!one race ratio  \\\n",
       "0               1.0                                          0.981341   \n",
       "1               1.0                                          0.982836   \n",
       "2               1.0                                          0.986308   \n",
       "3               1.0                                          0.991699   \n",
       "4               1.0                                          0.983780   \n",
       "\n",
       "   estimate!!race!!total population!!two or more races ratio  \\\n",
       "0                                           0.018659           \n",
       "1                                           0.017164           \n",
       "2                                           0.013692           \n",
       "3                                           0.008301           \n",
       "4                                           0.016220           \n",
       "\n",
       "   estimate!!race!!total population!!one race.1 ratio  \\\n",
       "0                                           0.981341    \n",
       "1                                           0.982836    \n",
       "2                                           0.986308    \n",
       "3                                           0.991699    \n",
       "4                                           0.983780    \n",
       "\n",
       "   estimate!!race!!total population!!one race!!white ratio  \\\n",
       "0                                           0.768786         \n",
       "1                                           0.862662         \n",
       "2                                           0.473819         \n",
       "3                                           0.766547         \n",
       "4                                           0.955052         \n",
       "\n",
       "   estimate!!race!!total population!!one race!!black or african american ratio  \\\n",
       "0                                           0.191395                             \n",
       "1                                           0.094970                             \n",
       "2                                           0.475758                             \n",
       "3                                           0.222755                             \n",
       "4                                           0.014954                             \n",
       "\n",
       "   estimate!!race!!total population!!one race!!american indian and alaska native ratio  \\\n",
       "0                                           0.002880                                     \n",
       "1                                           0.007314                                     \n",
       "2                                           0.002793                                     \n",
       "3                                           0.000355                                     \n",
       "4                                           0.002446                                     \n",
       "\n",
       "   estimate!!race!!total population!!one race!!american indian and alaska native!!cherokee tribal grouping ratio  \\\n",
       "0                                           0.001486                                                               \n",
       "1                                           0.001369                                                               \n",
       "2                                           0.001008                                                               \n",
       "3                                           0.000000                                                               \n",
       "4                                           0.000347                                                               \n",
       "\n",
       "   estimate!!race!!total population!!one race!!american indian and alaska native!!chippewa tribal grouping ratio  \\\n",
       "0                                                0.0                                                               \n",
       "1                                                0.0                                                               \n",
       "2                                                0.0                                                               \n",
       "3                                                0.0                                                               \n",
       "4                                                0.0                                                               \n",
       "\n",
       "   estimate!!race!!total population!!one race!!american indian and alaska native!!navajo tribal grouping ratio  \\\n",
       "0                                           0.000797                                                             \n",
       "1                                           0.000336                                                             \n",
       "2                                           0.000349                                                             \n",
       "3                                           0.000000                                                             \n",
       "4                                           0.000000                                                             \n",
       "\n",
       "   ...  nursing facilities total beds ratio  nurse practitioners_y ratio  \\\n",
       "0  ...                                  0.0                          0.0   \n",
       "1  ...                                  0.0                          0.0   \n",
       "2  ...                                  0.0                          0.0   \n",
       "3  ...                                  0.0                          0.0   \n",
       "4  ...                                  0.0                          0.0   \n",
       "\n",
       "   advpractnurs midwve,male w/npi ratio  st_num ratio  countyfips ratio  \\\n",
       "0                                   0.0      0.000018          0.018134   \n",
       "1                                   0.0      0.000005          0.004820   \n",
       "2                                   0.0      0.000039          0.038981   \n",
       "3                                   0.0      0.000044          0.044702   \n",
       "4                                   0.0      0.000017          0.017504   \n",
       "\n",
       "   beds ratio  case_per_pop ratio  beds_per_pop ratio  beds_per_case ratio  \\\n",
       "0    0.001540        2.198855e-08        2.789593e-08             0.000023   \n",
       "1    0.001855        4.802750e-09        8.912795e-09             0.000009   \n",
       "2    0.002870        7.973384e-08        1.113265e-07             0.000054   \n",
       "3    0.001554        8.670536e-08        6.897017e-08             0.000035   \n",
       "4    0.000434        1.324126e-08        7.523445e-09             0.000010   \n",
       "\n",
       "   pop_density ratio  \n",
       "0       6.605477e-10  \n",
       "1       3.350478e-10  \n",
       "2       4.461026e-10  \n",
       "3       6.240023e-10  \n",
       "4       6.041798e-10  \n",
       "\n",
       "[5 rows x 845 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios = [] # instantiate empty list\n",
    "for num in range(845): #iterates through all census columns\n",
    "    ratio = cens[cens.columns[num]]/ cens['population']\n",
    "    ratios.append(ratio) \n",
    "    \n",
    "\n",
    "ratio_df = pd.DataFrame(ratios).T \n",
    "#turn list into a dataframe, need to transpose, so the values and columns line up properly\n",
    "ratio_df.columns =  cens.columns\n",
    "\n",
    "ratio_df.columns = ratio_df.columns + ' ratio'\n",
    "\n",
    "ratio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_df.to_csv('~/documents/population_ratios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master.join(ratio_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We overwrote the Master to include the ratio columns.  Data is cleaned up to where we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to see is what the distribution of our likely target (Cases per Capita)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(master['case_per_pop'], bins = 20)\n",
    "plt.title('Cases Per Capita Histogram')\n",
    "plt.xlabel('Cases Per Capita')\n",
    "plt.ylabel('Number of Counties');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable has a distribution that is right-skewed, which makes sense since you can't have a negative number with this feature.  Taking the log did not even out the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(master['beds'], master['population'])\n",
    "plt.title('Beds per Population')\n",
    "plt.xlabel('Beds')\n",
    "plt.ylabel('Population');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wanted to look for any discrepancies in the amount of hospital beds given the population of a county, but found that the relationship is fairly linear with a positive correlation.  This is not surprising because one would typically expect that areas with higher populations are more likely to have a greater number of hospital beds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(master['deaths']/master['cases'], master['beds_per_pop'])\n",
    "plt.title('Deaths/Cases Ratio vs. Beds Per Capita')\n",
    "plt.xlabel('Deaths/Cases Ratio')\n",
    "plt.ylabel('Beds Per Capita');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This finding was fascinating.  We wanted to explore the relationship between the likelihood of COVID-19 resulting in death compared to the amount of hospital beds per capita.  We do have many counties that have cases, but not any deaths, so that does technically throw off some of the linearity at this point in time. However, we do appear to see a slight negative correlation in this graph, which suggests that COVID-19 cases are more likely to become severe in counties that don't have a lot of hospital beds relative to their population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2375"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".95/2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "738.15"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape[0] * 0.2375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2369"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape[0] - 739"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This informs us on how many counties will be designated as a \"hotspot,\" as determined by counties that fall one standard deviation above the mean in terms of infections per capita.  I'm going to round up for the cutoff because the value should be larger than 738, and since you can't have .15 of a county, I will use 739 as designated hotspots.  That leaves us with 2369 that will not be considered hotspots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "above_std_1 = master.sort_values(by = 'case_per_pop', ascending = False).head(739)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a list of counties that meet our criteria of a COVID-19 hotspot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.002056\n",
       "Name: case_per_pop, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "above_std_1['case_per_pop'].sort_values().head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows our cutoff point for our cases per capita ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "below = master.sort_values(by = 'case_per_pop', ascending = False).tail(2369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>county</th>\n",
       "      <th>total_area</th>\n",
       "      <th>land_area</th>\n",
       "      <th>water_area</th>\n",
       "      <th>county_x</th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>population</th>\n",
       "      <th>estimate!!race!!total population!!one race</th>\n",
       "      <th>...</th>\n",
       "      <th>nursing facilities total beds ratio</th>\n",
       "      <th>nurse practitioners_y ratio</th>\n",
       "      <th>advpractnurs midwve,male w/npi ratio</th>\n",
       "      <th>st_num ratio</th>\n",
       "      <th>countyfips ratio</th>\n",
       "      <th>beds ratio</th>\n",
       "      <th>case_per_pop ratio</th>\n",
       "      <th>beds_per_pop ratio</th>\n",
       "      <th>beds_per_case ratio</th>\n",
       "      <th>pop_density ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>autauga county</td>\n",
       "      <td>1513895194</td>\n",
       "      <td>1539602155</td>\n",
       "      <td>2.570696e+07</td>\n",
       "      <td>autauga county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>55200</td>\n",
       "      <td>54170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>2.198855e-08</td>\n",
       "      <td>2.789593e-08</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6.605477e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>baldwin county</td>\n",
       "      <td>2984648805</td>\n",
       "      <td>4117625664</td>\n",
       "      <td>1.132977e+09</td>\n",
       "      <td>baldwin county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1003</td>\n",
       "      <td>208107</td>\n",
       "      <td>204535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>4.802750e-09</td>\n",
       "      <td>8.912795e-09</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.350478e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>barbour county</td>\n",
       "      <td>2241636927</td>\n",
       "      <td>2292160140</td>\n",
       "      <td>5.052321e+07</td>\n",
       "      <td>barbour county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1005</td>\n",
       "      <td>25782</td>\n",
       "      <td>25429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.038981</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>7.973384e-08</td>\n",
       "      <td>1.113265e-07</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>4.461026e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bibb county</td>\n",
       "      <td>1602558222</td>\n",
       "      <td>1612159622</td>\n",
       "      <td>9.601400e+06</td>\n",
       "      <td>bibb county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1007</td>\n",
       "      <td>22527</td>\n",
       "      <td>22340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.044702</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>8.670536e-08</td>\n",
       "      <td>6.897017e-08</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>6.240023e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>blount county</td>\n",
       "      <td>1655136409</td>\n",
       "      <td>1670127873</td>\n",
       "      <td>1.499146e+07</td>\n",
       "      <td>blount county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1009</td>\n",
       "      <td>57645</td>\n",
       "      <td>56710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.017504</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.324126e-08</td>\n",
       "      <td>7.523445e-09</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>6.041798e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1699 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   key_0          county  total_area   land_area    water_area  \\\n",
       "0      0  autauga county  1513895194  1539602155  2.570696e+07   \n",
       "1      1  baldwin county  2984648805  4117625664  1.132977e+09   \n",
       "2      2  barbour county  2241636927  2292160140  5.052321e+07   \n",
       "3      3     bibb county  1602558222  1612159622  9.601400e+06   \n",
       "4      4   blount county  1655136409  1670127873  1.499146e+07   \n",
       "\n",
       "         county_x state    id  population  \\\n",
       "0  autauga county    AL  1001       55200   \n",
       "1  baldwin county    AL  1003      208107   \n",
       "2  barbour county    AL  1005       25782   \n",
       "3     bibb county    AL  1007       22527   \n",
       "4   blount county    AL  1009       57645   \n",
       "\n",
       "   estimate!!race!!total population!!one race  ...  \\\n",
       "0                                       54170  ...   \n",
       "1                                      204535  ...   \n",
       "2                                       25429  ...   \n",
       "3                                       22340  ...   \n",
       "4                                       56710  ...   \n",
       "\n",
       "   nursing facilities total beds ratio  nurse practitioners_y ratio  \\\n",
       "0                                  0.0                          0.0   \n",
       "1                                  0.0                          0.0   \n",
       "2                                  0.0                          0.0   \n",
       "3                                  0.0                          0.0   \n",
       "4                                  0.0                          0.0   \n",
       "\n",
       "   advpractnurs midwve,male w/npi ratio  st_num ratio  countyfips ratio  \\\n",
       "0                                   0.0      0.000018          0.018134   \n",
       "1                                   0.0      0.000005          0.004820   \n",
       "2                                   0.0      0.000039          0.038981   \n",
       "3                                   0.0      0.000044          0.044702   \n",
       "4                                   0.0      0.000017          0.017504   \n",
       "\n",
       "   beds ratio  case_per_pop ratio  beds_per_pop ratio  beds_per_case ratio  \\\n",
       "0    0.001540        2.198855e-08        2.789593e-08             0.000023   \n",
       "1    0.001855        4.802750e-09        8.912795e-09             0.000009   \n",
       "2    0.002870        7.973384e-08        1.113265e-07             0.000054   \n",
       "3    0.001554        8.670536e-08        6.897017e-08             0.000035   \n",
       "4    0.000434        1.324126e-08        7.523445e-09             0.000010   \n",
       "\n",
       "   pop_density ratio  \n",
       "0       6.605477e-10  \n",
       "1       3.350478e-10  \n",
       "2       4.461026e-10  \n",
       "3       6.240023e-10  \n",
       "4       6.041798e-10  \n",
       "\n",
       "[5 rows x 1699 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "above_std_1['case_per_pop'] = ((above_std_1['case_per_pop'].values *0) +1).astype(int)\n",
    "# converts the hotspots to a value of one for the purposes of classification\n",
    "below['case_per_pop'] = ((below['case_per_pop'].values *0)).astype(int)\n",
    "# converts the rest to a value of zero for the purposes of classification\n",
    "master['case_per_pop'] = pd.concat([above_std_1['case_per_pop'],below['case_per_pop']])\n",
    "# overwrites our cases per capita column in the master with our classifications \n",
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master.to_csv('~/documents/case_per_pop_dummied_std_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = master['case_per_pop'].value_counts(normalize = True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using accuracy as our metric, our baseline is a score of .76227, which would occur if our model predicted an area to not be a coronavirus hotspot.  Since once standard deviation above the mean resulted in a decimal, we technically have a slightly lower baseline than initially thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = master.drop(columns = ['total_covid', 'deaths', 'county_x', 'county_y', 'state', 'id', \n",
    "                           'case_per_pop', 'beds_per_case', 'beds_per_case ratio', 'unnamed: 0_y', 'st_num',\n",
    "                           'cases', 'countyfips', 'key_0', 'county', 'case_per_pop ratio',\n",
    "                           'population ratio', 'st_num ratio', 'cases ratio', 'total_covid ratio',\n",
    "                           'deaths ratio', 'countyfips ratio'])\n",
    "'''drops features that could leak in regards to COVID-19 data, numerical columns relating to id,\n",
    "non-numerical columns, and remaining null columns'''\n",
    "y = master['case_per_pop']\n",
    "# sets target variable as cases per capita.\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)\n",
    "# For logistic regression, we will need our data scaled\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ss, y, random_state = 11, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108, 1677)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a classification problem, we want to start off by building a Logistic Regression model.  Since we have 1677 columns for only 3108 rows, we're going to force the lasso penalty on the model to inform feature elimination for other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([ #instantiate model\n",
    "    ('lr', LogisticRegression(random_state = 11))\n",
    "])\n",
    "\n",
    "# set hyperparameters\n",
    "\n",
    "pipe_params = {'lr__dual' : [True, False],\n",
    "               'lr__class_weight' : ['dict', 'balanced', None],\n",
    "              'lr__solver': ['liblinear', 'lbfgs', None],\n",
    "              'lr__penalty': ['l1'] # running this with the lasso and ridge techniques by applying a penalty, also running with no penalty\n",
    "              }\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid = pipe_params,\n",
    "                 cv = 5,\n",
    "                 scoring = 'accuracy',\n",
    "                 verbose = 2   \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.5s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   2.6s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.5s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.4s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:   16.2s finished\n"
     ]
    }
   ],
   "source": [
    "logreg_model = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg_train_score = logreg_model.score(X_train, y_train)\n",
    "\n",
    "logreg_test_score = logreg_model.score(X_test, y_test)\n",
    "\n",
    "logreg_cv = cross_val_score(logreg_model.best_estimator_, X_ss, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__class_weight': None,\n",
       " 'lr__dual': False,\n",
       " 'lr__penalty': 'l1',\n",
       " 'lr__solver': 'liblinear'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.8266838266838267\n",
      "Test Score 0.8056628056628057\n",
      "Cross Val Score 0.7770425255396596\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score {logreg_train_score}')\n",
    "print(f'Test Score {logreg_test_score}')\n",
    "print(f'Cross Val Score {logreg_cv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 90 fits for our first Logistic Regression Model, our best fit involed no class weights, no dual formation, and the liblinear solver.  For the sake of feature elimination, we forced the l1 (lasso) penalty on the model. This model was overfit because it had a  training score of .8267 and a testing score of .8057.  The testing score .8057 is still better than our baseline model's score of .76227.  Our lower cross-validation score of .777 vs our testing score shows that our model may not perform as well against unseen data as it did against our test data.  Next, I want to rerun the Logistic Regression Model with the features that our lasso eliminated.  Even though I am not evaluating coefficients yet, I will have to set up a new X & y with the irrelevant features removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-2.393127</td>\n",
       "      <td>estimate!!sex and age!!total population!!75 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>-1.402154</td>\n",
       "      <td>estimate!!citizen, voting age population!!citi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>-1.005262</td>\n",
       "      <td>unnamed: 0_y ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>-0.862214</td>\n",
       "      <td>estimate!!hispanic or latino and race!!total p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.808956</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.887311</td>\n",
       "      <td>estimate!!sex and age!!total population!!16 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.005249</td>\n",
       "      <td>estimate!!hispanic or latino and race!!total p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.237792</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>1.404032</td>\n",
       "      <td>estimate!!sex and age!!total population!!18 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.484136</td>\n",
       "      <td>estimate!!sex and age!!total population!!85 ye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1677 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficient                                            feature\n",
       "75     -2.393127  estimate!!sex and age!!total population!!75 to...\n",
       "893    -1.402154  estimate!!citizen, voting age population!!citi...\n",
       "927    -1.005262                                 unnamed: 0_y ratio\n",
       "878    -0.862214  estimate!!hispanic or latino and race!!total p...\n",
       "20     -0.808956  estimate!!race!!total population!!one race!!as...\n",
       "..           ...                                                ...\n",
       "915     0.887311  estimate!!sex and age!!total population!!16 ye...\n",
       "47      1.005249  estimate!!hispanic or latino and race!!total p...\n",
       "19      1.237792  estimate!!race!!total population!!one race!!as...\n",
       "923     1.404032  estimate!!sex and age!!total population!!18 ye...\n",
       "76      1.484136  estimate!!sex and age!!total population!!85 ye...\n",
       "\n",
       "[1677 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = logreg_model.best_estimator_.steps[0][1].coef_\n",
    "coef_df = pd.DataFrame(coefs).T\n",
    "coef_df['coefficients'] = list(X.columns)\n",
    "coef_df.rename(columns=({0: 'coefficient',\n",
    "                        'coefficients': 'feature'}), inplace=True)\n",
    "# gives us a dataframe of coefficients\n",
    "coef_df.sort_values(by = 'coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df['abs'] = abs(coef_df['coefficient'])\n",
    "\n",
    "lose_these = coef_df.loc[coef_df['abs'] < 0.0000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lose_these.to_csv('~/documents/bad_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we are not evaluating our coefficients yet, we created a list of features that added no value to our model as determined by the lasso penalty, and created a new dataframe of only the relevant features.  We will run a train, test split on this new dataframe and utilize the new dataframe for the rest of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_master = master.drop(columns = list(lose_these['feature'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108, 131)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = better_master.drop(columns = ['total_covid', 'deaths', 'county_x', 'county_y', 'state', 'id', \n",
    "                           'case_per_pop', 'beds_per_case', 'beds_per_case ratio', 'unnamed: 0_y', 'st_num',\n",
    "                           'cases', 'countyfips', 'key_0', 'county', 'case_per_pop ratio',\n",
    "                           'population ratio', 'st_num ratio', 'cases ratio', 'total_covid ratio',\n",
    "                           'deaths ratio', 'countyfips ratio'])\n",
    "y = better_master['case_per_pop']\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ss, y, random_state = 11, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([ #instantiate model\n",
    "    ('lr', LogisticRegression(random_state = 11))\n",
    "])\n",
    "\n",
    "# set hyperparameters\n",
    "\n",
    "pipe_params = {'lr__dual' : [True, False],\n",
    "               'lr__class_weight' : ['dict', 'balanced', None],\n",
    "              'lr__solver': ['liblinear', 'lbfgs', None],\n",
    "              'lr__penalty': ['l1', 'l2', 'none'] \n",
    "               # running this with the lasso and ridge techniques by applying a penalty, also running with no penalty\n",
    "              }\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid = pipe_params,\n",
    "                 cv = 5,\n",
    "                 scoring = 'accuracy',\n",
    "                 verbose = 2   \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.4s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.5s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   2.8s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.8s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.6s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.8s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.4s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   2.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.5s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.9s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   2.2s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done 270 out of 270 | elapsed:   26.2s finished\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg_2 = gs.fit(X_train, y_train)\n",
    "\n",
    "logreg_2_train_score = logreg_2.score(X_train, y_train)\n",
    "\n",
    "logreg_2_test_score = logreg_2.score(X_test, y_test)\n",
    "\n",
    "logreg_2_cv = cross_val_score(logreg_2.best_estimator_, X_ss, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__class_weight': 'dict',\n",
       " 'lr__dual': False,\n",
       " 'lr__penalty': 'none',\n",
       " 'lr__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.8352638352638353\n",
      "Test Score 0.8120978120978121\n",
      "Cross Val Score 0.7863719444314998\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score {logreg_2_train_score}')\n",
    "print(f'Test Score {logreg_2_test_score}')\n",
    "print(f'Cross Val Score {logreg_2_cv}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 270 fits for our second Logistic Regression model, our best fit involed the dict class weight, no dual formation, the lbfgs solver, and no penalty. This model was overfit because it had a  training score of .8353 and a testing score of .8121.  The testing score .8057 is still better than our baseline model's score of .76227.  Our lower cross-validation score of .7864 vs our testing score shows that our model may not perform as well against unseen data as it did against our test data.  Next, we want to utilize a KNN model to see if we can improve upon our score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('knn', KNeighborsClassifier())])\n",
    "\n",
    "# set hyperparameters\n",
    "\n",
    "pipe_params = {\n",
    "    'knn__n_neighbors': [3,5,7,9,27],\n",
    "    'knn__weights' : ['uniform', 'distance'], # distance gives more predictive power to closer neighbors\n",
    "    'knn__p': [1,2,'p'], # allows us to test Minkowski, Euclidean, and Manhattan measurements\n",
    "               \n",
    "              }\n",
    "\n",
    "gsknn = GridSearchCV(pipe,\n",
    "                 param_grid = pipe_params,\n",
    "                 cv = 5,\n",
    "                 scoring = 'accuracy',\n",
    "                 verbose = 2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=uniform ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=uniform ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=distance, total=   0.2s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=uniform ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=uniform ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=uniform, total=   0.9s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=distance, total=   0.6s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=distance, total=   0.5s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=distance, total=   0.5s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=uniform, total=   0.6s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=uniform, total=   0.6s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=uniform, total=   1.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=uniform, total=   0.5s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=uniform, total=   0.5s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=distance, total=   0.4s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=distance, total=   0.9s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=distance, total=   1.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=distance, total=   1.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=distance, total=   1.1s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=uniform ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=uniform, total=   0.5s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=uniform, total=   0.6s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=uniform .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=uniform, total=   0.5s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=uniform, total=   0.8s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=uniform, total=   0.6s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=distance, total=   0.5s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=distance, total=   0.5s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=distance, total=   0.5s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=distance, total=   0.4s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=uniform, total=   0.5s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=uniform, total=   0.5s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=uniform, total=   0.7s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=distance, total=   0.5s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=distance, total=   0.4s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=distance, total=   0.5s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=distance, total=   0.6s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=distance, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:   40.9s finished\n"
     ]
    }
   ],
   "source": [
    "knn_model = gsknn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 27, 'knn__p': 2, 'knn__weights': 'distance'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_test = knn_model.score(X_test, y_test)\n",
    "\n",
    "knn_train = knn_model.score(X_train, y_train)\n",
    "\n",
    "knn_cv = cross_val_score(knn_model.best_estimator_, X_ss, y).mean()\n",
    "\n",
    "knn_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 1.0\n",
      "Test Score 0.8043758043758044\n",
      "Cross Val Score 0.7940832906162139\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score {knn_train}')\n",
    "print(f'Test Score {knn_test}')\n",
    "print(f'Cross Val Score {knn_cv}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 150 fits for our KNN model, our best fit involed the 27 nearest neighbors, Euclidean distance, and weighting our points by distance. This model was overfit because it had a perfect training, but a testing score of .8044.  The testing score .8044 is still better than our baseline model's score of .76227.  Our lower cross-validation score of .7941 vs our testing score shows that our model may not perform as well against unseen data as it did against our test data.  Next, we want to run a Support Vector Machine to see if multidimensional grouping might allow the model to predict hotspots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([ #instantiate\n",
    "    ('svc', SVC())])\n",
    "\n",
    "# set hyperparameters\n",
    "\n",
    "pipe_params = {\n",
    "    'svc__kernel': ['linear', 'poly', 'rbf'],\n",
    "    'svc__class_weight' : [dict, 'balanced'],\n",
    "    'svc__random_state': [11],\n",
    "    'svc__gamma' : ['scale', 'auto'],\n",
    "    'svc__C' : [0, .5, 1],\n",
    "    'svc__shrinking' : [True, False]\n",
    "              }\n",
    "\n",
    "gssvc = GridSearchCV(pipe,\n",
    "                 param_grid = pipe_params,\n",
    "                 cv = 5,\n",
    "                 scoring = 'accuracy',\n",
    "                 verbose = 2   \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.2s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.2s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   3.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   3.4s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   4.2s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   3.5s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   2.5s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   1.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   1.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.4s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   1.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   1.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.2s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.2s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.3s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.2s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   3.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   3.4s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   3.5s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   5.6s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   5.5s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.6s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.6s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.5s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.3s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.9s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   5.2s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   6.5s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   6.6s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   4.1s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   9.6s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   1.0s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   1.4s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.1s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.6s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   2.1s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.9s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   2.2s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   3.0s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   5.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   6.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   6.3s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   4.3s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   9.9s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   1.6s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   1.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   1.4s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   2.0s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   1.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.0s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.3s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.6s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   1.4s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   1.3s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   1.2s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   1.5s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   1.2s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   1.1s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   1.1s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   1.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   1.4s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:  3.6min finished\n"
     ]
    }
   ],
   "source": [
    "svc_model = gssvc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc_test = svc_model.score(X_test, y_test)\n",
    "\n",
    "svc_train = svc_model.score(X_train, y_train)\n",
    "\n",
    "svc_cv = cross_val_score(svc_model.best_estimator_, X_ss, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 1,\n",
       " 'svc__class_weight': 'balanced',\n",
       " 'svc__gamma': 'scale',\n",
       " 'svc__kernel': 'poly',\n",
       " 'svc__random_state': 11,\n",
       " 'svc__shrinking': True}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.8043758043758044\n",
      "Test Score 0.8416988416988417\n",
      "Cross Val Score 0.7796091771906115\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score {svc_test}')\n",
    "print(f'Test Score {svc_train}')\n",
    "print(f'Cross Val Score {svc_cv}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 360 fits for our Support Vector Machine model, our best fit involed a C of 1, balanced class weights, scaled gamma, the poly kernel, and shrinking heuristics. This model was actually underfit because it had a training score of .8044, and a testing score of .8417.  The testing score .8417 is still better than our baseline model's score of .76227.  Our lower cross-validation score of .7796 vs our testing score shows that our model may not perform as well against unseen data as it did against our test data.  Since our test score still doesn't meet our predictive threshold, we would like to start with a Decision Tree classifier and then optimize it with a few techniques if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.8978978978978979\n",
      "Test Score 0.7619047619047619\n",
      "Cross Val Score 0.7442119597578846\n"
     ]
    }
   ],
   "source": [
    "dt_pipe = Pipeline([\n",
    "    ('dt' ,DecisionTreeClassifier())\n",
    "])\n",
    "pipe_params = {\n",
    "    'dt__max_depth' : [10],\n",
    "    'dt__min_samples_leaf' : [8],\n",
    "    'dt__min_samples_split' : [3],\n",
    "    }\n",
    "dtgs = GridSearchCV(dt_pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params,\n",
    "                  n_jobs = -1,# what parameters values are we searching?\n",
    "                  cv=StratifiedKFold(shuffle=True)\n",
    "                  ,\n",
    "                  verbose = 2) # 3-fold cross-validation.\n",
    "dtgs.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "decision_tree_test = dtgs.score(X_test, y_test)\n",
    "\n",
    "decision_tree_train = dtgs.score(X_train, y_train)\n",
    "\n",
    "decision_tree_cv = cross_val_score(dtgs.best_estimator_, X_ss, y).mean()\n",
    "\n",
    "print(f'Train Score {decision_tree_train}')\n",
    "print(f'Test Score {decision_tree_test}')\n",
    "print(f'Cross Val Score {decision_tree_cv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__max_depth': 10, 'dt__min_samples_leaf': 8, 'dt__min_samples_split': 3}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtgs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our Decision Tree model, our best fit involed a maximum depth of 10, 8 minimum samples for a leaf, a 3 minimum samples to split. This model was overfit because it had a training score of .8988, and a testing score of .7658.  The testing score .8417 is still better than our baseline model's score of .76227.  Our lower cross-validation score of .7458 vs our testing score shows that our model may not perform as well against unseen data as it did against our test data.  The lower cross-validation score than the baseline might even imply tht this model wouldn't even meet our standards for interpretability.  Since our test score still doesn't meet our predictive threshold, we would like to see if a Bagging technique could boost our score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   24.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.9991419991419992\n",
      "Test Score 0.8146718146718147\n",
      "Cross Val Score 0.7892653173234747\n"
     ]
    }
   ],
   "source": [
    "bag_pipe = Pipeline([\n",
    "    ('bag', BaggingClassifier())])\n",
    "pipe_params = {\n",
    "    'bag__n_estimators': [50],\n",
    "    'bag__max_features': [.9]\n",
    "    }\n",
    "bcgs = GridSearchCV(bag_pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params,\n",
    "                  n_jobs = -1,# what parameters values are we searching?\n",
    "                  cv=StratifiedKFold(shuffle=True),\n",
    "                  verbose = 2) # 3-fold cross-validation.\n",
    "bcgs.fit(X_train,y_train)\n",
    "bagging_test = bcgs.score(X_test, y_test)\n",
    "\n",
    "bagging_train = bcgs.score(X_train, y_train)\n",
    "\n",
    "bagging_cv = cross_val_score(bcgs.best_estimator_, X_ss, y).mean()\n",
    "\n",
    "print(f'Train Score {bagging_train}')\n",
    "print(f'Test Score {bagging_test}')\n",
    "print(f'Cross Val Score {bagging_cv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bag__max_features': 0.9, 'bag__n_estimators': 50}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcgs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our Bagging Classifier, our best fit involed .9 for maximum features and 50 estimators. This model was overfit because it had a training score of .9983, and a testing score of .8147.  The testing score .8147 is still better than our baseline model's score of .76227.  Our lower cross-validation score of .7941 vs our testing score shows that our model may not perform as well against unseen data as it did against our test data.  Since our test score still doesn't meet our predictive threshold, we would like to see if a Random Forest Classifier could boost our score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] rf__max_depth=5, rf__n_estimators=20 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. rf__max_depth=5, rf__n_estimators=20, total=   0.3s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=20 ............................\n",
      "[CV] ............. rf__max_depth=5, rf__n_estimators=20, total=   0.2s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=20 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. rf__max_depth=5, rf__n_estimators=20, total=   0.3s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=20 ............................\n",
      "[CV] ............. rf__max_depth=5, rf__n_estimators=20, total=   0.2s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=20 ............................\n",
      "[CV] ............. rf__max_depth=5, rf__n_estimators=20, total=   0.2s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=25 ............................\n",
      "[CV] ............. rf__max_depth=5, rf__n_estimators=25, total=   0.2s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=25 ............................\n",
      "[CV] ............. rf__max_depth=5, rf__n_estimators=25, total=   0.3s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=25 ............................\n",
      "[CV] ............. rf__max_depth=5, rf__n_estimators=25, total=   0.2s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=25 ............................\n",
      "[CV] ............. rf__max_depth=5, rf__n_estimators=25, total=   0.3s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=25 ............................\n",
      "[CV] ............. rf__max_depth=5, rf__n_estimators=25, total=   0.3s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=30 ............................\n",
      "[CV] ............. rf__max_depth=5, rf__n_estimators=30, total=   0.3s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=30 ............................\n",
      "[CV] ............. rf__max_depth=5, rf__n_estimators=30, total=   0.3s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=30 ............................\n",
      "[CV] ............. rf__max_depth=5, rf__n_estimators=30, total=   0.3s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=30 ............................\n",
      "[CV] ............. rf__max_depth=5, rf__n_estimators=30, total=   0.3s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=30 ............................\n",
      "[CV] ............. rf__max_depth=5, rf__n_estimators=30, total=   0.4s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=20 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=20, total=   0.3s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=20 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=20, total=   0.3s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=20 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=20, total=   0.3s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=20 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=20, total=   0.3s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=20 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=20, total=   0.3s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=25 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=25, total=   0.4s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=25 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=25, total=   0.4s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=25 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=25, total=   0.4s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=25 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=25, total=   0.4s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=25 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=25, total=   0.4s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=30 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=30, total=   0.4s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=30 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=30, total=   0.4s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=30 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=30, total=   0.5s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=30 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=30, total=   0.4s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=30 ...........................\n",
      "[CV] ............ rf__max_depth=10, rf__n_estimators=30, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.9356499356499357\n",
      "Test Score 0.8133848133848134\n",
      "Cross Val Score 0.7940843261827465\n"
     ]
    }
   ],
   "source": [
    "rf_pipe = Pipeline([\n",
    "    ('rf', RandomForestClassifier())])\n",
    "rf_params = {\n",
    "    'rf__max_depth':[5,10],\n",
    "    'rf__n_estimators':[20,25,30]\n",
    "}\n",
    "rfgs = GridSearchCV(rf_pipe, param_grid=rf_params, cv=5,verbose= 2)\n",
    "rfgs.fit(X_train, y_train)\n",
    "rf_test = rfgs.score(X_test, y_test)\n",
    "\n",
    "rf_train = rfgs.score(X_train, y_train)\n",
    "\n",
    "rf_cv = cross_val_score(rfgs.best_estimator_, X_ss, y).mean()\n",
    "\n",
    "print(f'Train Score {rf_train}')\n",
    "print(f'Test Score {rf_test}')\n",
    "print(f'Cross Val Score {rf_cv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__max_depth': 10, 'rf__n_estimators': 20}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfgs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 30 fits for our Random Forest Classifier, our best fit a maximum depth of 10 and 25 estimators. This model was overfit because it had a training score of .94, and a testing score of .8095.  The testing score .8095 is still better than our baseline model's score of .76227.  Our lower cross-validation score of .7896 vs our testing score shows that our model may not perform as well against unseen data as it did against our test data.  Since our test score still doesn't meet our predictive threshold, we would like to see if the Adaboost method could boost our score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   14.9s remaining:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   15.0s remaining:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   21.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   21.5s finished\n"
     ]
    }
   ],
   "source": [
    "ada_pipe = Pipeline([\n",
    "    ('ada', AdaBoostClassifier())])\n",
    "ada_params = {\n",
    "    'ada__n_estimators' : [250],\n",
    "    'ada__learning_rate' : [1.5]\n",
    "    }\n",
    "adags = GridSearchCV(ada_pipe, param_grid=ada_params, cv=StratifiedKFold(shuffle=True),verbose=12, n_jobs=-1)\n",
    "adags.fit(X_train, y_train)\n",
    "ada_test = adags.score(X_test, y_test)\n",
    "\n",
    "ada_train = adags.score(X_train, y_train)\n",
    "\n",
    "ada_cv = cross_val_score(adags.best_estimator_, X_ss, y).mean()\n",
    "\n",
    "print(f'Train Score {ada_train}')\n",
    "print(f'Test Score {ada_test}')\n",
    "print(f'Cross Val Score {ada_cv}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our Adaboost, our best fit involed a learning rate of 1.5 and 250 estimators. This model was overfit because it had a training score of .9254, and a testing score of .7722.  The testing score .7722 is barely better than our baseline model's score of .76227.  Our lower cross-validation score of .7053 vs our testing score shows that our model may not perform as well against unseen data as it did against our test data.  The lower cross-validation score than the baseline might even imply tht this model wouldn't even meet our standards for interpretability.  We are confident that we will not be able to meet our 95% predictability threshold, so we do want to move on to selection for model interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Baseline Accuracy: {baseline}')\n",
    "print(f'First Logistic Regression Training Score: {logreg_train_score}')\n",
    "print(f'First Logistic Regression Testing Score: {logreg_test_score}')\n",
    "print(f'First Logistic Regression Cross Val Score: {logreg_cv}')\n",
    "print(f'Logistic Regression (Post-Feature Elimination) Training Score: {logreg_2_train_score}')\n",
    "print(f'Logistic Regression (Post-Feature Elimination) Testing Score: {logreg_2_test_score}')\n",
    "print(f'Logistic Regression (Post-Feature Elimination) Cross Val Score: {logreg_2_cv}')\n",
    "print(f'KNN Training Score: {knn_train}')\n",
    "print(f'KNN Testing Score: {knn_test}')\n",
    "print(f'KNN Val Score: {knn_cv}')\n",
    "print(f'Support Vector Machine Training Score: {svc_test}')\n",
    "print(f'Support Vector Machine Testing Score: {svc_train}')\n",
    "print(f'Support Vector Machine Cross Val Score: {svc_cv}')\n",
    "print(f'Decision Tree Training Score: {decision_tree_train}')\n",
    "print(f'Decision Tree Testing Score: {decision_tree_test}')\n",
    "print(f'Decision Tree Cross Val Score: {decision_tree_cv}')\n",
    "print(f'Bagging Classifier Training Score: {bagging_train}')\n",
    "print(f'Bagging Classifier Testing Score: {bagging_test}')\n",
    "print(f'Bagging Classifier Cross Val Score: {bagging_cv}')\n",
    "print(f'Random Forest Training Score: {rf_train}')\n",
    "print(f'Random Forest Testing Score: {rf_test}')\n",
    "print(f'Random Forest Cross Val Score: {rf_cv}')\n",
    "print(f'Adaboost Training Score: {ada_train}')\n",
    "print(f'Adaboost Testing Score: {ada_test}')\n",
    "print(f'Adaboost Cross Val Score: {ada_cv}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to select our second Logistic Regression model because a Logistic Regression model is a fairly interpretive model and the model still outperforms many of the other models we built.  Our test score of .8121 was the third best test score of all of our models and we will be able to evaluate the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we selected our model and it is a classification problem, the first thing we want to do is look at our Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg_preds = logreg_2.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, logreg_preds).ravel() # From Danielle Medellin's confusion matrix setup\n",
    "cm = confusion_matrix(y_test, logreg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_df = pd.DataFrame(cm)\n",
    "cm_df.columns = ['Non-Hotspot Prediction', 'Hotspot Prediction']\n",
    "\n",
    "cm_df.index = ['Actual Non-Hotspot', \"Actual Hotspot\"]\n",
    "#This adds the appropriate row and column names for the confusion matrix\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_df, annot = True, fmt = 'g', cmap = 'Blues')\n",
    "plt.title('Confusion Matrix', size = 15)\n",
    "plt.ylabel('Predictions', size = 15)\n",
    "plt.xlabel('Actual Class', size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our accuracy score does beat our baseline, the unbalanced classes of having mostly non-hotspots hurts the predictability aspect of correctly predicting COVID-19 hotspots.  Due to this, our model is mostly guessing that most areas are not hotspots, which gives 105 false positives, which would mean that this model is NOT good at predicting where there is a hotspot.  The better-than-baseline accuracy seems mostly driven by its ability to predict where there isn't a hotspot, which isn't that difficult since that is our majority class.  If we were to further fine-tune the model, we would want to significantly decrease the False Positives, which we might accomplish by either bootstrapping techniques, PCA, or adjusting our classification threshold.\n",
    "\n",
    "Next, we do want to investigate some of our coefficients, since our model still outperformed the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coefs = logreg_2.best_estimator_.steps[0][1].coef_\n",
    "# gets the coefficients\n",
    "new_coef_df = pd.DataFrame(new_coefs).T\n",
    "# transposes, so we can line them up correctly\n",
    "\n",
    "\n",
    "new_coef_df['coefficients'] = list(X.columns)\n",
    "#names a column for coefficients\n",
    "new_coef_df.rename(columns=({0: 'coefficient',\n",
    "                        'coefficients': 'feature'}), inplace=True)\n",
    "# this is slightly confusing, but we are making sure that our features are named correctly\n",
    "\n",
    "new_coef_df['actual_odds'] = np.exp(new_coef_df['coefficient'])\n",
    "# since our coefficients are technically the log odds, we exponentiated to showcase the actual odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(new_coef_df.sort_values(by = 'coefficient').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These represent our lowest coefficients, meaning a greater feature value in these are more likely to result in an area not being considered a hotspot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef_df.sort_values(by = 'coefficient').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_counties = y_test.loc[(y_test != 1) & (logreg_preds == 1)].index #shows me misclassified rows\n",
    "\n",
    "\n",
    "fp_df = better_master.loc[master.index[fp_counties]]\n",
    "\n",
    "\n",
    "fp_df['population'] = master['population'][fp_df.index].values\n",
    "\n",
    "fp_df.sort_values(by = 'population', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp_df.to_csv('~/documents/false_positives.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chosen Logistic Regression model scored 0.8121 on accuracy, which means that while it failed to meet our goal of .95 in order to fulfill its usage as a predictive model.  However, the model did surpass the accuracy score of .7625 that allows us to interpret coefficients and further investigate potential COVID-19 hotspots.\n",
    "\n",
    "We do want to stress that on areas of actual COVID-19 hotspots, the model did not do a good job at predicting COVID-19 hotspots.  Our clients should not make any actionable decisions based on the model other than further research into some of the possible correlated features, like the high ratio of men to women over 18 being more prevalent in COVID-19 hotspots.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
