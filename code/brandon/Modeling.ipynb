{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our client wants to try to predict COVID-19 hotspots based on demographics and has asked us to build a predictive model that could predict if a county is a COVID-19 hotspot.  Since we are cautious about trying to predict an ongoing problem with many changes in real-time data, we informed that if our models don't meet a __.95 accuracy score or better__ that they should only use the model for interpretive purposes and not predictive purposes.  While the client understands the low likelihood of building a predictive model under this criteria, they gave us the budget to proceed anyway.\n",
    "\n",
    "We defined a \"COVID-19 hotspot\" as a county in the contiguous US that has a rate of infected residents per capita that is higher than one standard deviation for the mean.  This actually presents an interesting situation where we already know that our baseline model will have an accuracy rate of .7625.  Due to this, we will only consider our model interpretable if we can beat the baseline accuracy.\n",
    "\n",
    "We are viewing this as a classification problem and will look to run Logistic Regression, KNN, Support Vector Machine, Decision Tree Classifier, Bagging Classifier,Random Forest, and AdaBoost models in order to see if it's possible to predict COVID-19 hotspots based on county demographic data.\n",
    "\n",
    "To reiterate, our goal for the model to be considered predictive is a __.95 accuracy score or better__, and our goal for the model to be considered interpretable is a __.7626 accuracy score or better__.  This is to ensure that we are held to high standards when it comes to predicting an ongoing pandemic, but also ensures that we can interpret the findings if we are performing better than average.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1882,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.base import TransformerMixin # from Mahdi\n",
    "\n",
    "import regex as re\n",
    "\n",
    "random_state = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was initially pulled on May 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1883,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv('~/downloads/new_beds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1884,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Master was the result of all of our cleaned dataframes merged into one, however we found some more specific area data after the fact, which is why we read in a separate dataframe.  We will have to do a little more cleaning, but master will remain as our Master dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1885,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "area = pd.read_csv('~/downloads/area_ready.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1886,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>total_area</th>\n",
       "      <th>land_area</th>\n",
       "      <th>water_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autauga county</td>\n",
       "      <td>1513895194</td>\n",
       "      <td>1539602155</td>\n",
       "      <td>2.570696e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baldwin county</td>\n",
       "      <td>2984648805</td>\n",
       "      <td>4117625664</td>\n",
       "      <td>1.132977e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barbour county</td>\n",
       "      <td>2241636927</td>\n",
       "      <td>2292160140</td>\n",
       "      <td>5.052321e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bibb county</td>\n",
       "      <td>1602558222</td>\n",
       "      <td>1612159622</td>\n",
       "      <td>9.601400e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blount county</td>\n",
       "      <td>1655136409</td>\n",
       "      <td>1670127873</td>\n",
       "      <td>1.499146e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           county  total_area   land_area    water_area\n",
       "0  autauga county  1513895194  1539602155  2.570696e+07\n",
       "1  baldwin county  2984648805  4117625664  1.132977e+09\n",
       "2  barbour county  2241636927  2292160140  5.052321e+07\n",
       "3     bibb county  1602558222  1612159622  9.601400e+06\n",
       "4   blount county  1655136409  1670127873  1.499146e+07"
      ]
     },
     "execution_count": 1886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area = area.drop(columns = 'Unnamed: 0')\n",
    "# csv was created without index = False, so have to drop the first column\n",
    "area.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are still treated our master as the master, first, we're going to merge area and master and save over the master dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1887,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>county</th>\n",
       "      <th>total_area</th>\n",
       "      <th>land_area</th>\n",
       "      <th>water_area</th>\n",
       "      <th>county_x</th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>population</th>\n",
       "      <th>estimate!!race!!total population!!one race</th>\n",
       "      <th>...</th>\n",
       "      <th>cert nurse midwvs,ft oth emptyp_y</th>\n",
       "      <th>nursing facilities total beds</th>\n",
       "      <th>nurse practitioners_y</th>\n",
       "      <th>advpractnurs midwve,male w/npi</th>\n",
       "      <th>st_num</th>\n",
       "      <th>countyfips</th>\n",
       "      <th>beds</th>\n",
       "      <th>case_per_pop</th>\n",
       "      <th>beds_per_pop</th>\n",
       "      <th>beds_per_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>autauga county</td>\n",
       "      <td>1513895194</td>\n",
       "      <td>1539602155</td>\n",
       "      <td>2.570696e+07</td>\n",
       "      <td>autauga county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>55200</td>\n",
       "      <td>54170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>1.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>baldwin county</td>\n",
       "      <td>2984648805</td>\n",
       "      <td>4117625664</td>\n",
       "      <td>1.132977e+09</td>\n",
       "      <td>baldwin county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1003</td>\n",
       "      <td>208107</td>\n",
       "      <td>204535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>1.855769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>barbour county</td>\n",
       "      <td>2241636927</td>\n",
       "      <td>2292160140</td>\n",
       "      <td>5.052321e+07</td>\n",
       "      <td>barbour county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1005</td>\n",
       "      <td>25782</td>\n",
       "      <td>25429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1005</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>1.396226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bibb county</td>\n",
       "      <td>1602558222</td>\n",
       "      <td>1612159622</td>\n",
       "      <td>9.601400e+06</td>\n",
       "      <td>bibb county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1007</td>\n",
       "      <td>22527</td>\n",
       "      <td>22340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1007</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.795455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>blount county</td>\n",
       "      <td>1655136409</td>\n",
       "      <td>1670127873</td>\n",
       "      <td>1.499146e+07</td>\n",
       "      <td>blount county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1009</td>\n",
       "      <td>57645</td>\n",
       "      <td>56710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1009</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.568182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 853 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   key_0          county  total_area   land_area    water_area  \\\n",
       "0      0  autauga county  1513895194  1539602155  2.570696e+07   \n",
       "1      1  baldwin county  2984648805  4117625664  1.132977e+09   \n",
       "2      2  barbour county  2241636927  2292160140  5.052321e+07   \n",
       "3      3     bibb county  1602558222  1612159622  9.601400e+06   \n",
       "4      4   blount county  1655136409  1670127873  1.499146e+07   \n",
       "\n",
       "         county_x state    id  population  \\\n",
       "0  autauga county    AL  1001       55200   \n",
       "1  baldwin county    AL  1003      208107   \n",
       "2  barbour county    AL  1005       25782   \n",
       "3     bibb county    AL  1007       22527   \n",
       "4   blount county    AL  1009       57645   \n",
       "\n",
       "   estimate!!race!!total population!!one race  ...  \\\n",
       "0                                       54170  ...   \n",
       "1                                      204535  ...   \n",
       "2                                       25429  ...   \n",
       "3                                       22340  ...   \n",
       "4                                       56710  ...   \n",
       "\n",
       "   cert nurse midwvs,ft oth emptyp_y  nursing facilities total beds  \\\n",
       "0                                0.0                            0.0   \n",
       "1                                0.0                            0.0   \n",
       "2                                0.0                            0.0   \n",
       "3                                0.0                            0.0   \n",
       "4                                0.0                            0.0   \n",
       "\n",
       "   nurse practitioners_y  advpractnurs midwve,male w/npi  st_num  countyfips  \\\n",
       "0                    0.0                             0.0       1        1001   \n",
       "1                    0.0                             0.0       1        1003   \n",
       "2                    0.0                             0.0       1        1005   \n",
       "3                    0.0                             0.0       1        1007   \n",
       "4                    0.0                             0.0       1        1009   \n",
       "\n",
       "    beds  case_per_pop  beds_per_pop  beds_per_case  \n",
       "0   85.0      0.001214      0.001540       1.268657  \n",
       "1  386.0      0.000999      0.001855       1.855769  \n",
       "2   74.0      0.002056      0.002870       1.396226  \n",
       "3   35.0      0.001953      0.001554       0.795455  \n",
       "4   25.0      0.000763      0.000434       0.568182  \n",
       "\n",
       "[5 rows x 853 columns]"
      ]
     },
     "execution_count": 1887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master = pd.merge(area, master, how = 'left', on=area.index)\n",
    "\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we've cleaned, we still want to check our null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1888,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key_0                                  0\n",
       "# hosp w/diag radioisotope fac         0\n",
       "other spec, tot, pc, hosp res          0\n",
       "forensic path, pc, hosp ft stf         0\n",
       "# stng/lt hosps,100-199 beds_y         0\n",
       "                                    ... \n",
       "skilled nurs fac certified beds_x      0\n",
       "# stng/lt hosps,050-099 beds_x         0\n",
       "nursing home beds, st gen hosp_x       0\n",
       "water_area                             1\n",
       "beds_per_case                        103\n",
       "Length: 853, dtype: int64"
      ]
     },
     "execution_count": 1888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to end up dropping beds per case when we set up our X & y variables because that would be technically leaking coronavirus data into our model, but for EDA purposes, it could be worth keeping around.  I'm more concerned investigating the water area null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1889,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>county</th>\n",
       "      <th>total_area</th>\n",
       "      <th>land_area</th>\n",
       "      <th>water_area</th>\n",
       "      <th>county_x</th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>population</th>\n",
       "      <th>estimate!!race!!total population!!one race</th>\n",
       "      <th>...</th>\n",
       "      <th>cert nurse midwvs,ft oth emptyp_y</th>\n",
       "      <th>nursing facilities total beds</th>\n",
       "      <th>nurse practitioners_y</th>\n",
       "      <th>advpractnurs midwve,male w/npi</th>\n",
       "      <th>st_num</th>\n",
       "      <th>countyfips</th>\n",
       "      <th>beds</th>\n",
       "      <th>case_per_pop</th>\n",
       "      <th>beds_per_pop</th>\n",
       "      <th>beds_per_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>greeley county</td>\n",
       "      <td>2016057907</td>\n",
       "      <td>2016057907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greeley county</td>\n",
       "      <td>KS</td>\n",
       "      <td>20071</td>\n",
       "      <td>1200</td>\n",
       "      <td>1179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20071</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 853 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     key_0          county  total_area   land_area  water_area  \\\n",
       "889    889  greeley county  2016057907  2016057907         NaN   \n",
       "\n",
       "           county_x state     id  population  \\\n",
       "889  greeley county    KS  20071        1200   \n",
       "\n",
       "     estimate!!race!!total population!!one race  ...  \\\n",
       "889                                        1179  ...   \n",
       "\n",
       "     cert nurse midwvs,ft oth emptyp_y  nursing facilities total beds  \\\n",
       "889                                0.0                            0.0   \n",
       "\n",
       "     nurse practitioners_y  advpractnurs midwve,male w/npi  st_num  \\\n",
       "889                    0.0                             0.0      20   \n",
       "\n",
       "     countyfips  beds  case_per_pop  beds_per_pop  beds_per_case  \n",
       "889       20071  18.0           0.0         0.015            inf  \n",
       "\n",
       "[1 rows x 853 columns]"
      ]
     },
     "execution_count": 1889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.loc[master['water_area'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since total area for Greeley County equals land area, I'm going to impute 0 for water area in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1890,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['water_area'].replace({None: 0}, inplace = True)\n",
    "\n",
    "master['pop_density'] = master['population'] / master['total_area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The census data we collected is in total units, but we want to see if ratios might be a better predictor of hotspots than a total.  We do want to be able to feed both into our model.  To get started, we feature engineered a column for population density.  Next we want to create a for loop to loop through the census-specific columns and create ratios with the population as a denominator for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1891,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3108, 845)"
      ]
     },
     "execution_count": 1891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cens = master[master.columns[8:]]\n",
    "cens.drop(columns = 'county_y', inplace = True)\n",
    "cens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    748\n",
       "int64       97\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cens.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1893,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "population                                                   int64\n",
       "estimate!!sex and age!!total population!!65 to 74 years      int64\n",
       "estimate!!sex and age!!total population!!60 to 64 years      int64\n",
       "estimate!!sex and age!!total population!!55 to 59 years      int64\n",
       "estimate!!sex and age!!total population!!45 to 54 years      int64\n",
       "                                                            ...   \n",
       "dist hosp by 05 - 14 services                              float64\n",
       "int med subspecs, pc, hosp res                             float64\n",
       "ophthalmolgy, pc, hosp resdnts                             float64\n",
       "preventable hospital stays rate                            float64\n",
       "pop_density                                                float64\n",
       "Length: 845, dtype: object"
      ]
     },
     "execution_count": 1893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cens.dtypes.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1894,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race ratio</th>\n",
       "      <th>estimate!!race!!total population!!two or more races ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race.1 ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race!!white ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race!!black or african american ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native!!cherokee tribal grouping ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native!!chippewa tribal grouping ratio</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native!!navajo tribal grouping ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>nursing facilities total beds ratio</th>\n",
       "      <th>nurse practitioners_y ratio</th>\n",
       "      <th>advpractnurs midwve,male w/npi ratio</th>\n",
       "      <th>st_num ratio</th>\n",
       "      <th>countyfips ratio</th>\n",
       "      <th>beds ratio</th>\n",
       "      <th>case_per_pop ratio</th>\n",
       "      <th>beds_per_pop ratio</th>\n",
       "      <th>beds_per_case ratio</th>\n",
       "      <th>pop_density ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981341</td>\n",
       "      <td>0.018659</td>\n",
       "      <td>0.981341</td>\n",
       "      <td>0.768786</td>\n",
       "      <td>0.191395</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>2.198855e-08</td>\n",
       "      <td>2.789593e-08</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6.605477e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982836</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.982836</td>\n",
       "      <td>0.862662</td>\n",
       "      <td>0.094970</td>\n",
       "      <td>0.007314</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>4.802750e-09</td>\n",
       "      <td>8.912795e-09</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.350478e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986308</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.986308</td>\n",
       "      <td>0.473819</td>\n",
       "      <td>0.475758</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.038981</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>7.973384e-08</td>\n",
       "      <td>1.113265e-07</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>4.461026e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991699</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.991699</td>\n",
       "      <td>0.766547</td>\n",
       "      <td>0.222755</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.044702</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>8.670536e-08</td>\n",
       "      <td>6.897017e-08</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>6.240023e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983780</td>\n",
       "      <td>0.016220</td>\n",
       "      <td>0.983780</td>\n",
       "      <td>0.955052</td>\n",
       "      <td>0.014954</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.017504</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.324126e-08</td>\n",
       "      <td>7.523445e-09</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>6.041798e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 845 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population ratio  estimate!!race!!total population!!one race ratio  \\\n",
       "0               1.0                                          0.981341   \n",
       "1               1.0                                          0.982836   \n",
       "2               1.0                                          0.986308   \n",
       "3               1.0                                          0.991699   \n",
       "4               1.0                                          0.983780   \n",
       "\n",
       "   estimate!!race!!total population!!two or more races ratio  \\\n",
       "0                                           0.018659           \n",
       "1                                           0.017164           \n",
       "2                                           0.013692           \n",
       "3                                           0.008301           \n",
       "4                                           0.016220           \n",
       "\n",
       "   estimate!!race!!total population!!one race.1 ratio  \\\n",
       "0                                           0.981341    \n",
       "1                                           0.982836    \n",
       "2                                           0.986308    \n",
       "3                                           0.991699    \n",
       "4                                           0.983780    \n",
       "\n",
       "   estimate!!race!!total population!!one race!!white ratio  \\\n",
       "0                                           0.768786         \n",
       "1                                           0.862662         \n",
       "2                                           0.473819         \n",
       "3                                           0.766547         \n",
       "4                                           0.955052         \n",
       "\n",
       "   estimate!!race!!total population!!one race!!black or african american ratio  \\\n",
       "0                                           0.191395                             \n",
       "1                                           0.094970                             \n",
       "2                                           0.475758                             \n",
       "3                                           0.222755                             \n",
       "4                                           0.014954                             \n",
       "\n",
       "   estimate!!race!!total population!!one race!!american indian and alaska native ratio  \\\n",
       "0                                           0.002880                                     \n",
       "1                                           0.007314                                     \n",
       "2                                           0.002793                                     \n",
       "3                                           0.000355                                     \n",
       "4                                           0.002446                                     \n",
       "\n",
       "   estimate!!race!!total population!!one race!!american indian and alaska native!!cherokee tribal grouping ratio  \\\n",
       "0                                           0.001486                                                               \n",
       "1                                           0.001369                                                               \n",
       "2                                           0.001008                                                               \n",
       "3                                           0.000000                                                               \n",
       "4                                           0.000347                                                               \n",
       "\n",
       "   estimate!!race!!total population!!one race!!american indian and alaska native!!chippewa tribal grouping ratio  \\\n",
       "0                                                0.0                                                               \n",
       "1                                                0.0                                                               \n",
       "2                                                0.0                                                               \n",
       "3                                                0.0                                                               \n",
       "4                                                0.0                                                               \n",
       "\n",
       "   estimate!!race!!total population!!one race!!american indian and alaska native!!navajo tribal grouping ratio  \\\n",
       "0                                           0.000797                                                             \n",
       "1                                           0.000336                                                             \n",
       "2                                           0.000349                                                             \n",
       "3                                           0.000000                                                             \n",
       "4                                           0.000000                                                             \n",
       "\n",
       "   ...  nursing facilities total beds ratio  nurse practitioners_y ratio  \\\n",
       "0  ...                                  0.0                          0.0   \n",
       "1  ...                                  0.0                          0.0   \n",
       "2  ...                                  0.0                          0.0   \n",
       "3  ...                                  0.0                          0.0   \n",
       "4  ...                                  0.0                          0.0   \n",
       "\n",
       "   advpractnurs midwve,male w/npi ratio  st_num ratio  countyfips ratio  \\\n",
       "0                                   0.0      0.000018          0.018134   \n",
       "1                                   0.0      0.000005          0.004820   \n",
       "2                                   0.0      0.000039          0.038981   \n",
       "3                                   0.0      0.000044          0.044702   \n",
       "4                                   0.0      0.000017          0.017504   \n",
       "\n",
       "   beds ratio  case_per_pop ratio  beds_per_pop ratio  beds_per_case ratio  \\\n",
       "0    0.001540        2.198855e-08        2.789593e-08             0.000023   \n",
       "1    0.001855        4.802750e-09        8.912795e-09             0.000009   \n",
       "2    0.002870        7.973384e-08        1.113265e-07             0.000054   \n",
       "3    0.001554        8.670536e-08        6.897017e-08             0.000035   \n",
       "4    0.000434        1.324126e-08        7.523445e-09             0.000010   \n",
       "\n",
       "   pop_density ratio  \n",
       "0       6.605477e-10  \n",
       "1       3.350478e-10  \n",
       "2       4.461026e-10  \n",
       "3       6.240023e-10  \n",
       "4       6.041798e-10  \n",
       "\n",
       "[5 rows x 845 columns]"
      ]
     },
     "execution_count": 1894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios = [] # instantiate empty list\n",
    "for num in range(845): #iterates through all census columns\n",
    "    ratio = cens[cens.columns[num]]/ cens['population']\n",
    "    ratios.append(ratio) \n",
    "    \n",
    "\n",
    "ratio_df = pd.DataFrame(ratios).T \n",
    "#turn list into a dataframe, need to transpose, so the values and columns line up properly\n",
    "ratio_df.columns =  cens.columns\n",
    "\n",
    "ratio_df.columns = ratio_df.columns + ' ratio'\n",
    "\n",
    "ratio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1895,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_df.to_csv('~/documents/population_ratios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1896,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master.join(ratio_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We overwrote the Master to include the ratio columns.  Data is cleaned up to where we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1897,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(master['case_per_pop'], bins = 20)\n",
    "plt.title('% of Cases Per Capita Histogram')\n",
    "plt.xlabel('% of Cases Per Capita')\n",
    "plt.ylabel('Number of Counties');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1898,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After everything is grouped, I can run some boxplots, diplaying differences between hotspots and non-hotspots.\n",
    "# I can also look at relationships, like cases per pop vs beds per pop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1899,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2375"
      ]
     },
     "execution_count": 1899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".95/2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1900,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "738.15"
      ]
     },
     "execution_count": 1900,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape[0] * 0.2375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1901,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2369"
      ]
     },
     "execution_count": 1901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape[0] - 739"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This informs us on how many counties will be designated as a \"hotspot.\"  I'm going to round up for the cutoff because the value should be larger than 738, and since you can't have .15 of a county, I will use 739 as designated hotspots.  That leaves us with 2369 that will not be considered hotspots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1902,
   "metadata": {},
   "outputs": [],
   "source": [
    "above_std_1 = master.sort_values(by = 'case_per_pop', ascending = False).head(739)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a list of counties that meet our criteria of a COVID-19 hotspot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1903,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.002056\n",
       "Name: case_per_pop, dtype: float64"
      ]
     },
     "execution_count": 1903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "above_std_1['case_per_pop'].sort_values().head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows our cutoff point for our cases per population ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1904,
   "metadata": {},
   "outputs": [],
   "source": [
    "below = master.sort_values(by = 'case_per_pop', ascending = False).tail(2369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1905,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>county</th>\n",
       "      <th>total_area</th>\n",
       "      <th>land_area</th>\n",
       "      <th>water_area</th>\n",
       "      <th>county_x</th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>population</th>\n",
       "      <th>estimate!!race!!total population!!one race</th>\n",
       "      <th>...</th>\n",
       "      <th>nursing facilities total beds ratio</th>\n",
       "      <th>nurse practitioners_y ratio</th>\n",
       "      <th>advpractnurs midwve,male w/npi ratio</th>\n",
       "      <th>st_num ratio</th>\n",
       "      <th>countyfips ratio</th>\n",
       "      <th>beds ratio</th>\n",
       "      <th>case_per_pop ratio</th>\n",
       "      <th>beds_per_pop ratio</th>\n",
       "      <th>beds_per_case ratio</th>\n",
       "      <th>pop_density ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>autauga county</td>\n",
       "      <td>1513895194</td>\n",
       "      <td>1539602155</td>\n",
       "      <td>2.570696e+07</td>\n",
       "      <td>autauga county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>55200</td>\n",
       "      <td>54170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>2.198855e-08</td>\n",
       "      <td>2.789593e-08</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6.605477e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>baldwin county</td>\n",
       "      <td>2984648805</td>\n",
       "      <td>4117625664</td>\n",
       "      <td>1.132977e+09</td>\n",
       "      <td>baldwin county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1003</td>\n",
       "      <td>208107</td>\n",
       "      <td>204535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>4.802750e-09</td>\n",
       "      <td>8.912795e-09</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.350478e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>barbour county</td>\n",
       "      <td>2241636927</td>\n",
       "      <td>2292160140</td>\n",
       "      <td>5.052321e+07</td>\n",
       "      <td>barbour county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1005</td>\n",
       "      <td>25782</td>\n",
       "      <td>25429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.038981</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>7.973384e-08</td>\n",
       "      <td>1.113265e-07</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>4.461026e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bibb county</td>\n",
       "      <td>1602558222</td>\n",
       "      <td>1612159622</td>\n",
       "      <td>9.601400e+06</td>\n",
       "      <td>bibb county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1007</td>\n",
       "      <td>22527</td>\n",
       "      <td>22340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.044702</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>8.670536e-08</td>\n",
       "      <td>6.897017e-08</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>6.240023e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>blount county</td>\n",
       "      <td>1655136409</td>\n",
       "      <td>1670127873</td>\n",
       "      <td>1.499146e+07</td>\n",
       "      <td>blount county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1009</td>\n",
       "      <td>57645</td>\n",
       "      <td>56710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.017504</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.324126e-08</td>\n",
       "      <td>7.523445e-09</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>6.041798e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1699 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   key_0          county  total_area   land_area    water_area  \\\n",
       "0      0  autauga county  1513895194  1539602155  2.570696e+07   \n",
       "1      1  baldwin county  2984648805  4117625664  1.132977e+09   \n",
       "2      2  barbour county  2241636927  2292160140  5.052321e+07   \n",
       "3      3     bibb county  1602558222  1612159622  9.601400e+06   \n",
       "4      4   blount county  1655136409  1670127873  1.499146e+07   \n",
       "\n",
       "         county_x state    id  population  \\\n",
       "0  autauga county    AL  1001       55200   \n",
       "1  baldwin county    AL  1003      208107   \n",
       "2  barbour county    AL  1005       25782   \n",
       "3     bibb county    AL  1007       22527   \n",
       "4   blount county    AL  1009       57645   \n",
       "\n",
       "   estimate!!race!!total population!!one race  ...  \\\n",
       "0                                       54170  ...   \n",
       "1                                      204535  ...   \n",
       "2                                       25429  ...   \n",
       "3                                       22340  ...   \n",
       "4                                       56710  ...   \n",
       "\n",
       "   nursing facilities total beds ratio  nurse practitioners_y ratio  \\\n",
       "0                                  0.0                          0.0   \n",
       "1                                  0.0                          0.0   \n",
       "2                                  0.0                          0.0   \n",
       "3                                  0.0                          0.0   \n",
       "4                                  0.0                          0.0   \n",
       "\n",
       "   advpractnurs midwve,male w/npi ratio  st_num ratio  countyfips ratio  \\\n",
       "0                                   0.0      0.000018          0.018134   \n",
       "1                                   0.0      0.000005          0.004820   \n",
       "2                                   0.0      0.000039          0.038981   \n",
       "3                                   0.0      0.000044          0.044702   \n",
       "4                                   0.0      0.000017          0.017504   \n",
       "\n",
       "   beds ratio  case_per_pop ratio  beds_per_pop ratio  beds_per_case ratio  \\\n",
       "0    0.001540        2.198855e-08        2.789593e-08             0.000023   \n",
       "1    0.001855        4.802750e-09        8.912795e-09             0.000009   \n",
       "2    0.002870        7.973384e-08        1.113265e-07             0.000054   \n",
       "3    0.001554        8.670536e-08        6.897017e-08             0.000035   \n",
       "4    0.000434        1.324126e-08        7.523445e-09             0.000010   \n",
       "\n",
       "   pop_density ratio  \n",
       "0       6.605477e-10  \n",
       "1       3.350478e-10  \n",
       "2       4.461026e-10  \n",
       "3       6.240023e-10  \n",
       "4       6.041798e-10  \n",
       "\n",
       "[5 rows x 1699 columns]"
      ]
     },
     "execution_count": 1905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "above_std_1['case_per_pop'] = ((above_std_1['case_per_pop'].values *0) +1).astype(int)\n",
    "\n",
    "below['case_per_pop'] = ((below['case_per_pop'].values *0)).astype(int)\n",
    "\n",
    "master['case_per_pop'] = pd.concat([above_std_1['case_per_pop'],below['case_per_pop']])\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes our newly created 1 and 0 classifiers for our counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1906,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master.to_csv('~/documents/case_per_pop_dummied_std_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.762227\n",
       "1    0.237773\n",
       "Name: case_per_pop, dtype: float64"
      ]
     },
     "execution_count": 1907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['case_per_pop'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using accuracy as our metric, our baseline is a score of .76227, which would occur if our model predicted an area to not be a coronavirus hotspot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1908,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key_0                                      0\n",
       "# stng/lt hosps,006-049 beds_x ratio       0\n",
       "neonatal intens cr, beds set up ratio      0\n",
       "total inpatient, beds set up_y ratio       0\n",
       "# stng/lt hosps,050-099 beds_x ratio       0\n",
       "                                        ... \n",
       "nuclear med, pc, hosp ft staff             0\n",
       "# hosp w/c.t. scanner                      0\n",
       "# hosp w/other long-term care              0\n",
       "beds_per_case                            103\n",
       "beds_per_case ratio                      103\n",
       "Length: 1699, dtype: int64"
      ]
     },
     "execution_count": 1908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1909,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = master.drop(columns = ['total_covid', 'deaths', 'county_x', 'county_y', 'state', 'id', \n",
    "                           'case_per_pop', 'beds_per_case', 'beds_per_case ratio', 'unnamed: 0_y', 'st_num',\n",
    "                           'cases', 'countyfips', 'key_0', 'county', 'case_per_pop ratio',\n",
    "                           'population ratio', 'st_num ratio', 'cases ratio', 'total_covid ratio',\n",
    "                           'deaths ratio', 'countyfips ratio'])\n",
    "y = master['case_per_pop']\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ss, y, random_state = 11, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1910,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([ #instantiate transformers and model\n",
    "    ('lr', LogisticRegression(random_state = 11))\n",
    "])\n",
    "\n",
    "# set hyperparameters\n",
    "\n",
    "pipe_params = {'lr__dual' : [True, False],\n",
    "               'lr__class_weight' : ['dict', 'balanced', None],\n",
    "              'lr__solver': ['liblinear', 'lbfgs', None],\n",
    "              'lr__penalty': ['l1'] # running this with the lasso and ridge techniques by applying a penalty, also running with no penalty\n",
    "              }\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid = pipe_params,\n",
    "                 cv = 5,\n",
    "                 scoring = 'accuracy',\n",
    "                 verbose = 2   \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1911,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.8s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.9s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.9s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.6s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.4s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.4s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   2.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   2.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.9s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:   19.8s finished\n"
     ]
    }
   ],
   "source": [
    "logreg_model = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1912,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg_train_score = logreg_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1913,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_test_score = logreg_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1914,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__class_weight': None,\n",
       " 'lr__dual': False,\n",
       " 'lr__penalty': 'l1',\n",
       " 'lr__solver': 'liblinear'}"
      ]
     },
     "execution_count": 1914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1915,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7770425255396596"
      ]
     },
     "execution_count": 1915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logreg_model.best_estimator_, X_ss, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1916,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-2.393127</td>\n",
       "      <td>estimate!!sex and age!!total population!!75 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>-1.402154</td>\n",
       "      <td>estimate!!citizen, voting age population!!citi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>-1.005262</td>\n",
       "      <td>unnamed: 0_y ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>-0.862214</td>\n",
       "      <td>estimate!!hispanic or latino and race!!total p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.808956</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.887311</td>\n",
       "      <td>estimate!!sex and age!!total population!!16 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.005249</td>\n",
       "      <td>estimate!!hispanic or latino and race!!total p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.237792</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>1.404032</td>\n",
       "      <td>estimate!!sex and age!!total population!!18 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.484136</td>\n",
       "      <td>estimate!!sex and age!!total population!!85 ye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1677 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficient                                            feature\n",
       "75     -2.393127  estimate!!sex and age!!total population!!75 to...\n",
       "893    -1.402154  estimate!!citizen, voting age population!!citi...\n",
       "927    -1.005262                                 unnamed: 0_y ratio\n",
       "878    -0.862214  estimate!!hispanic or latino and race!!total p...\n",
       "20     -0.808956  estimate!!race!!total population!!one race!!as...\n",
       "..           ...                                                ...\n",
       "915     0.887311  estimate!!sex and age!!total population!!16 ye...\n",
       "47      1.005249  estimate!!hispanic or latino and race!!total p...\n",
       "19      1.237792  estimate!!race!!total population!!one race!!as...\n",
       "923     1.404032  estimate!!sex and age!!total population!!18 ye...\n",
       "76      1.484136  estimate!!sex and age!!total population!!85 ye...\n",
       "\n",
       "[1677 rows x 2 columns]"
      ]
     },
     "execution_count": 1916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = logreg_model.best_estimator_.steps[0][1].coef_\n",
    "\n",
    "coef_df = pd.DataFrame(coefs).T\n",
    "\n",
    "coef_df['coefficients'] = list(X.columns)\n",
    "\n",
    "coef_df.rename(columns=({0: 'coefficient',\n",
    "                        'coefficients': 'feature'}), inplace=True)\n",
    "\n",
    "coef_df.sort_values(by = 'coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1917,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('lr',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l1', random_state=11,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 1917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1918,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8266838266838267"
      ]
     },
     "execution_count": 1918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1919,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8056628056628057"
      ]
     },
     "execution_count": 1919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1920,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df['abs'] = abs(coef_df['coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1921,
   "metadata": {},
   "outputs": [],
   "source": [
    "lose_these = coef_df.loc[coef_df['abs'] < 0.0000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1922,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lose_these.to_csv('~/documents/bad_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1923,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total_area',\n",
       " 'land_area',\n",
       " 'population',\n",
       " 'estimate!!race!!total population!!one race',\n",
       " 'estimate!!race!!total population!!two or more races',\n",
       " 'estimate!!race!!total population!!one race.1',\n",
       " 'estimate!!race!!total population!!one race!!white',\n",
       " 'estimate!!race!!total population!!one race!!black or african american',\n",
       " 'estimate!!race!!total population!!one race!!american indian and alaska native!!navajo tribal grouping',\n",
       " 'estimate!!race!!total population!!one race!!american indian and alaska native!!sioux tribal grouping',\n",
       " 'estimate!!race!!total population!!one race!!asian',\n",
       " 'estimate!!race!!total population!!one race!!asian!!chinese',\n",
       " 'estimate!!race!!total population!!one race!!asian!!other asian',\n",
       " 'estimate!!race!!total population!!one race!!native hawaiian and other pacific islander',\n",
       " 'estimate!!race!!total population!!one race!!native hawaiian and other pacific islander!!native hawaiian',\n",
       " 'estimate!!race!!total population!!one race!!some other race',\n",
       " 'estimate!!race!!total population!!two or more races.1',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!white',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!black or african american',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!american indian and alaska native',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!asian',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!native hawaiian and other pacific islander',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!some other race',\n",
       " 'estimate!!hispanic or latino and race!!total population',\n",
       " 'estimate!!hispanic or latino and race!!total population!!hispanic or latino (of any race)',\n",
       " 'estimate!!hispanic or latino and race!!total population!!hispanic or latino (of any race)!!mexican',\n",
       " 'estimate!!hispanic or latino and race!!total population!!hispanic or latino (of any race)!!puerto rican',\n",
       " 'estimate!!hispanic or latino and race!!total population!!hispanic or latino (of any race)!!other hispanic or latino',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!black or african american alone',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!asian alone',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!native hawaiian and other pacific islander alone',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!two or more races',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!two or more races!!two races excluding some other race, and three or more races',\n",
       " 'estimate!!total housing units',\n",
       " 'estimate!!citizen, voting age population!!citizen, 18 and over population',\n",
       " 'estimate!!citizen, voting age population!!citizen, 18 and over population!!male',\n",
       " 'estimate!!citizen, voting age population!!citizen, 18 and over population!!female',\n",
       " 'estimate!!sex and age!!total population',\n",
       " 'estimate!!sex and age!!total population!!male',\n",
       " 'estimate!!sex and age!!total population!!female',\n",
       " 'estimate!!sex and age!!total population!!under 5 years',\n",
       " 'estimate!!sex and age!!total population!!5 to 9 years',\n",
       " 'estimate!!sex and age!!total population!!10 to 14 years',\n",
       " 'estimate!!sex and age!!total population!!15 to 19 years',\n",
       " 'estimate!!sex and age!!total population!!20 to 24 years',\n",
       " 'estimate!!sex and age!!total population!!25 to 34 years',\n",
       " 'estimate!!sex and age!!total population!!35 to 44 years',\n",
       " 'estimate!!sex and age!!total population!!45 to 54 years',\n",
       " 'estimate!!sex and age!!total population!!55 to 59 years',\n",
       " 'estimate!!sex and age!!total population!!65 to 74 years',\n",
       " 'estimate!!sex and age!!total population!!under 18 years',\n",
       " 'estimate!!sex and age!!total population!!16 years and over',\n",
       " 'estimate!!sex and age!!total population!!18 years and over',\n",
       " 'estimate!!sex and age!!total population!!21 years and over',\n",
       " 'estimate!!sex and age!!total population!!62 years and over',\n",
       " 'estimate!!sex and age!!total population!!65 years and over',\n",
       " 'estimate!!sex and age!!total population!!18 years and over.1',\n",
       " 'estimate!!sex and age!!total population!!18 years and over!!male',\n",
       " 'estimate!!sex and age!!total population!!18 years and over!!female',\n",
       " 'estimate!!sex and age!!total population!!65 years and over.1',\n",
       " 'estimate!!sex and age!!total population!!65 years and over!!male',\n",
       " 'estimate!!sex and age!!total population!!65 years and over!!female',\n",
       " 'colon/rectal srg, total ptn cr',\n",
       " 'ophthalmolgy, total patn care',\n",
       " \"m.d.'s, total other_x\",\n",
       " 'aerospace med, total',\n",
       " 'forensic path, total',\n",
       " \"m.d.'s, total ptn care non-fed_x\",\n",
       " 'public health, total patnt care',\n",
       " 'child psych, total patn care',\n",
       " 'medical genetics, total',\n",
       " 'surgical specs, total, 35-44',\n",
       " \"total d.o.'s, total non-fed\",\n",
       " \"total m.d.'s, female_x\",\n",
       " \"total d.o.'s, total federal\",\n",
       " 'nursing home beds, total hosp_x',\n",
       " \"do's, orthopedic surg, total_x\",\n",
       " 'medical specs, total, 35-44',\n",
       " 'other specs, total, < 35',\n",
       " 'dent, total male, priv pract',\n",
       " \"total d.o.'s, male\",\n",
       " 'dentists, total, priv pract, ft',\n",
       " 'gnrl int med, total patn care',\n",
       " \"total d.o.'s, 55-64\",\n",
       " 'path,anat/clinic,total',\n",
       " 'transplant surg, total',\n",
       " \"do's, gen pract, total_x\",\n",
       " 'ped subspecs, total',\n",
       " \"do's, emergency med, total_x\",\n",
       " 'psychiatry, total patient care_x',\n",
       " \"total rep facility exp (1000's)\",\n",
       " \"md's, gen pract, total\",\n",
       " 'psychiatry, total_x',\n",
       " 'other specs, total patnt care',\n",
       " 'dentists, total, priv pract, pt',\n",
       " 'total inpatient, beds set up_x',\n",
       " 'gastroenterology, total',\n",
       " 'urology, total patient care',\n",
       " \"do's, ped subspecs, total_x\",\n",
       " 'plastic surg, total',\n",
       " \"do's inactive, total_x\",\n",
       " 'total medicare inpatient days',\n",
       " 'ped subspecs, total patn care',\n",
       " \"md's, fam med subspec, total\",\n",
       " 'public health, total',\n",
       " \"do's, anesthesiolgy, total_x\",\n",
       " 'surg specs tot, total',\n",
       " \"total m.d.'s, 45-54_x\",\n",
       " 'medical specs, total, 55-64',\n",
       " 'dermatology, total',\n",
       " 'cardiovas dis, total patn care',\n",
       " 'dentists, total priv practice',\n",
       " 'urology, total',\n",
       " \"do's, gnrl int med, total_x\",\n",
       " 'diag radiolgy, total',\n",
       " 'int med subspecs, total',\n",
       " \"do's, ob-gyn, general, total_x\",\n",
       " \"md's, gen pract, total ptn care\",\n",
       " \"total d.o.'s, 75 +\",\n",
       " \"total m.d.'s, 55-64_x\",\n",
       " 'radiology, total',\n",
       " 'phys med/rehab, total patnt cr',\n",
       " \"d.o.'s, total ptn care non-fed\",\n",
       " 'vascular med, total',\n",
       " 'emergency med, total',\n",
       " 'medical specs, total, 65-74',\n",
       " '# surgical operations, total',\n",
       " 'gen prev med, total patnt care',\n",
       " \"do's, gen pract, total ptn care_x\",\n",
       " \"total d.o.'s, < 35\",\n",
       " 'neurology, total',\n",
       " 'radiology, total patient care',\n",
       " \"do's, fam med subspec, total_x\",\n",
       " 'vascular med, total patn care',\n",
       " 'other specs, total, 45-54',\n",
       " 'genrl surg, total patient care',\n",
       " \"total m.d.'s, < 35_x\",\n",
       " 'other specs, total, 75 +',\n",
       " 'other specs, total, 35-44',\n",
       " \"total d.o.'s, 65-74\",\n",
       " \"total d.o.'s, 35-44\",\n",
       " \"total m.d.'s, total non-fed_x\",\n",
       " \"total d.o.'s, female\",\n",
       " 'surgical specs, total, 55-64',\n",
       " 'ophthalmolgy, total',\n",
       " 'medical specs, total, 75 +',\n",
       " 'cardiovas dis, total',\n",
       " 'licensed beds, total hospital_x',\n",
       " \"md's, fam med gen, total\",\n",
       " 'surgical specs, total, 65-74',\n",
       " \"d.o.'s, total pc, hosp ft staff_x\",\n",
       " 'ob-gyn, general, total',\n",
       " 'total active d.o.s non-federal',\n",
       " 'nuclear med, total patient care',\n",
       " \"total m.d.'s, 75 +_x\",\n",
       " \"do's, genrl surg, total_x\",\n",
       " 'phys med/rehab, total',\n",
       " 'colon/rectal srg, total',\n",
       " 'pediatrics, general, total',\n",
       " 'plastic surg, total patn care',\n",
       " 'dent, total female, priv pract',\n",
       " 'surgical specs, total, 75 +',\n",
       " 'other spec, tot, total ptn care',\n",
       " 'rad oncology, total',\n",
       " 'gen prev med, total',\n",
       " \"m.d.'s, total oth prof activity_x\",\n",
       " 'dentists, total prof active',\n",
       " 'other specs, total, 65-74',\n",
       " \"do's, ob-gyn subspecs, total_x\",\n",
       " \"total m.d.'s, male_x\",\n",
       " 'med spec tot, total',\n",
       " \"do's, phys med/rehab, total_x\",\n",
       " \"total m.d.'s, 65-74_x\",\n",
       " \"md's inactive, total\",\n",
       " 'rad oncology, total patnt care',\n",
       " 'child psych, total',\n",
       " '# nhsc total active sites',\n",
       " 'thoracic surg, total patn care',\n",
       " \"do's, psychiatry, total_x\",\n",
       " \"total m.d.'s, tot non-fed & fed_x\",\n",
       " \"do's, other specs, total_x\",\n",
       " \"md's not classified, total\",\n",
       " 'skilled nurs fac total beds_x',\n",
       " 'allergy & immunology, total',\n",
       " 'med spec tot, total patn care',\n",
       " 'nuclear med, total',\n",
       " 'orthopedic surg, total',\n",
       " 'aerospace med, total patn care',\n",
       " 'total deaths',\n",
       " 'thoracic surg, total',\n",
       " \"total d.o.'s, tot non-fed & fed\",\n",
       " 'surg specs tot, total patn care',\n",
       " \"m.d.'s, total pc, hosp ft staff_x\",\n",
       " 'anesthesiolgy, total',\n",
       " 'ped cardiolgy, total patn care',\n",
       " 'neurolgcal surg, total',\n",
       " 'ob-gyn, gen, total patient care',\n",
       " 'anesthesiolgy, total patn care',\n",
       " 'ob-gyn subspecs, total',\n",
       " 'surgical specs, total, < 35',\n",
       " 'otolaryngolgy, total ptn care',\n",
       " 'forensic path, total patn care',\n",
       " 'genrl surg, total',\n",
       " 'gastroenterology, total ptn cr',\n",
       " 'general internal med, total',\n",
       " 'occupat med, total',\n",
       " 'occupat med, total patnt care',\n",
       " \"d.o.'s, total oth prof activity\",\n",
       " 'medical specs, total, < 35',\n",
       " 'medical specs, total, 45-54',\n",
       " \"m.d.'s, total, inactive_x\",\n",
       " 'dermatology, total patnt care',\n",
       " 'emergency med, total patn care',\n",
       " \"total d.o.'s, 45-54\",\n",
       " 'ped cardiolgy, total',\n",
       " 'orthopedic surg, total ptn care',\n",
       " \"do's not classified, total_x\",\n",
       " 'neurolgcal surg, total ptn care',\n",
       " \"md's, total gen pract, total\",\n",
       " 'pulmonary dis, total patn care',\n",
       " 'other specs, total, 55-64',\n",
       " 'other specs, total',\n",
       " 'diag radiolgy, total patn care',\n",
       " 'total active m.d.s non-federal_x',\n",
       " 'other spec, tot, total',\n",
       " 'surgical specs, total, 45-54',\n",
       " \"do's, int med subspecs, total_x\",\n",
       " 'total active d.o.s federal',\n",
       " 'pulmonary dis, total',\n",
       " 'nursing facilities total beds_x',\n",
       " 'otolaryngolgy, total',\n",
       " \"total m.d.'s, 35-44_x\",\n",
       " 'neurology, total patient care',\n",
       " \"do's, fam med gen, total_x\",\n",
       " 'short term non-gen hosp beds_x',\n",
       " 'oth special care, beds set up',\n",
       " 'psychiatric care, beds set up',\n",
       " \"veterans' hospital beds_x\",\n",
       " 'nursing home beds, st gen hosp_x',\n",
       " 'nursing facilities cert beds_x',\n",
       " 'intermediate care, beds set up',\n",
       " 'hospital beds_x',\n",
       " 'gen med/surg, ped, beds set up',\n",
       " 'licensed beds, long term hosp_x',\n",
       " 'nursing home beds, total hosp_y',\n",
       " 'nursing home beds, stng hosp_x',\n",
       " 'long term hosp beds_x',\n",
       " '# veteran hosp, 200-299 beds_x',\n",
       " 'skilled nurs fac certified beds_x',\n",
       " '# stng/lt hosps,050-099 beds_x',\n",
       " 'total inpatient, beds set up_y',\n",
       " 'neonatal intens cr, beds set up',\n",
       " '# stng/lt hosps,006-049 beds_x',\n",
       " 'licensed nurs home beds, stng_x',\n",
       " 'other care, beds set up',\n",
       " '# veteran hosp, 100-199 beds_x',\n",
       " '# veteran hosp, 050-099 beds_x',\n",
       " '# st gen hosp, 006-049 beds_x',\n",
       " 'cardiac intens cr, beds set up',\n",
       " 'neonat intermed cr, beds set up',\n",
       " '# stng/lt hosps,200-299 beds_x',\n",
       " 'licensed beds, total hospital_y',\n",
       " '# st gen hosp, 200-299 beds_x',\n",
       " '# st gen hosp, 100-199 beds_x',\n",
       " 'med/surg intens cr, beds set up',\n",
       " 'short term general hosp beds_x',\n",
       " 'acute lt care, beds set up',\n",
       " 'licensed beds, short term hosp_x',\n",
       " 'obstetrics care, beds set up',\n",
       " 'licensed nurs home beds, lt_x',\n",
       " 'skilled nurs fac total beds_y',\n",
       " 'licensed nursing home beds_x',\n",
       " 'licensed nurs home beds, stgen_x',\n",
       " '# stng/lt hosps,100-199 beds_x',\n",
       " '# st gen hosp, 300+ beds_x',\n",
       " '# st gen hosp, 050-099 beds_x',\n",
       " 'skilled nurs care, beds set up_x',\n",
       " '# veteran hosp, 006-049 beds_x',\n",
       " '# veteran hosp, 300+ beds_x',\n",
       " 'burn care, beds set up',\n",
       " 'nursing facilities total beds_y',\n",
       " 'other lt care, beds set up',\n",
       " 'short term community hosp beds_x',\n",
       " \"m.d.'s, total other_y\",\n",
       " \"m.d.'s, total ptn care non-fed_y\",\n",
       " \"total m.d.'s, female_y\",\n",
       " 'tot active m.d.s non-fed & fed',\n",
       " \"total m.d.'s, 45-54_y\",\n",
       " \"total m.d.'s, 55-64_y\",\n",
       " \"total m.d.'s, < 35_y\",\n",
       " \"total m.d.'s, total non-fed_y\",\n",
       " \"total m.d.'s, 75 +_y\",\n",
       " \"m.d.'s, total oth prof activity_y\",\n",
       " \"total m.d.'s, male_y\",\n",
       " \"total m.d.'s, 65-74_y\",\n",
       " \"total m.d.'s, tot non-fed & fed_y\",\n",
       " \"m.d.'s, total pc, hosp ft staff_y\",\n",
       " \"m.d.'s, total, inactive_y\",\n",
       " 'total active m.d.s non-federal_y',\n",
       " \"total m.d.'s, 35-44_y\",\n",
       " 'public health, pc, hosp ft stf',\n",
       " '# hosp w/assistv technology ctr',\n",
       " '# hosp w/meals on wheels',\n",
       " 'short term non-gen hosp beds_y',\n",
       " '# hosp w/ambulance services',\n",
       " \"veterans' hospital beds_y\",\n",
       " 'preventable hospital stays rate',\n",
       " 'other specs, pc, hosp ft staff',\n",
       " '# hosp w/residency training',\n",
       " 'nursing home beds, st gen hosp_y',\n",
       " '# hosp w/medicare certification',\n",
       " '# hosp participating in network',\n",
       " '# hosp w/psych outpatient serv',\n",
       " 'dist hosp by 05 - 14 services',\n",
       " 'int med subspecs, pc, hosp res',\n",
       " 'ophthalmolgy, pc, hosp resdnts',\n",
       " 'radiology, pc, hosp ft staff',\n",
       " '# critical access hospitals',\n",
       " '# hosp w/indigent care clinic',\n",
       " 'nurs home admissions,stgen hosp_x',\n",
       " '# hosp w/heart transplant',\n",
       " 'hospital beds_y',\n",
       " 'ob-gyn subspecs,pc,hosp resdnt',\n",
       " '# hosp w/patient repr services',\n",
       " 'pulmonary dis, pc, hosp resdnt',\n",
       " 'licensed beds, long term hosp_y',\n",
       " 'thoracic surg, pc, hosp resdnt',\n",
       " '# hosp w/medical/surg intens cr',\n",
       " 'ob-gyn subspecs,pc,hosp ft stf',\n",
       " '# hosp w/shaped beam rad system',\n",
       " '# hosp w/dental services',\n",
       " '# rehabilitation lt hosps',\n",
       " 'nursing home beds, stng hosp_y',\n",
       " 'dermatology, pc, hosp ft staff',\n",
       " 'occupat med, pc, hosp ft staff',\n",
       " '# hosp w/lung transplant',\n",
       " '# hosp w/child wellness program',\n",
       " '# hosp w/blood donor center',\n",
       " 'gen int med, pc, hosp ft staff',\n",
       " '# psychiatric lt hosps',\n",
       " '# hosp w/tobacco treatment serv',\n",
       " 'outpat visits in long term hosp',\n",
       " 'allergy&immunlgy,pc,hosp ft stf',\n",
       " 'int med subspecs,pc,hosp ft stf',\n",
       " 'other med, pc, hosp ft staff',\n",
       " '# short term general hosps',\n",
       " '# hosp w/arthritis treatmt cntr',\n",
       " 'long term hosp beds_y',\n",
       " '# veteran hosp, 200-299 beds_y',\n",
       " '# hosp w/adult day care program',\n",
       " '# hosp w/optical colonoscopy',\n",
       " 'oth oth spec, pc, hosp ft staff',\n",
       " 'neurolgcal surg, pc, hosp res',\n",
       " 'cert nurse midwvs,ft hosp/med_x',\n",
       " 'cardiovas dis, pc, hosp resdnt',\n",
       " '# hosp w/support groups',\n",
       " '# hosp w/home health services',\n",
       " '# hosp w/esoph impedance study',\n",
       " '# hosp w/assisted living',\n",
       " '# hosp w/burn care',\n",
       " 'orthopedic surg, pc, hosp res',\n",
       " '# hosp w/geriatric services',\n",
       " '# hosp w/aprn/physician assist',\n",
       " '# stng/lt hosps,050-099 beds_y',\n",
       " '# hosp w/pain management pgm',\n",
       " 'emergency med, pc, hosp ft stf',\n",
       " 'phys med/rehab, pc, hosp ft stf',\n",
       " 'otolaryngolgy, pc, hosp ft stf',\n",
       " '# hosp w/pediatric intens care',\n",
       " 'ped subspecs, pc, hosp ft staff',\n",
       " '# hosp w/alc/chem depdnt op ser',\n",
       " 'dist hosp by 25+ services',\n",
       " 'psychiatry, pc, hosp ft staff_x',\n",
       " '# hosp w/physical rehab op serv',\n",
       " 'rad oncology, pc, hosp ft staff',\n",
       " 'dist hosp by 15 - 24 services',\n",
       " '# hosp w/pediatric emerg depart',\n",
       " \"# children's psych lt hosps\",\n",
       " '# hosp w/rural health clinic',\n",
       " '# hosp w/primary care aprn/pas',\n",
       " '# hosp w/orthopedic services',\n",
       " 'pulmonary dis, pc, hosp ft stf',\n",
       " '# hosp w/teen outreach services',\n",
       " 'ped cardiolgy, pc, hosp resdnt',\n",
       " 'gastroenterology, pc, hosp res',\n",
       " 'inpatient days in va hosps',\n",
       " '# hosp w/anesth svc aprn/pas',\n",
       " \"# veterans' hospitals\",\n",
       " 'nuclear med, pc, hosp residnts',\n",
       " '# hosp w/nutrition programs',\n",
       " '# hosp w/volunteer serv dept',\n",
       " '# hosp w/gen med/surg care, ped',\n",
       " 'ophthalmolgy, pc, hosp ft staff',\n",
       " \"md's,tot gen prac,pc,hosp res\",\n",
       " 'genrl surg, pc, hosp ft staff',\n",
       " 'dist hosp by 00 - 04 services',\n",
       " '# hosp w/auxiliary services',\n",
       " 'phys med/rehab, pc, hosp resdnt',\n",
       " '# hosp w/patient education cntr',\n",
       " '# hosp w/neonatal intens care',\n",
       " 'transplant surg, pc,hosp ft stf',\n",
       " 'other surg, pc, hosp ft staff',\n",
       " 'anesthesiolgy, pc, hosp ft stf',\n",
       " 'medical genetics,pc,hosp ft stf',\n",
       " '# hosp w/chiropractic services',\n",
       " '# stng/lt hosps,006-049 beds_y',\n",
       " '# hosp w/hiv-aids services',\n",
       " '# hosp w/psychiatric care',\n",
       " '# hosp w/robot-asst walk therap',\n",
       " 'path,anat/clinic,pc,hosp resdnt',\n",
       " '# hosp w/emergency department',\n",
       " '# veteran hosp, 100-199 beds_y',\n",
       " '# hosp w/physical rehab care',\n",
       " '# hosp w/hemodialysis',\n",
       " '# veteran hosp, 050-099 beds_y',\n",
       " '# hosp w/mobile health services',\n",
       " '# st gen hosp, 006-049 beds_y',\n",
       " 'inpatient days in st gen hosp',\n",
       " '# hosp w/virtual colonoscopy',\n",
       " '# hosp w/ip palliative cre unit',\n",
       " 'thoracic surg, pc, hosp ft stf',\n",
       " '# hosp w/intermediate nurs care_x',\n",
       " '# hosp w/sleep center',\n",
       " '# gen medical/surgical lt hosps',\n",
       " '# hosp w/obstetric care',\n",
       " 'short term community hosp admis',\n",
       " '# hosp w/intraoperative mri',\n",
       " 'inptn days in stng/lt hosp',\n",
       " '# hosp w/skilled nursing care_x',\n",
       " '# hosp w/case management',\n",
       " '# hosp w/hospice',\n",
       " '# hosp w/alc/drug abuse ip care',\n",
       " '# hosp w/medical school affiln',\n",
       " '# hosp w/wound mngmnt services',\n",
       " '# stng/lt hosps,200-299 beds_y',\n",
       " '# hosp w/fertility clinic',\n",
       " '# hosp w/patient ctrl analgesia',\n",
       " 'cardiovas dis, pc, hosp ft stf',\n",
       " '# hosp w/immunization program',\n",
       " 'aerospace med, pc, hosp resdnt',\n",
       " 'licensed beds, total hospital',\n",
       " '# hosp w/psych consl/liaisn ser',\n",
       " 'short term gen hosp admissions',\n",
       " \"d.o.'s, total pc, hosp ft staff_y\",\n",
       " '# hosp w/neurological services',\n",
       " 'transplant surg, pc,hosp resdnt',\n",
       " 'neurology, pc, hosp ft staff',\n",
       " '# hosp w/health fair',\n",
       " 'allergy&immunology,hosp resdnt',\n",
       " '# hosp w/adult diagnostic cath',\n",
       " '# hosp w/cardiac intensive care',\n",
       " '# hosp w/psych resdntl ped trmt',\n",
       " '# st gen hosp, 200-299 beds_y',\n",
       " 'urology, pc, hosp ft staff',\n",
       " '# chronic disease lt hosps',\n",
       " 'otolaryngolgy, pc, hosp resdnt',\n",
       " '# st gen hosp, 100-199 beds_y',\n",
       " 'dist hosp by 00 - 39% util rate',\n",
       " 'short term general hosp beds_y',\n",
       " '# hosp w/adult cardiology serv',\n",
       " 'surg specs tot, pc, hosp resdnt',\n",
       " 'anesthesiolgy, pc, hosp resdnt',\n",
       " 'ped cardiolgy, pc, hosp ft stf',\n",
       " '# hosp w/breast cancer scrn/mam',\n",
       " '# hosp w/extracorporeal shock',\n",
       " 'medcre benef hosp readmiss rate',\n",
       " '# hosp w/telehealth stroke care',\n",
       " 'vascular med, pc, hosp ft stf',\n",
       " 'forensic path, pc, hosp resdnt',\n",
       " '# hosp w/ambulatory surgery ctr_x',\n",
       " '# hosp w/ercp',\n",
       " '# hosp w/kidney transplant',\n",
       " 'licensed beds, short term hosp_y',\n",
       " '# hosp w/psych pediatric serv',\n",
       " '# hosp w/positron emiss tom/ct',\n",
       " '# hosp w/palliative care pgm',\n",
       " '# hosp w/telehealth eicu',\n",
       " '# hosp w/community outreach',\n",
       " 'vascular med, pc, hosp resdnt',\n",
       " '# hosp w/ped cardiac surgery_x',\n",
       " '# hosp w/cardiac rehabilitation',\n",
       " '# psychiatric short term hosps',\n",
       " '# hosp w/community health educ',\n",
       " 'diag radiolgy, pc, hosp ft stf',\n",
       " '# hosp w/stereotactic radiosurg',\n",
       " '# hosp w/bariart/wgt cntrl serv',\n",
       " '# hosp w/image-guided rad ther',\n",
       " '# hosp w/oncology services',\n",
       " '# hosp w/fitness center',\n",
       " '# acute long-term care st hosps',\n",
       " 'outpat visits in st gen hosp',\n",
       " \"m.d.'s, total pc, hosp ft staff\",\n",
       " '# hosp w/freestandng outpat ctr',\n",
       " 'colon/rectal srg, pc, hosp res',\n",
       " '# hosp w/outpatient surgery_x',\n",
       " 'stng/lt, hosp admissions',\n",
       " 'medical genetics,pc,hosp resdnt',\n",
       " '# hosp w/liver transplant',\n",
       " '#hosp w/genetic test/counseling',\n",
       " '# hosp w/chemotherapy',\n",
       " '# hosp w/psych intensive op ser',\n",
       " '# hosp w/oth transplant service',\n",
       " 'path,anat/clinic,pc,hosp ft stf',\n",
       " 'nurs home admissions, tot hosp_x',\n",
       " \"# children's psych st hosps\",\n",
       " \"veterans' hospital admissions\",\n",
       " '# hosp w/ling/translation serv',\n",
       " '# hosp w/proton therapy',\n",
       " '# hosp w/certified trauma cntr',\n",
       " '# hosp w/endoscopic ultrasound',\n",
       " '# hosp w/tissue transplant',\n",
       " 'child psych, pc, hosp ft staff',\n",
       " '# long term hospitals',\n",
       " '# hosp w/urgent care center',\n",
       " '# hosp w/c.t. scanner',\n",
       " 'nuclear med, pc, hosp ft staff',\n",
       " '# hosp w/swing bed services',\n",
       " '# hosp w/diag radioisotope fac',\n",
       " 'other spec, tot, pc, hosp res',\n",
       " 'forensic path, pc, hosp ft stf',\n",
       " '# stng/lt hosps,100-199 beds_y',\n",
       " '# hosp w/acute long-term care',\n",
       " '# st gen hosp, 300+ beds_y',\n",
       " '# hosp w/gen med/surg cr, adult',\n",
       " '# st gen hosp, 050-099 beds_y',\n",
       " '# hosp w/other long-term care',\n",
       " 'emergency med, pc, hosp resdnt',\n",
       " '# hosp w/electrodiagnostic serv',\n",
       " 'gnrl int med, pc, hosp ft staff',\n",
       " '# critical access st gen hosps',\n",
       " '# hosp w/psych geriatric serv',\n",
       " 'hospital admissions',\n",
       " 'plastic surg, pc, hosp ft staff',\n",
       " 'aerospace med, pc, hosp ft stf',\n",
       " '# hosp w/other care',\n",
       " 'dist hosp by 80+% util rate',\n",
       " '# rehabilitation st hosps',\n",
       " '# hosp w/sports medicine',\n",
       " 'surg specs tot, pc, hosp ft stf',\n",
       " '# hosp w/computer asst orth srg',\n",
       " 'dist hosp by 40 - 59% util rate',\n",
       " '# hosp w/other intensive care',\n",
       " '# hosp w/primary care dept',\n",
       " '# hosp w/occupational hlth serv',\n",
       " 'ob-gyn subspecs,pc,hosp residnt',\n",
       " 'pediatrics,gen,pc,hosp ft staff',\n",
       " 'ob-gyn, gen, pc, hosp ft staff',\n",
       " '# hosp w/psych emergency serv',\n",
       " 'outpatient visits in va hosp',\n",
       " '# veteran hosp, 006-049 beds_y',\n",
       " '# hosp w/simulated rehab enviro',\n",
       " '# hosp w/chapl/pastor care serv',\n",
       " '# hosp w/other special care',\n",
       " \"# hosp w/women's hlth cntr/serv\",\n",
       " '# hosp w/hospitalists care',\n",
       " '# veteran hosp, 300+ beds_y',\n",
       " '# hosp w/alc/chem depdnt ped sv',\n",
       " '# hosp w/transport to hlth serv',\n",
       " '# hosp w/psych education serv',\n",
       " '# hosp w/ablat of barrets esoph',\n",
       " 'diag radiolgy, pc, hosp resdnt',\n",
       " '# hosp w/adult cardiac surgery_x',\n",
       " '# hosp w/neonatal intermed care',\n",
       " '# hosp w/health screenings',\n",
       " 'gen prev med, pc, hosp ft staff',\n",
       " 'dist hosp by 60 - 79% util rate',\n",
       " '# hosp w/ped diagnostic cath',\n",
       " '# hosp w/ultrasound',\n",
       " 'public health, pc, hosp residnt',\n",
       " '# acute long-term care lt hosps',\n",
       " '# short term non-general hosps',\n",
       " '# hospices',\n",
       " '# hosp w/mag resonance imaging',\n",
       " 'med spec tot, pc, hosp ft staff',\n",
       " '# hosp w/robotic surgery_x',\n",
       " '# hosp w/ped cardiac electrophy',\n",
       " '# hosp w/enabling services',\n",
       " 'short term community hosp beds_y',\n",
       " '# hosp w/alzheimer center',\n",
       " '# hosp w/crisis prevention',\n",
       " 'physician assistants, < 35',\n",
       " 'physician assistants,other spec',\n",
       " 'aprn/physician assistants, pt',\n",
       " 'aprn/physician assistants, ft',\n",
       " 'physician assistants, inactive',\n",
       " 'physician assistants',\n",
       " 'physician assistants, 35-44',\n",
       " 'physician assistants, 45-54',\n",
       " 'physician assistants, active',\n",
       " 'physician assistants, 65 +',\n",
       " 'physician assistants, unk spec',\n",
       " 'physician assistants, female',\n",
       " 'physician assistants, pt',\n",
       " 'physician assistants, surg spec',\n",
       " 'physician assistants, male',\n",
       " 'physician assistants, ft',\n",
       " 'physician assistants, prim care',\n",
       " 'physician assistants w/npi',\n",
       " 'physician assistants, 55-64',\n",
       " 'advanced practice reg nurses,ft_x',\n",
       " 'registered nurses, part-time_x',\n",
       " 'registered nurses, vacancies_x',\n",
       " 'registered nurses, full-time_x',\n",
       " 'cert nurse midwvs,ft hosp/med_y',\n",
       " 'cert regist nurse anesth, 45-54_x',\n",
       " 'cert nurse midwvs,retrd/not emp_x',\n",
       " 'cert regist nurse anesth, male_x',\n",
       " 'cert nurse midwvs,ft mid/physpr_x',\n",
       " 'cert regist nurse anesth, < 35_x',\n",
       " 'advanced practice reg nurses,ft_y',\n",
       " 'cert nurse midwvs,ft unk emptyp_x',\n",
       " 'adv practice regist nurse w/npi_x',\n",
       " 'cert regist nurse anesth, 65 +_x',\n",
       " 'registered nurses, part-time_y',\n",
       " 'certified nurse midwives_x',\n",
       " 'registered nurses, vacancies_y',\n",
       " 'registered nurses, full-time_y',\n",
       " 'adv pract nurse midwives w/npi_x',\n",
       " 'cert regist nurse anesth, 35-44_x',\n",
       " 'cert regist nurse anesth,female_x',\n",
       " 'cert regist nurse anesth, 55-64_x',\n",
       " 'certified nurse midwives, pt_x',\n",
       " 'cert regist nurse anesthetists_x',\n",
       " 'nurse practitioners, male w/npi_x',\n",
       " 'certified nurse midwives, ft_x',\n",
       " 'clinical nurse specialist w/npi_x',\n",
       " 'nurse practitioners w/npi_x',\n",
       " 'nurse practitioners, fmle w/npi_x',\n",
       " 'cert nurse midwvs,ft oth emptyp_x',\n",
       " 'nurse practitioners_x',\n",
       " \"do's, other specs, tot patnt cr\",\n",
       " \"do's, genrl surg, tot ptnt care\",\n",
       " \"do's, emergency med, tot ptn cr\",\n",
       " \"do's, orthopedic surg, total_y\",\n",
       " \"do's, pediatrics,gen,tot ptn cr\",\n",
       " \"do's, gen pract, total_y\",\n",
       " \"do's, psychiatry, tot patnt cr_x\",\n",
       " \"do's, intmed subspcs,tot ptn cr\",\n",
       " \"do's, emergency med, total_y\",\n",
       " \"do's, orthopedic srg,tot ptn cr\",\n",
       " \"do's, ped subspecs, total_y\",\n",
       " \"do's inactive, total_y\",\n",
       " \"do's,primary care, patient care\",\n",
       " \"do's, anesthesiolgy, total_y\",\n",
       " \"do's, inactive, 45-54\",\n",
       " \"do's, pediatrics, general, tot\",\n",
       " \"do's, gnrl int med, total_y\",\n",
       " \"do's, ped subspecs, tot patn cr\",\n",
       " \"do's, ob-gyn, general, total_y\",\n",
       " \"do's, anesthesiolgy, tot ptn cr\",\n",
       " \"do's, phys med/rehab,tot ptn cr\",\n",
       " \"do's, ob-gyn, gen, tot patn cr\",\n",
       " \"do's, fam med gen, tot ptn cr\",\n",
       " \"do's, gen pract, total ptn care_y\",\n",
       " \"do's, fam med subspec, total_y\",\n",
       " \"do's, inactive, 65-74\",\n",
       " \"do's, inactive, male\",\n",
       " \"do's, genrl surg, total_y\",\n",
       " \"do's, inactive, 55-64\",\n",
       " \"do's, ob-gyn subspecs, total_y\",\n",
       " \"do's, phys med/rehab, total_y\",\n",
       " \"do's, ob-gyn subspcs,tot ptn cr\",\n",
       " \"do's, psychiatry, total_y\",\n",
       " \"do's, other specs, total_y\",\n",
       " \"do's, inactive, < 35\",\n",
       " \"do's, inactive, 75 +\",\n",
       " \"do's, inactive, female\",\n",
       " \"do's not classified, total_y\",\n",
       " \"do's, gnrl int med, tot ptn cr\",\n",
       " \"do's, inactive, 35-44\",\n",
       " \"do's, int med subspecs, total_y\",\n",
       " \"do's, fam med subsp,tot ptn cr\",\n",
       " \"do's, fam med gen, total_y\",\n",
       " 'plastic surgery, 55-64',\n",
       " 'orthopedic surgery, 35-44',\n",
       " 'general surgery, 35-44',\n",
       " 'thoracic surgery, 55-64',\n",
       " 'colon & rectal surgery, < 35',\n",
       " 'colon & rectal surgery, 75 +',\n",
       " 'general surgery, 75 +',\n",
       " 'orthopedic surgery, 45-54',\n",
       " 'colon & rectal surgery, 45-54',\n",
       " 'thoracic surgery, 75 +',\n",
       " 'orthopedic surgery, 75 +',\n",
       " 'plastic surgery, 75 +',\n",
       " 'plastic surgery, 35-44',\n",
       " 'thoracic surgery, < 35',\n",
       " 'colon & rectal surgery, 55-64',\n",
       " 'orthopedic surgery, 65-74',\n",
       " 'neurological surgery, 65-74',\n",
       " 'thoracic surgery, 45-54',\n",
       " 'transplantation surgery, 55-64',\n",
       " 'plastic surgery, 65-74',\n",
       " 'transplantation surgery, 35-44',\n",
       " 'plastic surgery, 45-54',\n",
       " '# hosp w/ambulatory surgery ctr_y',\n",
       " '# ambulatory surgery centers',\n",
       " 'transplantation surgery, 45-54',\n",
       " 'transplantation surgery, < 35',\n",
       " '# hosp w/ped cardiac surgery_y',\n",
       " 'neurological surgery, 45-54',\n",
       " 'neurological surgery, < 35',\n",
       " 'general surgery, 65-74',\n",
       " 'colon & rectal surgery, 35-44',\n",
       " 'colon & rectal surgery, 65-74',\n",
       " 'thoracic surgery, 35-44',\n",
       " '# hosp w/outpatient surgery_y',\n",
       " 'general surgery, 55-64',\n",
       " 'general surgery, < 35',\n",
       " 'neurological surgery, 75 +',\n",
       " 'general surgery, 45-54',\n",
       " 'orthopedic surgery, < 35',\n",
       " 'orthopedic surgery, 55-64',\n",
       " 'plastic surgery, < 35',\n",
       " 'neurological surgery, 55-64',\n",
       " 'thoracic surgery, 65-74',\n",
       " 'transplantation surgery, 75 +',\n",
       " '# hosp w/adult cardiac surgery_y',\n",
       " 'neurological surgery, 35-44',\n",
       " 'transplantation surgery, 65-74',\n",
       " '# hosp w/robotic surgery_y',\n",
       " 'respiratory therapists, ft',\n",
       " 'respiratory therapists, pt',\n",
       " 'psychiatry, 45-54',\n",
       " \"do's, psychiatry, tot patnt cr_y\",\n",
       " 'psychiatry, total patient care_y',\n",
       " 'child psychiatry, 35-44',\n",
       " 'psychiatry, total_y',\n",
       " 'child psychiatry, 75 +',\n",
       " 'child psychiatry, < 35',\n",
       " 'psychiatry, pc, hosp ft staff_y',\n",
       " 'psychiatry, 65-74',\n",
       " 'psychiatry, 55-64',\n",
       " 'child psychiatry, 55-64',\n",
       " 'psychiatry, < 35',\n",
       " 'child psychiatry, 45-54',\n",
       " 'psychiatry, 75 +',\n",
       " 'psychiatry, other prof activity',\n",
       " \"do's, psychiatry, total\",\n",
       " 'psychiatry, 35-44',\n",
       " 'child psychiatry, 65-74',\n",
       " 'psychiatry, other',\n",
       " 'nursing home beds, st gen hosp',\n",
       " 'nursing facilities cert beds_y',\n",
       " 'nurs home admissions,stgen hosp_y',\n",
       " 'clin nurs specialist,fmle w/npi',\n",
       " 'nursing home beds, stng hosp',\n",
       " 'nurs home inptn days, stng/lt',\n",
       " 'skilled nurs fac certified beds_y',\n",
       " 'cert nurse midwvs,ft hosp/med',\n",
       " 'nurs home admissions, stng/lt',\n",
       " 'advpractnurs midwve,fmle w/npi',\n",
       " 'cert regist nurse anesth, 45-54_y',\n",
       " 'certregistnursanesth,male w/npi',\n",
       " 'cert nurse midwvs,retrd/not emp_y',\n",
       " 'cert regist nurse anesth, male_y',\n",
       " 'cert nurse midwvs,ft mid/physpr_y',\n",
       " 'cert regist nurse anesth, < 35_y',\n",
       " 'advanced practice reg nurses,ft',\n",
       " 'nurs home inpatient days',\n",
       " 'cert nurse midwvs,ft unk emptyp_y',\n",
       " 'licensed nurs home beds, stng_y',\n",
       " 'adv practice regist nurse w/npi_y',\n",
       " '# hosp w/intermediate nurs care_y',\n",
       " 'cert regist nurse anesth, 65 +_y',\n",
       " '# hosp w/skilled nursing care_y',\n",
       " 'registered nurses, part-time',\n",
       " 'certified nurse midwives_y',\n",
       " 'registered nurses, vacancies',\n",
       " 'registered nurses, full-time',\n",
       " 'adv pract nurse midwives w/npi_y',\n",
       " '# skilled nursing facilities',\n",
       " 'certregistnursanesth,fmle w/npi',\n",
       " 'licensed nurs home beds, lt_y',\n",
       " 'cert regist nurse anesth, 35-44_y',\n",
       " 'skilled nurs fac total beds',\n",
       " 'cert regist nurse anesth,female_y',\n",
       " 'cert regist nurse anesth, 55-64_y',\n",
       " 'certified nurse midwives, pt_y',\n",
       " 'nurs home inpatient days, stgen',\n",
       " 'cert regist nurse anesthetists_y',\n",
       " 'nurs home admissions, tot hosp_y',\n",
       " 'nurse practitioners, male w/npi_y',\n",
       " 'certified nurse midwives, ft_y',\n",
       " 'licensed nursing home beds_y',\n",
       " 'licensed nurs home beds, stgen_y',\n",
       " 'adv prct regist nurs,fmle w/npi',\n",
       " 'adv prct regist nurs,male w/npi',\n",
       " 'clinical nurse specialist w/npi_y',\n",
       " 'nurse practitioners w/npi_y',\n",
       " 'skilled nurs care, beds set up_y',\n",
       " 'nurse practitioners, fmle w/npi_y',\n",
       " 'clin nurs specialist,male w/npi',\n",
       " '# nursing facilities',\n",
       " 'cert nurse midwvs,ft oth emptyp_y',\n",
       " 'nursing facilities total beds',\n",
       " 'nurse practitioners_y',\n",
       " 'advpractnurs midwve,male w/npi',\n",
       " 'estimate!!race!!total population!!one race!!white ratio',\n",
       " 'estimate!!race!!total population!!one race!!american indian and alaska native ratio',\n",
       " 'estimate!!race!!total population!!one race!!asian ratio',\n",
       " 'estimate!!race!!total population!!one race!!asian!!chinese ratio',\n",
       " 'estimate!!race!!total population!!one race!!native hawaiian and other pacific islander ratio',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population ratio',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!white ratio',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!american indian and alaska native ratio',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!some other race ratio',\n",
       " 'estimate!!hispanic or latino and race!!total population ratio',\n",
       " 'estimate!!hispanic or latino and race!!total population!!hispanic or latino (of any race) ratio',\n",
       " 'estimate!!hispanic or latino and race!!total population!!hispanic or latino (of any race)!!cuban ratio',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino ratio',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!white alone ratio',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!black or african american alone ratio',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!asian alone ratio',\n",
       " 'estimate!!total housing units ratio',\n",
       " 'estimate!!citizen, voting age population!!citizen, 18 and over population!!male ratio',\n",
       " 'estimate!!sex and age!!total population ratio',\n",
       " 'estimate!!sex and age!!total population!!male ratio',\n",
       " 'estimate!!sex and age!!total population!!female ratio',\n",
       " 'estimate!!sex and age!!total population!!5 to 9 years ratio',\n",
       " 'estimate!!sex and age!!total population!!60 to 64 years ratio',\n",
       " 'estimate!!sex and age!!total population!!85 years and over ratio',\n",
       " 'estimate!!sex and age!!total population!!under 18 years ratio',\n",
       " 'estimate!!sex and age!!total population!!62 years and over ratio',\n",
       " 'estimate!!sex and age!!total population!!65 years and over ratio',\n",
       " 'estimate!!sex and age!!total population!!18 years and over!!male ratio',\n",
       " 'estimate!!sex and age!!total population!!65 years and over.1 ratio',\n",
       " 'colon/rectal srg, total ptn cr ratio',\n",
       " 'ophthalmolgy, total patn care ratio',\n",
       " \"m.d.'s, total other_x ratio\",\n",
       " 'aerospace med, total ratio',\n",
       " 'forensic path, total ratio',\n",
       " \"m.d.'s, total ptn care non-fed_x ratio\",\n",
       " 'public health, total patnt care ratio',\n",
       " 'child psych, total patn care ratio',\n",
       " 'medical genetics, total ratio',\n",
       " 'surgical specs, total, 35-44 ratio',\n",
       " \"total d.o.'s, total non-fed ratio\",\n",
       " \"total m.d.'s, female_x ratio\",\n",
       " \"total d.o.'s, total federal ratio\",\n",
       " 'nursing home beds, total hosp_x ratio',\n",
       " \"do's, orthopedic surg, total_x ratio\",\n",
       " 'medical specs, total, 35-44 ratio',\n",
       " 'other specs, total, < 35 ratio',\n",
       " 'dent, total male, priv pract ratio',\n",
       " \"total d.o.'s, male ratio\",\n",
       " 'dentists, total, priv pract, ft ratio',\n",
       " 'gnrl int med, total patn care ratio',\n",
       " \"total d.o.'s, 55-64 ratio\",\n",
       " 'path,anat/clinic,total ratio',\n",
       " 'transplant surg, total ratio',\n",
       " \"do's, gen pract, total_x ratio\",\n",
       " 'ped subspecs, total ratio',\n",
       " \"do's, emergency med, total_x ratio\",\n",
       " 'psychiatry, total patient care_x ratio',\n",
       " \"total rep facility exp (1000's) ratio\",\n",
       " \"md's, gen pract, total ratio\",\n",
       " 'psychiatry, total_x ratio',\n",
       " 'other specs, total patnt care ratio',\n",
       " 'dentists, total, priv pract, pt ratio',\n",
       " 'total inpatient, beds set up_x ratio',\n",
       " 'gastroenterology, total ratio',\n",
       " 'urology, total patient care ratio',\n",
       " \"do's, ped subspecs, total_x ratio\",\n",
       " 'plastic surg, total ratio',\n",
       " \"do's inactive, total_x ratio\",\n",
       " 'total medicare inpatient days ratio',\n",
       " 'ped subspecs, total patn care ratio',\n",
       " \"md's, fam med subspec, total ratio\",\n",
       " 'public health, total ratio',\n",
       " \"do's, anesthesiolgy, total_x ratio\",\n",
       " 'surg specs tot, total ratio',\n",
       " \"total m.d.'s, 45-54_x ratio\",\n",
       " 'medical specs, total, 55-64 ratio',\n",
       " 'dermatology, total ratio',\n",
       " 'cardiovas dis, total patn care ratio',\n",
       " 'dentists, total priv practice ratio',\n",
       " 'urology, total ratio',\n",
       " \"do's, gnrl int med, total_x ratio\",\n",
       " 'diag radiolgy, total ratio',\n",
       " 'int med subspecs, total ratio',\n",
       " \"do's, ob-gyn, general, total_x ratio\",\n",
       " \"md's, gen pract, total ptn care ratio\",\n",
       " \"total d.o.'s, 75 + ratio\",\n",
       " \"total m.d.'s, 55-64_x ratio\",\n",
       " 'radiology, total ratio',\n",
       " 'phys med/rehab, total patnt cr ratio',\n",
       " 'vascular med, total ratio',\n",
       " 'emergency med, total ratio',\n",
       " 'medical specs, total, 65-74 ratio',\n",
       " '# surgical operations, total ratio',\n",
       " 'gen prev med, total patnt care ratio',\n",
       " \"do's, gen pract, total ptn care_x ratio\",\n",
       " \"total d.o.'s, < 35 ratio\",\n",
       " 'neurology, total ratio',\n",
       " 'radiology, total patient care ratio',\n",
       " \"do's, fam med subspec, total_x ratio\",\n",
       " 'vascular med, total patn care ratio',\n",
       " 'other specs, total, 45-54 ratio',\n",
       " 'genrl surg, total patient care ratio',\n",
       " \"total m.d.'s, < 35_x ratio\",\n",
       " 'other specs, total, 75 + ratio',\n",
       " 'other specs, total, 35-44 ratio',\n",
       " \"total d.o.'s, 65-74 ratio\",\n",
       " \"total d.o.'s, 35-44 ratio\",\n",
       " \"total m.d.'s, total non-fed_x ratio\",\n",
       " \"total d.o.'s, female ratio\",\n",
       " 'surgical specs, total, 55-64 ratio',\n",
       " 'ophthalmolgy, total ratio',\n",
       " 'medical specs, total, 75 + ratio',\n",
       " 'cardiovas dis, total ratio',\n",
       " 'licensed beds, total hospital_x ratio',\n",
       " \"md's, fam med gen, total ratio\",\n",
       " 'surgical specs, total, 65-74 ratio',\n",
       " \"d.o.'s, total pc, hosp ft staff_x ratio\",\n",
       " 'total active d.o.s non-federal ratio',\n",
       " 'nuclear med, total patient care ratio',\n",
       " \"total m.d.'s, 75 +_x ratio\",\n",
       " \"do's, genrl surg, total_x ratio\",\n",
       " 'phys med/rehab, total ratio',\n",
       " 'colon/rectal srg, total ratio',\n",
       " 'pediatrics, general, total ratio',\n",
       " 'plastic surg, total patn care ratio',\n",
       " 'dent, total female, priv pract ratio',\n",
       " 'surgical specs, total, 75 + ratio',\n",
       " 'other spec, tot, total ptn care ratio',\n",
       " 'rad oncology, total ratio',\n",
       " 'gen prev med, total ratio',\n",
       " \"m.d.'s, total oth prof activity_x ratio\",\n",
       " 'dentists, total prof active ratio',\n",
       " 'other specs, total, 65-74 ratio',\n",
       " \"do's, ob-gyn subspecs, total_x ratio\",\n",
       " \"total m.d.'s, male_x ratio\",\n",
       " 'med spec tot, total ratio',\n",
       " \"do's, phys med/rehab, total_x ratio\",\n",
       " \"total m.d.'s, 65-74_x ratio\",\n",
       " \"md's inactive, total ratio\",\n",
       " 'rad oncology, total patnt care ratio',\n",
       " 'child psych, total ratio',\n",
       " '# nhsc total active sites ratio',\n",
       " 'thoracic surg, total patn care ratio',\n",
       " \"do's, psychiatry, total_x ratio\",\n",
       " \"total m.d.'s, tot non-fed & fed_x ratio\",\n",
       " \"do's, other specs, total_x ratio\",\n",
       " \"md's not classified, total ratio\",\n",
       " 'skilled nurs fac total beds_x ratio',\n",
       " 'allergy & immunology, total ratio',\n",
       " 'med spec tot, total patn care ratio',\n",
       " 'nuclear med, total ratio',\n",
       " 'orthopedic surg, total ratio',\n",
       " 'aerospace med, total patn care ratio',\n",
       " 'total deaths ratio',\n",
       " 'thoracic surg, total ratio',\n",
       " \"total d.o.'s, tot non-fed & fed ratio\",\n",
       " 'surg specs tot, total patn care ratio',\n",
       " \"m.d.'s, total pc, hosp ft staff_x ratio\",\n",
       " 'anesthesiolgy, total ratio',\n",
       " 'ped cardiolgy, total patn care ratio',\n",
       " 'neurolgcal surg, total ratio',\n",
       " 'ob-gyn, gen, total patient care ratio',\n",
       " 'anesthesiolgy, total patn care ratio',\n",
       " 'ob-gyn subspecs, total ratio',\n",
       " 'surgical specs, total, < 35 ratio',\n",
       " 'otolaryngolgy, total ptn care ratio',\n",
       " 'forensic path, total patn care ratio',\n",
       " 'genrl surg, total ratio',\n",
       " 'gastroenterology, total ptn cr ratio',\n",
       " 'general internal med, total ratio',\n",
       " 'occupat med, total patnt care ratio',\n",
       " \"d.o.'s, total oth prof activity ratio\",\n",
       " 'medical specs, total, < 35 ratio',\n",
       " \"m.d.'s, total, inactive_x ratio\",\n",
       " 'dermatology, total patnt care ratio',\n",
       " 'emergency med, total patn care ratio',\n",
       " \"total d.o.'s, 45-54 ratio\",\n",
       " 'ped cardiolgy, total ratio',\n",
       " 'orthopedic surg, total ptn care ratio',\n",
       " \"do's not classified, total_x ratio\",\n",
       " 'neurolgcal surg, total ptn care ratio',\n",
       " \"md's, total gen pract, total ratio\",\n",
       " 'pulmonary dis, total patn care ratio',\n",
       " 'other specs, total, 55-64 ratio',\n",
       " 'other specs, total ratio',\n",
       " 'diag radiolgy, total patn care ratio',\n",
       " 'total active m.d.s non-federal_x ratio',\n",
       " 'other spec, tot, total ratio',\n",
       " 'surgical specs, total, 45-54 ratio',\n",
       " \"do's, int med subspecs, total_x ratio\",\n",
       " 'total active d.o.s federal ratio',\n",
       " 'pulmonary dis, total ratio',\n",
       " 'nursing facilities total beds_x ratio',\n",
       " 'otolaryngolgy, total ratio',\n",
       " \"total m.d.'s, 35-44_x ratio\",\n",
       " 'neurology, total patient care ratio',\n",
       " \"do's, fam med gen, total_x ratio\",\n",
       " 'short term non-gen hosp beds_x ratio',\n",
       " 'oth special care, beds set up ratio',\n",
       " 'psychiatric care, beds set up ratio',\n",
       " ...]"
      ]
     },
     "execution_count": 1923,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lose_these['feature'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1924,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_master = master.drop(columns = list(lose_these['feature'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1925,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108, 131)"
      ]
     },
     "execution_count": 1925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1926,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = better_master.drop(columns = ['total_covid', 'deaths', 'county_x', 'county_y', 'state', 'id', \n",
    "                           'case_per_pop', 'beds_per_case', 'beds_per_case ratio', 'unnamed: 0_y', 'st_num',\n",
    "                           'cases', 'countyfips', 'key_0', 'county', 'case_per_pop ratio',\n",
    "                           'population ratio', 'st_num ratio', 'cases ratio', 'total_covid ratio',\n",
    "                           'deaths ratio', 'countyfips ratio'])\n",
    "y = better_master['case_per_pop']\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ss, y, random_state = 11, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1927,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([ #instantiate transformers and model\n",
    "    ('lr', LogisticRegression(random_state = 11))\n",
    "])\n",
    "\n",
    "# set hyperparameters\n",
    "\n",
    "pipe_params = {'lr__dual' : [True, False],\n",
    "               'lr__class_weight' : ['dict', 'balanced', None],\n",
    "              'lr__solver': ['liblinear', 'lbfgs', None],\n",
    "              'lr__penalty': ['l1', 'l2', 'none'] # running this with the lasso and ridge techniques by applying a penalty, also running with no penalty\n",
    "              }\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid = pipe_params,\n",
    "                 cv = 5,\n",
    "                 scoring = 'accuracy',\n",
    "                 verbose = 2   \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1928,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   4.7s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   2.4s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.7s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   2.9s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.4s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.4s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.4s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   2.7s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   2.2s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.2s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   2.9s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.4s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done 270 out of 270 | elapsed:   36.2s finished\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg_2 = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1929,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg_2_train_score = logreg_2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1930,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_2_test_score = logreg_2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1931,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__class_weight': 'dict',\n",
       " 'lr__dual': False,\n",
       " 'lr__penalty': 'none',\n",
       " 'lr__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 1931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1932,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7863719444314998"
      ]
     },
     "execution_count": 1932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logreg_2.best_estimator_, X_ss, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1933,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coefs = logreg_2.best_estimator_.steps[0][1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1934,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef_df = pd.DataFrame(new_coefs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1935,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.006155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.714659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.168225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.219950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.434883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-0.324234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>-0.099186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.047428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.040452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-0.217792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0   -0.006155\n",
       "1    0.714659\n",
       "2   -0.168225\n",
       "3    0.219950\n",
       "4   -0.434883\n",
       "..        ...\n",
       "104 -0.324234\n",
       "105 -0.099186\n",
       "106  0.047428\n",
       "107  0.040452\n",
       "108 -0.217792\n",
       "\n",
       "[109 rows x 1 columns]"
      ]
     },
     "execution_count": 1935,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1936,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 1936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1937,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef_df['coefficients'] = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1938,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef_df.rename(columns=({0: 'coefficient',\n",
    "                        'coefficients': 'feature'}), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1939,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-5.330073</td>\n",
       "      <td>estimate!!sex and age!!total population!!75 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-3.402592</td>\n",
       "      <td>estimate!!sex and age!!total population!!sex r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.952018</td>\n",
       "      <td>estimate!!race!!total population!!two or more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.629154</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-1.465498</td>\n",
       "      <td>estimate!!race!!total population!!one race!!am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.490142</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.385746</td>\n",
       "      <td>estimate!!sex and age!!total population!!60 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.562487</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2.976099</td>\n",
       "      <td>estimate!!sex and age!!total population!!18 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.158591</td>\n",
       "      <td>estimate!!sex and age!!total population!!85 ye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    coefficient                                            feature\n",
       "23    -5.330073  estimate!!sex and age!!total population!!75 to...\n",
       "78    -3.402592  estimate!!sex and age!!total population!!sex r...\n",
       "14    -1.952018  estimate!!race!!total population!!two or more ...\n",
       "8     -1.629154  estimate!!race!!total population!!one race!!as...\n",
       "45    -1.465498  estimate!!race!!total population!!one race!!am...\n",
       "..          ...                                                ...\n",
       "6      1.490142  estimate!!race!!total population!!one race!!as...\n",
       "22     2.385746  estimate!!sex and age!!total population!!60 to...\n",
       "7      2.562487  estimate!!race!!total population!!one race!!as...\n",
       "95     2.976099  estimate!!sex and age!!total population!!18 ye...\n",
       "24     3.158591  estimate!!sex and age!!total population!!85 ye...\n",
       "\n",
       "[109 rows x 2 columns]"
      ]
     },
     "execution_count": 1939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coef_df.sort_values(by = 'coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1940,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.006155</td>\n",
       "      <td>water_area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.714659</td>\n",
       "      <td>estimate!!race!!total population!!one race!!am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.168225</td>\n",
       "      <td>estimate!!race!!total population!!one race!!am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.219950</td>\n",
       "      <td>estimate!!race!!total population!!one race!!am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.434883</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-0.324234</td>\n",
       "      <td>medical specs, total, 45-54 ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>-0.099186</td>\n",
       "      <td>physician assistants, prim care ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.047428</td>\n",
       "      <td>child psychiatry, &lt; 35 ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.040452</td>\n",
       "      <td>beds ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-0.217792</td>\n",
       "      <td>beds_per_pop ratio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficient                                            feature\n",
       "0      -0.006155                                         water_area\n",
       "1       0.714659  estimate!!race!!total population!!one race!!am...\n",
       "2      -0.168225  estimate!!race!!total population!!one race!!am...\n",
       "3       0.219950  estimate!!race!!total population!!one race!!am...\n",
       "4      -0.434883  estimate!!race!!total population!!one race!!as...\n",
       "..           ...                                                ...\n",
       "104    -0.324234                  medical specs, total, 45-54 ratio\n",
       "105    -0.099186              physician assistants, prim care ratio\n",
       "106     0.047428                       child psychiatry, < 35 ratio\n",
       "107     0.040452                                         beds ratio\n",
       "108    -0.217792                                 beds_per_pop ratio\n",
       "\n",
       "[109 rows x 2 columns]"
      ]
     },
     "execution_count": 1940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coef_df[abs(new_coef_df['coefficient']) > .0000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1941,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('lr',\n",
       "                 LogisticRegression(C=1.0, class_weight='dict', dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='none', random_state=11,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 1941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1942,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Score: 0.8352638352638353\n",
      " Testing Score: 0.8120978120978121\n"
     ]
    }
   ],
   "source": [
    "print(f' Training Score: {logreg_2_train_score}')\n",
    "print(f' Testing Score: {logreg_2_test_score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1943,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('knn', KNeighborsClassifier())])\n",
    "\n",
    "# set hyperparameters\n",
    "\n",
    "pipe_params = {\n",
    "    'knn__n_neighbors': [3,5,7,9,27],\n",
    "    'knn__weights' : ['uniform', 'distance'], # distance gives more predictive power to closer neighbors\n",
    "    'knn__p': [1,2,'p'], # allows us to test Minkowski, Euclidean, and Manhattan measurements\n",
    "               \n",
    "              }\n",
    "\n",
    "gsknn = GridSearchCV(pipe,\n",
    "                 param_grid = pipe_params,\n",
    "                 cv = 5,\n",
    "                 scoring = 'accuracy',\n",
    "                 verbose = 2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1944,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=uniform ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=uniform, total=   0.7s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=uniform ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=uniform, total=   0.5s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=distance, total=   0.4s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=distance, total=   0.4s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=1, knn__weights=distance, total=   0.4s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=3, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=3, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=uniform ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=uniform, total=   0.5s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=uniform, total=   0.5s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=uniform, total=   0.6s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=uniform, total=   0.7s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=distance, total=   0.4s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=distance, total=   0.8s\n",
      "[CV] knn__n_neighbors=5, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=2, knn__weights=distance, total=   0.6s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=5, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=5, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=uniform ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=uniform, total=   0.9s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=7, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=2, knn__weights=distance, total=   0.4s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=7, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=7, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=uniform ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=uniform, total=   1.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=1, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=1, knn__weights=distance, total=   0.4s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=2, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=uniform ..............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=9, knn__p=p, knn__weights=distance .............\n",
      "[CV]  knn__n_neighbors=9, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=uniform .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=uniform, total=   0.4s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=uniform, total=   0.9s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=distance, total=   0.6s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=distance, total=   0.6s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=1, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=1, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=uniform, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=distance, total=   0.3s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=distance, total=   0.4s\n",
      "[CV] knn__n_neighbors=27, knn__p=2, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=2, knn__weights=distance, total=   0.4s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=uniform .............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=uniform, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=distance, total=   0.0s\n",
      "[CV] knn__n_neighbors=27, knn__p=p, knn__weights=distance ............\n",
      "[CV]  knn__n_neighbors=27, knn__p=p, knn__weights=distance, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:   38.4s finished\n"
     ]
    }
   ],
   "source": [
    "knn_model = gsknn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1945,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8043758043758044"
      ]
     },
     "execution_count": 1945,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1946,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 1946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1947,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 27, 'knn__p': 2, 'knn__weights': 'distance'}"
      ]
     },
     "execution_count": 1947,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1948,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7940832906162139"
      ]
     },
     "execution_count": 1948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn_model.best_estimator_, X_ss, y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1949,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([ #instantiate\n",
    "    ('svc', SVC())])\n",
    "\n",
    "# set hyperparameters\n",
    "\n",
    "pipe_params = {\n",
    "    'svc__kernel': ['linear', 'poly', 'rbf'],\n",
    "    'svc__class_weight' : [dict, 'balanced'],\n",
    "    'svc__random_state': [11],\n",
    "    'svc__gamma' : ['scale', 'auto'],\n",
    "    'svc__C' : [0, .5, 1],\n",
    "    'svc__shrinking' : [True, False]\n",
    "              }\n",
    "\n",
    "gssvc = GridSearchCV(pipe,\n",
    "                 param_grid = pipe_params,\n",
    "                 cv = 5,\n",
    "                 scoring = 'accuracy',\n",
    "                 verbose = 2   \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1950,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: C <= 0\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.2s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   2.4s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   2.5s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   6.4s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   4.5s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   3.5s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   5.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   4.6s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   1.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   1.3s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   1.2s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   1.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   1.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.2s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.6s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.5s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.7s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.4s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   2.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   1.5s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   1.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   1.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   1.4s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   1.5s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   1.7s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   2.1s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.3s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.2s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   4.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   6.2s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   5.7s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   3.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   2.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   1.2s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   1.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   1.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   1.2s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   1.0s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.9s\n",
      "[CV] svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=0.5, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=<class 'dict'>, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.0s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: object of type 'type' has no len()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.9s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   2.2s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   9.4s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=  11.4s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   7.5s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   4.2s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   7.4s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=scale, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.5s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.6s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.5s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.3s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=True, total=   1.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   5.0s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   7.2s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   6.1s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=   4.0s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=linear, svc__random_state=11, svc__shrinking=False, total=  10.2s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.9s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=True, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=poly, svc__random_state=11, svc__shrinking=False, total=   0.8s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=True, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.7s\n",
      "[CV] svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False \n",
      "[CV]  svc__C=1, svc__class_weight=balanced, svc__gamma=auto, svc__kernel=rbf, svc__random_state=11, svc__shrinking=False, total=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:  3.9min finished\n"
     ]
    }
   ],
   "source": [
    "svc_model = gssvc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1951,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8043758043758044"
      ]
     },
     "execution_count": 1951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1952,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8416988416988417"
      ]
     },
     "execution_count": 1952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1953,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 1,\n",
       " 'svc__class_weight': 'balanced',\n",
       " 'svc__gamma': 'scale',\n",
       " 'svc__kernel': 'poly',\n",
       " 'svc__random_state': 11,\n",
       " 'svc__shrinking': True}"
      ]
     },
     "execution_count": 1953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1954,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-5.330073</td>\n",
       "      <td>estimate!!sex and age!!total population!!75 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-3.402592</td>\n",
       "      <td>estimate!!sex and age!!total population!!sex r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.952018</td>\n",
       "      <td>estimate!!race!!total population!!two or more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.629154</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-1.465498</td>\n",
       "      <td>estimate!!race!!total population!!one race!!am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.490142</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.385746</td>\n",
       "      <td>estimate!!sex and age!!total population!!60 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.562487</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2.976099</td>\n",
       "      <td>estimate!!sex and age!!total population!!18 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.158591</td>\n",
       "      <td>estimate!!sex and age!!total population!!85 ye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    coefficient                                            feature\n",
       "23    -5.330073  estimate!!sex and age!!total population!!75 to...\n",
       "78    -3.402592  estimate!!sex and age!!total population!!sex r...\n",
       "14    -1.952018  estimate!!race!!total population!!two or more ...\n",
       "8     -1.629154  estimate!!race!!total population!!one race!!as...\n",
       "45    -1.465498  estimate!!race!!total population!!one race!!am...\n",
       "..          ...                                                ...\n",
       "6      1.490142  estimate!!race!!total population!!one race!!as...\n",
       "22     2.385746  estimate!!sex and age!!total population!!60 to...\n",
       "7      2.562487  estimate!!race!!total population!!one race!!as...\n",
       "95     2.976099  estimate!!sex and age!!total population!!18 ye...\n",
       "24     3.158591  estimate!!sex and age!!total population!!85 ye...\n",
       "\n",
       "[109 rows x 2 columns]"
      ]
     },
     "execution_count": 1954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coef_df.sort_values(by = 'coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1955,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df['actual_odds'] = np.exp(coef_df['coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1956,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef_df['actual_odds'] = np.exp(new_coef_df['coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1957,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "      <th>abs</th>\n",
       "      <th>actual_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>total_area</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>land_area</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.006639</td>\n",
       "      <td>water_area</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.993383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>population</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>estimate!!race!!total population!!one race</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>nurse practitioners_y ratio</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>advpractnurs midwve,male w/npi ratio</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>0.022756</td>\n",
       "      <td>beds ratio</td>\n",
       "      <td>0.022756</td>\n",
       "      <td>1.023017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>-0.182812</td>\n",
       "      <td>beds_per_pop ratio</td>\n",
       "      <td>0.182812</td>\n",
       "      <td>0.832925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>pop_density ratio</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1677 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      coefficient                                     feature       abs  \\\n",
       "0        0.000000                                  total_area  0.000000   \n",
       "1        0.000000                                   land_area  0.000000   \n",
       "2       -0.006639                                  water_area  0.006639   \n",
       "3        0.000000                                  population  0.000000   \n",
       "4        0.000000  estimate!!race!!total population!!one race  0.000000   \n",
       "...           ...                                         ...       ...   \n",
       "1672     0.000000                 nurse practitioners_y ratio  0.000000   \n",
       "1673     0.000000        advpractnurs midwve,male w/npi ratio  0.000000   \n",
       "1674     0.022756                                  beds ratio  0.022756   \n",
       "1675    -0.182812                          beds_per_pop ratio  0.182812   \n",
       "1676     0.000000                           pop_density ratio  0.000000   \n",
       "\n",
       "      actual_odds  \n",
       "0        1.000000  \n",
       "1        1.000000  \n",
       "2        0.993383  \n",
       "3        1.000000  \n",
       "4        1.000000  \n",
       "...           ...  \n",
       "1672     1.000000  \n",
       "1673     1.000000  \n",
       "1674     1.023017  \n",
       "1675     0.832925  \n",
       "1676     1.000000  \n",
       "\n",
       "[1677 rows x 4 columns]"
      ]
     },
     "execution_count": 1957,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1958,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "      <th>actual_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.006155</td>\n",
       "      <td>water_area</td>\n",
       "      <td>0.993864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.714659</td>\n",
       "      <td>estimate!!race!!total population!!one race!!am...</td>\n",
       "      <td>2.043490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.168225</td>\n",
       "      <td>estimate!!race!!total population!!one race!!am...</td>\n",
       "      <td>0.845163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.219950</td>\n",
       "      <td>estimate!!race!!total population!!one race!!am...</td>\n",
       "      <td>1.246014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.434883</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "      <td>0.647341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-0.324234</td>\n",
       "      <td>medical specs, total, 45-54 ratio</td>\n",
       "      <td>0.723081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>-0.099186</td>\n",
       "      <td>physician assistants, prim care ratio</td>\n",
       "      <td>0.905574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.047428</td>\n",
       "      <td>child psychiatry, &lt; 35 ratio</td>\n",
       "      <td>1.048570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.040452</td>\n",
       "      <td>beds ratio</td>\n",
       "      <td>1.041281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-0.217792</td>\n",
       "      <td>beds_per_pop ratio</td>\n",
       "      <td>0.804293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficient                                            feature  \\\n",
       "0      -0.006155                                         water_area   \n",
       "1       0.714659  estimate!!race!!total population!!one race!!am...   \n",
       "2      -0.168225  estimate!!race!!total population!!one race!!am...   \n",
       "3       0.219950  estimate!!race!!total population!!one race!!am...   \n",
       "4      -0.434883  estimate!!race!!total population!!one race!!as...   \n",
       "..           ...                                                ...   \n",
       "104    -0.324234                  medical specs, total, 45-54 ratio   \n",
       "105    -0.099186              physician assistants, prim care ratio   \n",
       "106     0.047428                       child psychiatry, < 35 ratio   \n",
       "107     0.040452                                         beds ratio   \n",
       "108    -0.217792                                 beds_per_pop ratio   \n",
       "\n",
       "     actual_odds  \n",
       "0       0.993864  \n",
       "1       2.043490  \n",
       "2       0.845163  \n",
       "3       1.246014  \n",
       "4       0.647341  \n",
       "..           ...  \n",
       "104     0.723081  \n",
       "105     0.905574  \n",
       "106     1.048570  \n",
       "107     1.041281  \n",
       "108     0.804293  \n",
       "\n",
       "[109 rows x 3 columns]"
      ]
     },
     "execution_count": 1958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1959,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_eval = coef_df.loc[coef_df['coefficient'] != 0].sort_values(by = 'coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1960,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso_eval.to_csv('~/documents/lasso_coef.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1961,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2_eval = new_coef_df.loc[new_coef_df['coefficient'] != 0].sort_values(by = 'coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1962,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg2_eval.to_csv('~/documents/logreg_coefs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1963,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master.to_csv('~/documents/master_w_ratios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1964,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better_master.to_csv('~/documents/lassoed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1965,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>county</th>\n",
       "      <th>water_area</th>\n",
       "      <th>county_x</th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native!!cherokee tribal grouping</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native!!chippewa tribal grouping</th>\n",
       "      <th>estimate!!race!!total population!!one race!!asian!!asian indian</th>\n",
       "      <th>...</th>\n",
       "      <th>occupat med, total ratio</th>\n",
       "      <th>medical specs, total, 45-54 ratio</th>\n",
       "      <th>physician assistants, prim care ratio</th>\n",
       "      <th>child psychiatry, &lt; 35 ratio</th>\n",
       "      <th>st_num ratio</th>\n",
       "      <th>countyfips ratio</th>\n",
       "      <th>beds ratio</th>\n",
       "      <th>case_per_pop ratio</th>\n",
       "      <th>beds_per_pop ratio</th>\n",
       "      <th>beds_per_case ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>autauga county</td>\n",
       "      <td>2.570696e+07</td>\n",
       "      <td>autauga county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>159</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>2.198855e-08</td>\n",
       "      <td>2.789593e-08</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>baldwin county</td>\n",
       "      <td>1.132977e+09</td>\n",
       "      <td>baldwin county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1003</td>\n",
       "      <td>1522</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>4.802750e-09</td>\n",
       "      <td>8.912795e-09</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>barbour county</td>\n",
       "      <td>5.052321e+07</td>\n",
       "      <td>barbour county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1005</td>\n",
       "      <td>72</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.038981</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>7.973384e-08</td>\n",
       "      <td>1.113265e-07</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bibb county</td>\n",
       "      <td>9.601400e+06</td>\n",
       "      <td>bibb county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1007</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.044702</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>8.670536e-08</td>\n",
       "      <td>6.897017e-08</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>blount county</td>\n",
       "      <td>1.499146e+07</td>\n",
       "      <td>blount county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1009</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.017504</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.324126e-08</td>\n",
       "      <td>7.523445e-09</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>3103</td>\n",
       "      <td>sweetwater county</td>\n",
       "      <td>1.662303e+08</td>\n",
       "      <td>sweetwater county</td>\n",
       "      <td>WY</td>\n",
       "      <td>56037</td>\n",
       "      <td>742</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>1.270191</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>6.165514e-09</td>\n",
       "      <td>5.908618e-08</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>3104</td>\n",
       "      <td>teton county</td>\n",
       "      <td>5.708591e+08</td>\n",
       "      <td>teton county</td>\n",
       "      <td>WY</td>\n",
       "      <td>56039</td>\n",
       "      <td>77</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>2.430244</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>1.260068e-07</td>\n",
       "      <td>9.027350e-08</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>3105</td>\n",
       "      <td>uinta county</td>\n",
       "      <td>1.662582e+07</td>\n",
       "      <td>uinta county</td>\n",
       "      <td>WY</td>\n",
       "      <td>56041</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>2.719249</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>1.648102e-08</td>\n",
       "      <td>5.297472e-07</td>\n",
       "      <td>0.001560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>3106</td>\n",
       "      <td>washakie county</td>\n",
       "      <td>1.042960e+07</td>\n",
       "      <td>washakie county</td>\n",
       "      <td>WY</td>\n",
       "      <td>56043</td>\n",
       "      <td>52</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>6.894206</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>7.566513e-08</td>\n",
       "      <td>2.723945e-07</td>\n",
       "      <td>0.000443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>3107</td>\n",
       "      <td>weston county</td>\n",
       "      <td>5.225499e+06</td>\n",
       "      <td>weston county</td>\n",
       "      <td>WY</td>\n",
       "      <td>56045</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>7.893662</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.380480e-07</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3108 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_0             county    water_area           county_x state     id  \\\n",
       "0         0     autauga county  2.570696e+07     autauga county    AL   1001   \n",
       "1         1     baldwin county  1.132977e+09     baldwin county    AL   1003   \n",
       "2         2     barbour county  5.052321e+07     barbour county    AL   1005   \n",
       "3         3        bibb county  9.601400e+06        bibb county    AL   1007   \n",
       "4         4      blount county  1.499146e+07      blount county    AL   1009   \n",
       "...     ...                ...           ...                ...   ...    ...   \n",
       "3103   3103  sweetwater county  1.662303e+08  sweetwater county    WY  56037   \n",
       "3104   3104       teton county  5.708591e+08       teton county    WY  56039   \n",
       "3105   3105       uinta county  1.662582e+07       uinta county    WY  56041   \n",
       "3106   3106    washakie county  1.042960e+07    washakie county    WY  56043   \n",
       "3107   3107      weston county  5.225499e+06      weston county    WY  56045   \n",
       "\n",
       "      estimate!!race!!total population!!one race!!american indian and alaska native  \\\n",
       "0                                                   159                               \n",
       "1                                                  1522                               \n",
       "2                                                    72                               \n",
       "3                                                     8                               \n",
       "4                                                   141                               \n",
       "...                                                 ...                               \n",
       "3103                                                742                               \n",
       "3104                                                 77                               \n",
       "3105                                                160                               \n",
       "3106                                                 52                               \n",
       "3107                                                 37                               \n",
       "\n",
       "      estimate!!race!!total population!!one race!!american indian and alaska native!!cherokee tribal grouping  \\\n",
       "0                                                    82                                                         \n",
       "1                                                   285                                                         \n",
       "2                                                    26                                                         \n",
       "3                                                     0                                                         \n",
       "4                                                    20                                                         \n",
       "...                                                 ...                                                         \n",
       "3103                                                  0                                                         \n",
       "3104                                                 30                                                         \n",
       "3105                                                  0                                                         \n",
       "3106                                                 42                                                         \n",
       "3107                                                  0                                                         \n",
       "\n",
       "      estimate!!race!!total population!!one race!!american indian and alaska native!!chippewa tribal grouping  \\\n",
       "0                                                     0                                                         \n",
       "1                                                     0                                                         \n",
       "2                                                     0                                                         \n",
       "3                                                     0                                                         \n",
       "4                                                     0                                                         \n",
       "...                                                 ...                                                         \n",
       "3103                                                  0                                                         \n",
       "3104                                                  0                                                         \n",
       "3105                                                  0                                                         \n",
       "3106                                                  0                                                         \n",
       "3107                                                  0                                                         \n",
       "\n",
       "      estimate!!race!!total population!!one race!!asian!!asian indian  ...  \\\n",
       "0                                                     0                ...   \n",
       "1                                                    43                ...   \n",
       "2                                                    11                ...   \n",
       "3                                                    37                ...   \n",
       "4                                                    42                ...   \n",
       "...                                                 ...                ...   \n",
       "3103                                                  0                ...   \n",
       "3104                                                  6                ...   \n",
       "3105                                                  0                ...   \n",
       "3106                                                  0                ...   \n",
       "3107                                                  0                ...   \n",
       "\n",
       "      occupat med, total ratio  medical specs, total, 45-54 ratio  \\\n",
       "0                          0.0                                0.0   \n",
       "1                          0.0                                0.0   \n",
       "2                          0.0                                0.0   \n",
       "3                          0.0                                0.0   \n",
       "4                          0.0                                0.0   \n",
       "...                        ...                                ...   \n",
       "3103                       0.0                                0.0   \n",
       "3104                       0.0                                0.0   \n",
       "3105                       0.0                                0.0   \n",
       "3106                       0.0                                0.0   \n",
       "3107                       0.0                                0.0   \n",
       "\n",
       "      physician assistants, prim care ratio  child psychiatry, < 35 ratio  \\\n",
       "0                                       0.0                           0.0   \n",
       "1                                       0.0                           0.0   \n",
       "2                                       0.0                           0.0   \n",
       "3                                       0.0                           0.0   \n",
       "4                                       0.0                           0.0   \n",
       "...                                     ...                           ...   \n",
       "3103                                    0.0                           0.0   \n",
       "3104                                    0.0                           0.0   \n",
       "3105                                    0.0                           0.0   \n",
       "3106                                    0.0                           0.0   \n",
       "3107                                    0.0                           0.0   \n",
       "\n",
       "      st_num ratio  countyfips ratio  beds ratio  case_per_pop ratio  \\\n",
       "0         0.000018          0.018134    0.001540        2.198855e-08   \n",
       "1         0.000005          0.004820    0.001855        4.802750e-09   \n",
       "2         0.000039          0.038981    0.002870        7.973384e-08   \n",
       "3         0.000044          0.044702    0.001554        8.670536e-08   \n",
       "4         0.000017          0.017504    0.000434        1.324126e-08   \n",
       "...            ...               ...         ...                 ...   \n",
       "3103      0.001269          1.270191    0.002607        6.165514e-09   \n",
       "3104      0.002429          2.430244    0.002082        1.260068e-07   \n",
       "3105      0.002717          2.719249    0.010918        1.648102e-08   \n",
       "3106      0.006889          6.894206    0.002214        7.566513e-08   \n",
       "3107      0.007887          7.893662    0.001690        0.000000e+00   \n",
       "\n",
       "      beds_per_pop ratio  beds_per_case ratio  \n",
       "0           2.789593e-08             0.000023  \n",
       "1           8.912795e-09             0.000009  \n",
       "2           1.113265e-07             0.000054  \n",
       "3           6.897017e-08             0.000035  \n",
       "4           7.523445e-09             0.000010  \n",
       "...                  ...                  ...  \n",
       "3103        5.908618e-08             0.000217  \n",
       "3104        9.027350e-08             0.000031  \n",
       "3105        5.297472e-07             0.001560  \n",
       "3106        2.723945e-07             0.000443  \n",
       "3107        2.380480e-07                  inf  \n",
       "\n",
       "[3108 rows x 131 columns]"
      ]
     },
     "execution_count": 1965,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1966,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 3)"
      ]
     },
     "execution_count": 1966,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coef_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1985,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef_df.to_csv('~/documents/fin_coefficients.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1968,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.8978978978978979\n",
      "Test Score 0.7593307593307593\n",
      "Cross Val Score 0.7500064722908285\n"
     ]
    }
   ],
   "source": [
    "dt_pipe = Pipeline([\n",
    "    ('dt' ,DecisionTreeClassifier())\n",
    "])\n",
    "pipe_params = {\n",
    "    'dt__max_depth' : [10],\n",
    "    'dt__min_samples_leaf' : [8],\n",
    "    'dt__min_samples_split' : [3],\n",
    "    }\n",
    "gs = GridSearchCV(dt_pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params,\n",
    "                  n_jobs = -1,# what parameters values are we searching?\n",
    "                  cv=StratifiedKFold(shuffle=True)\n",
    "                  ,\n",
    "                  verbose = 2) # 3-fold cross-validation.\n",
    "gs.fit(X_train,y_train)\n",
    "gs.best_params_\n",
    "print(f'Train Score {gs.score(X_train,y_train)}')\n",
    "print(f'Test Score {gs.score(X_test,y_test)}')\n",
    "print(f'Cross Val Score {cross_val_score(gs.best_estimator_, X,y).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1969,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   21.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 1.0\n",
      "Test Score 0.8198198198198198\n",
      "Cross Val Score 0.7882996515318619\n"
     ]
    }
   ],
   "source": [
    "bag_pipe = Pipeline([\n",
    "    ('bag', BaggingClassifier())])\n",
    "pipe_params = {\n",
    "    'bag__n_estimators': [50],\n",
    "    'bag__max_features': [.9]\n",
    "    }\n",
    "gs = GridSearchCV(bag_pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params,\n",
    "                  n_jobs = -1,# what parameters values are we searching?\n",
    "                  cv=StratifiedKFold(shuffle=True),\n",
    "                  verbose = 2) # 3-fold cross-validation.\n",
    "gs.fit(X_train,y_train)\n",
    "print(f'Train Score {gs.score(X_train,y_train)}')\n",
    "print(f'Test Score {gs.score(X_test,y_test)}')\n",
    "print(f'Cross Val Score {cross_val_score(gs.best_estimator_, X,y).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1970,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] rf__max_depth=5, rf__n_estimators=20 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=20, score=0.816, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=20 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=20, score=0.822, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=20 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=20, score=0.800, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=20 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=20, score=0.792, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.9s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=20 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=20, score=0.796, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=25 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=25, score=0.799, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.3s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=25 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=25, score=0.809, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.7s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=25 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=25, score=0.803, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.9s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=25 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=25, score=0.794, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    2.2s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=25 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=25, score=0.792, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.4s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=30 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=30, score=0.807, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    2.7s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=30 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=30, score=0.803, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    3.0s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=30 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=30, score=0.803, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    3.3s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=30 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=30, score=0.807, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    3.6s remaining:    0.0s\n",
      "[CV] rf__max_depth=5, rf__n_estimators=30 ............................\n",
      "[CV]  rf__max_depth=5, rf__n_estimators=30, score=0.794, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    3.9s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=20 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=20, score=0.801, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    4.2s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=20 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=20, score=0.811, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    4.5s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=20 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=20, score=0.828, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    4.8s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=20 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=20, score=0.803, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    5.1s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=20 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=20, score=0.818, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    5.4s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=25 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=25, score=0.814, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    5.7s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=25 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=25, score=0.818, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    6.1s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=25 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=25, score=0.815, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:    6.4s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=25 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=25, score=0.788, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    6.8s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=25 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=25, score=0.807, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    7.2s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=30 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=30, score=0.805, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:    7.6s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=30 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=30, score=0.820, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    8.0s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=30 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=30, score=0.815, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:    8.5s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=30 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=30, score=0.803, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:    8.9s remaining:    0.0s\n",
      "[CV] rf__max_depth=10, rf__n_estimators=30 ...........................\n",
      "[CV]  rf__max_depth=10, rf__n_estimators=30, score=0.805, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    9.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    9.3s finished\n",
      "Train Score 0.9343629343629344\n",
      "Test Score 0.8018018018018018\n",
      "Cross Val Score 0.7886149815410265\n"
     ]
    }
   ],
   "source": [
    "rf_pipe = Pipeline([\n",
    "    ('rf', RandomForestClassifier())])\n",
    "rf_params = {\n",
    "    'rf__max_depth':[5,10],\n",
    "    'rf__n_estimators':[20,25,30]\n",
    "}\n",
    "gs = GridSearchCV(rf_pipe, param_grid=rf_params, cv=5,verbose=50)\n",
    "gs.fit(X_train, y_train)\n",
    "print(f'Train Score {gs.score(X_train,y_train)}')\n",
    "print(f'Test Score {gs.score(X_test,y_test)}')\n",
    "print(f'Cross Val Score {cross_val_score(gs.best_estimator_, X,y).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1971,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   13.7s remaining:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   13.7s remaining:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   19.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   19.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.9253539253539254\n",
      "Test Score 0.7722007722007722\n",
      "Cross Val Score 0.7059555431287571\n"
     ]
    }
   ],
   "source": [
    "ada_pipe = Pipeline([\n",
    "    ('ada', AdaBoostClassifier())])\n",
    "ada_params = {\n",
    "    'ada__n_estimators' : [250],\n",
    "    'ada__learning_rate' : [1.5]\n",
    "    }\n",
    "gs = GridSearchCV(ada_pipe, param_grid=ada_params, cv=StratifiedKFold(shuffle=True),verbose=12, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "print(f'Train Score {gs.score(X_train,y_train)}')\n",
    "print(f'Test Score {gs.score(X_test,y_test)}')\n",
    "print(f'Cross Val Score {cross_val_score(gs.best_estimator_, X,y).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1973,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = master.drop(columns = ['total_covid', 'deaths', 'county_x', 'county_y', 'state', 'id', \n",
    "                           'case_per_pop', 'beds_per_case', 'beds_per_case ratio', 'unnamed: 0_y', 'st_num',\n",
    "                           'cases', 'countyfips', 'key_0', 'county', 'case_per_pop ratio',\n",
    "                           'population ratio', 'st_num ratio', 'cases ratio', 'total_covid ratio',\n",
    "                           'deaths ratio', 'countyfips ratio'])\n",
    "y = master['case_per_pop']\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ss, y, random_state = 11, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1974,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg_preds = logreg_model.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, logreg_preds).ravel() # From Danielle Medellin's confusion matrix setup\n",
    "cm = confusion_matrix(y_test, logreg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1975,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[553,  39],\n",
       "       [112,  73]])"
      ]
     },
     "execution_count": 1975,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1976,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Hotspot Prediction</th>\n",
       "      <th>Hotspot Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Non-Hotspot</th>\n",
       "      <td>553</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Hotspot</th>\n",
       "      <td>112</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Non-Hotspot Prediction  Hotspot Prediction\n",
       "Actual Non-Hotspot                     553                  39\n",
       "Actual Hotspot                         112                  73"
      ]
     },
     "execution_count": 1976,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_df = pd.DataFrame(cm)\n",
    "cm_df.columns = ['Non-Hotspot Prediction', 'Hotspot Prediction']\n",
    "\n",
    "cm_df.index = ['Actual Non-Hotspot', \"Actual Hotspot\"]\n",
    "#This adds the appropriate row and column names for the confusion matrix\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1977,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8056628056628057"
      ]
     },
     "execution_count": 1977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(73 + 553)/(626 + 112 +39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1978,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm_df, annot = True, fmt = 'g', cmap = 'Blues')\n",
    "plt.title('Confusion Matrix', size = 15)\n",
    "plt.ylabel('Predictions', size = 15)\n",
    "plt.xlabel('Actual Class', size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1979,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate: 0.8056628056628057\n",
      "Sensitivity Rate: 0.3945945945945946\n",
      "Specificity Rate: 0.9341216216216216\n",
      "Precision Rate: 0.6517857142857143\n",
      "True Negative Rate: 0.8315789473684211\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp + tn)/(tp+fn+fp+tn)\n",
    "print(f'Accuracy Rate: {accuracy}')\n",
    "\n",
    "sensitivity = tp/(tp+fn)\n",
    "print(f'Sensitivity Rate: {sensitivity}')\n",
    "            \n",
    "specificity = tn/(tn+fp)\n",
    "print(f'Specificity Rate: {specificity}')\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "print(f'Precision Rate: {precision}')\n",
    "\n",
    "true_neg = tn/(tn+fn)\n",
    "print(f'True Negative Rate: {true_neg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1980,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "      <th>abs</th>\n",
       "      <th>actual_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>total_area</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>land_area</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.006639</td>\n",
       "      <td>water_area</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.993383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>population</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>estimate!!race!!total population!!one race</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>nurse practitioners_y ratio</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>advpractnurs midwve,male w/npi ratio</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>0.022756</td>\n",
       "      <td>beds ratio</td>\n",
       "      <td>0.022756</td>\n",
       "      <td>1.023017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>-0.182812</td>\n",
       "      <td>beds_per_pop ratio</td>\n",
       "      <td>0.182812</td>\n",
       "      <td>0.832925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>pop_density ratio</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1677 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      coefficient                                     feature       abs  \\\n",
       "0        0.000000                                  total_area  0.000000   \n",
       "1        0.000000                                   land_area  0.000000   \n",
       "2       -0.006639                                  water_area  0.006639   \n",
       "3        0.000000                                  population  0.000000   \n",
       "4        0.000000  estimate!!race!!total population!!one race  0.000000   \n",
       "...           ...                                         ...       ...   \n",
       "1672     0.000000                 nurse practitioners_y ratio  0.000000   \n",
       "1673     0.000000        advpractnurs midwve,male w/npi ratio  0.000000   \n",
       "1674     0.022756                                  beds ratio  0.022756   \n",
       "1675    -0.182812                          beds_per_pop ratio  0.182812   \n",
       "1676     0.000000                           pop_density ratio  0.000000   \n",
       "\n",
       "      actual_odds  \n",
       "0        1.000000  \n",
       "1        1.000000  \n",
       "2        0.993383  \n",
       "3        1.000000  \n",
       "4        1.000000  \n",
       "...           ...  \n",
       "1672     1.000000  \n",
       "1673     1.000000  \n",
       "1674     1.023017  \n",
       "1675     0.832925  \n",
       "1676     1.000000  \n",
       "\n",
       "[1677 rows x 4 columns]"
      ]
     },
     "execution_count": 1980,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1981,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_counties = y_test.loc[(y_test != 1) & (logreg_preds == 1)].index #shows me misclassified rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1982,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df = master.loc[master.index[fp_counties]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1983,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>county</th>\n",
       "      <th>total_area</th>\n",
       "      <th>land_area</th>\n",
       "      <th>water_area</th>\n",
       "      <th>county_x</th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>population</th>\n",
       "      <th>estimate!!race!!total population!!one race</th>\n",
       "      <th>...</th>\n",
       "      <th>nursing facilities total beds ratio</th>\n",
       "      <th>nurse practitioners_y ratio</th>\n",
       "      <th>advpractnurs midwve,male w/npi ratio</th>\n",
       "      <th>st_num ratio</th>\n",
       "      <th>countyfips ratio</th>\n",
       "      <th>beds ratio</th>\n",
       "      <th>case_per_pop ratio</th>\n",
       "      <th>beds_per_pop ratio</th>\n",
       "      <th>beds_per_case ratio</th>\n",
       "      <th>pop_density ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>149</td>\n",
       "      <td>maricopa county</td>\n",
       "      <td>23766342548</td>\n",
       "      <td>23829656320</td>\n",
       "      <td>6.331377e+07</td>\n",
       "      <td>maricopa county</td>\n",
       "      <td>AZ</td>\n",
       "      <td>4013</td>\n",
       "      <td>4253913</td>\n",
       "      <td>4099917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.403107e-07</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>3.053199e-10</td>\n",
       "      <td>6.379389e-10</td>\n",
       "      <td>4.911741e-07</td>\n",
       "      <td>4.207631e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>338</td>\n",
       "      <td>orange county</td>\n",
       "      <td>2073171585</td>\n",
       "      <td>2335738262</td>\n",
       "      <td>2.625667e+08</td>\n",
       "      <td>orange county</td>\n",
       "      <td>FL</td>\n",
       "      <td>12095</td>\n",
       "      <td>1321194</td>\n",
       "      <td>1276729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.082693e-06</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>8.467228e-10</td>\n",
       "      <td>1.820053e-09</td>\n",
       "      <td>1.626957e-06</td>\n",
       "      <td>4.823527e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>2549</td>\n",
       "      <td>denton county</td>\n",
       "      <td>2085807196</td>\n",
       "      <td>2275298676</td>\n",
       "      <td>1.894915e+08</td>\n",
       "      <td>denton county</td>\n",
       "      <td>TX</td>\n",
       "      <td>48121</td>\n",
       "      <td>807047</td>\n",
       "      <td>778441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.947609e-05</td>\n",
       "      <td>0.059626</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>1.338810e-09</td>\n",
       "      <td>2.278433e-09</td>\n",
       "      <td>2.108718e-06</td>\n",
       "      <td>4.794307e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>1897</td>\n",
       "      <td>bernalillo county</td>\n",
       "      <td>1857553267</td>\n",
       "      <td>1874472931</td>\n",
       "      <td>1.691966e+07</td>\n",
       "      <td>bernalillo county</td>\n",
       "      <td>NM</td>\n",
       "      <td>35001</td>\n",
       "      <td>677692</td>\n",
       "      <td>649178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.164588e-05</td>\n",
       "      <td>0.051647</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>2.242707e-09</td>\n",
       "      <td>4.313400e-09</td>\n",
       "      <td>2.838016e-06</td>\n",
       "      <td>5.383426e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>354</td>\n",
       "      <td>volusia county</td>\n",
       "      <td>1994708722</td>\n",
       "      <td>2852352391</td>\n",
       "      <td>8.576437e+08</td>\n",
       "      <td>volusia county</td>\n",
       "      <td>FL</td>\n",
       "      <td>12127</td>\n",
       "      <td>527634</td>\n",
       "      <td>517240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.274304e-05</td>\n",
       "      <td>0.022984</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>1.928896e-09</td>\n",
       "      <td>5.219153e-09</td>\n",
       "      <td>5.128124e-06</td>\n",
       "      <td>5.013263e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>347</td>\n",
       "      <td>seminole county</td>\n",
       "      <td>2078809884</td>\n",
       "      <td>2622105608</td>\n",
       "      <td>5.432957e+08</td>\n",
       "      <td>seminole county</td>\n",
       "      <td>FL</td>\n",
       "      <td>12117</td>\n",
       "      <td>455086</td>\n",
       "      <td>440178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.636864e-05</td>\n",
       "      <td>0.026626</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>1.979689e-09</td>\n",
       "      <td>1.665836e-09</td>\n",
       "      <td>1.849021e-06</td>\n",
       "      <td>4.810445e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>2291</td>\n",
       "      <td>charleston county</td>\n",
       "      <td>1237819592</td>\n",
       "      <td>2377478103</td>\n",
       "      <td>1.139659e+09</td>\n",
       "      <td>charleston county</td>\n",
       "      <td>SC</td>\n",
       "      <td>45019</td>\n",
       "      <td>394708</td>\n",
       "      <td>386707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.140083e-04</td>\n",
       "      <td>0.114056</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>3.087402e-09</td>\n",
       "      <td>1.367186e-08</td>\n",
       "      <td>1.121911e-05</td>\n",
       "      <td>8.078722e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>pulaski county</td>\n",
       "      <td>1838109640</td>\n",
       "      <td>1964339775</td>\n",
       "      <td>1.262301e+08</td>\n",
       "      <td>pulaski county</td>\n",
       "      <td>AR</td>\n",
       "      <td>5119</td>\n",
       "      <td>393463</td>\n",
       "      <td>382492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.270768e-05</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>0.010990</td>\n",
       "      <td>3.895018e-09</td>\n",
       "      <td>2.793045e-08</td>\n",
       "      <td>1.822487e-05</td>\n",
       "      <td>5.440372e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>339</td>\n",
       "      <td>osceola county</td>\n",
       "      <td>2976496907</td>\n",
       "      <td>3438557597</td>\n",
       "      <td>4.620607e+08</td>\n",
       "      <td>osceola county</td>\n",
       "      <td>FL</td>\n",
       "      <td>12097</td>\n",
       "      <td>338619</td>\n",
       "      <td>325112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.543806e-05</td>\n",
       "      <td>0.035725</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>4.831557e-09</td>\n",
       "      <td>5.476928e-09</td>\n",
       "      <td>3.347639e-06</td>\n",
       "      <td>3.359654e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>2055</td>\n",
       "      <td>lorain county</td>\n",
       "      <td>152700424</td>\n",
       "      <td>1272195481</td>\n",
       "      <td>1.119495e+09</td>\n",
       "      <td>lorain county</td>\n",
       "      <td>OH</td>\n",
       "      <td>39093</td>\n",
       "      <td>306713</td>\n",
       "      <td>295480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.271547e-04</td>\n",
       "      <td>0.127458</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>5.708341e-09</td>\n",
       "      <td>9.428861e-09</td>\n",
       "      <td>5.385390e-06</td>\n",
       "      <td>6.548770e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>349</td>\n",
       "      <td>st. lucie county</td>\n",
       "      <td>707932446</td>\n",
       "      <td>801167897</td>\n",
       "      <td>9.323545e+07</td>\n",
       "      <td>st. lucie county</td>\n",
       "      <td>FL</td>\n",
       "      <td>12111</td>\n",
       "      <td>305591</td>\n",
       "      <td>298502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.926817e-05</td>\n",
       "      <td>0.039631</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>2.944771e-09</td>\n",
       "      <td>9.348310e-09</td>\n",
       "      <td>1.038822e-05</td>\n",
       "      <td>1.412564e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>382</td>\n",
       "      <td>chatham county</td>\n",
       "      <td>612064386</td>\n",
       "      <td>1121845018</td>\n",
       "      <td>5.097806e+08</td>\n",
       "      <td>chatham county</td>\n",
       "      <td>GA</td>\n",
       "      <td>13051</td>\n",
       "      <td>287049</td>\n",
       "      <td>278392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.528844e-05</td>\n",
       "      <td>0.045466</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>3.531676e-09</td>\n",
       "      <td>1.904193e-08</td>\n",
       "      <td>1.878339e-05</td>\n",
       "      <td>1.633815e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>1106</td>\n",
       "      <td>lafayette parish</td>\n",
       "      <td>695108460</td>\n",
       "      <td>696257588</td>\n",
       "      <td>1.149128e+06</td>\n",
       "      <td>lafayette parish</td>\n",
       "      <td>LA</td>\n",
       "      <td>22055</td>\n",
       "      <td>240091</td>\n",
       "      <td>235792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.163192e-05</td>\n",
       "      <td>0.091861</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>8.344365e-09</td>\n",
       "      <td>2.182372e-08</td>\n",
       "      <td>1.089331e-05</td>\n",
       "      <td>1.438624e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1498</td>\n",
       "      <td>desoto county</td>\n",
       "      <td>1679934795</td>\n",
       "      <td>1700211892</td>\n",
       "      <td>2.027710e+07</td>\n",
       "      <td>desoto county</td>\n",
       "      <td>MS</td>\n",
       "      <td>28033</td>\n",
       "      <td>176132</td>\n",
       "      <td>171996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.589717e-04</td>\n",
       "      <td>0.159159</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>1.047627e-08</td>\n",
       "      <td>1.656863e-08</td>\n",
       "      <td>8.979280e-06</td>\n",
       "      <td>5.952612e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>1620</td>\n",
       "      <td>alamance county</td>\n",
       "      <td>1456395158</td>\n",
       "      <td>1458872839</td>\n",
       "      <td>2.477681e+06</td>\n",
       "      <td>alamance county</td>\n",
       "      <td>NC</td>\n",
       "      <td>37001</td>\n",
       "      <td>160576</td>\n",
       "      <td>156496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.304205e-04</td>\n",
       "      <td>0.230427</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>5.778631e-09</td>\n",
       "      <td>9.230297e-09</td>\n",
       "      <td>9.947411e-06</td>\n",
       "      <td>6.866268e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>433</td>\n",
       "      <td>houston county</td>\n",
       "      <td>963963952</td>\n",
       "      <td>973954144</td>\n",
       "      <td>9.990192e+06</td>\n",
       "      <td>houston county</td>\n",
       "      <td>GA</td>\n",
       "      <td>13153</td>\n",
       "      <td>151682</td>\n",
       "      <td>146107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.570562e-05</td>\n",
       "      <td>0.086714</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>1.230037e-08</td>\n",
       "      <td>1.199613e-08</td>\n",
       "      <td>6.429669e-06</td>\n",
       "      <td>1.037383e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>334</td>\n",
       "      <td>monroe county</td>\n",
       "      <td>-8607822600</td>\n",
       "      <td>2546043464</td>\n",
       "      <td>1.115387e+10</td>\n",
       "      <td>monroe county</td>\n",
       "      <td>FL</td>\n",
       "      <td>12087</td>\n",
       "      <td>76325</td>\n",
       "      <td>75190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.572224e-04</td>\n",
       "      <td>0.158362</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>1.373271e-08</td>\n",
       "      <td>2.523386e-08</td>\n",
       "      <td>2.407468e-05</td>\n",
       "      <td>-1.161734e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>1661</td>\n",
       "      <td>halifax county</td>\n",
       "      <td>1380131426</td>\n",
       "      <td>1433471234</td>\n",
       "      <td>5.333981e+07</td>\n",
       "      <td>halifax county</td>\n",
       "      <td>NC</td>\n",
       "      <td>37083</td>\n",
       "      <td>51737</td>\n",
       "      <td>50724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.151555e-04</td>\n",
       "      <td>0.716760</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>3.063454e-08</td>\n",
       "      <td>7.621276e-08</td>\n",
       "      <td>4.808560e-05</td>\n",
       "      <td>7.245687e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2795</td>\n",
       "      <td>charlottesville city</td>\n",
       "      <td>1926486612</td>\n",
       "      <td>1968605129</td>\n",
       "      <td>4.211852e+07</td>\n",
       "      <td>charlottesville city</td>\n",
       "      <td>VA</td>\n",
       "      <td>51540</td>\n",
       "      <td>47042</td>\n",
       "      <td>45647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.251520e-07</td>\n",
       "      <td>1.084138e-03</td>\n",
       "      <td>1.095617</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>2.982445e-08</td>\n",
       "      <td>2.765540e-07</td>\n",
       "      <td>1.971159e-04</td>\n",
       "      <td>5.190797e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>2804</td>\n",
       "      <td>danville city</td>\n",
       "      <td>418436883</td>\n",
       "      <td>473711563</td>\n",
       "      <td>5.527468e+07</td>\n",
       "      <td>danville city</td>\n",
       "      <td>VA</td>\n",
       "      <td>51590</td>\n",
       "      <td>41512</td>\n",
       "      <td>40227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.433031e-05</td>\n",
       "      <td>1.228560e-03</td>\n",
       "      <td>1.242773</td>\n",
       "      <td>0.007757</td>\n",
       "      <td>2.263171e-08</td>\n",
       "      <td>1.868566e-07</td>\n",
       "      <td>1.988921e-04</td>\n",
       "      <td>2.389847e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>1628</td>\n",
       "      <td>bladen county</td>\n",
       "      <td>3153481864</td>\n",
       "      <td>3163296263</td>\n",
       "      <td>9.814399e+06</td>\n",
       "      <td>bladen county</td>\n",
       "      <td>NC</td>\n",
       "      <td>37017</td>\n",
       "      <td>33778</td>\n",
       "      <td>33403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.095388e-03</td>\n",
       "      <td>1.095891</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>4.382300e-08</td>\n",
       "      <td>5.083468e-08</td>\n",
       "      <td>3.434188e-05</td>\n",
       "      <td>3.171098e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>2865</td>\n",
       "      <td>petersburg city</td>\n",
       "      <td>1218869346</td>\n",
       "      <td>1226420314</td>\n",
       "      <td>7.550968e+06</td>\n",
       "      <td>petersburg city</td>\n",
       "      <td>VA</td>\n",
       "      <td>51730</td>\n",
       "      <td>31827</td>\n",
       "      <td>31218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.602413e-03</td>\n",
       "      <td>1.625350</td>\n",
       "      <td>0.017972</td>\n",
       "      <td>4.146273e-08</td>\n",
       "      <td>5.646829e-07</td>\n",
       "      <td>4.279086e-04</td>\n",
       "      <td>8.204325e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>2314</td>\n",
       "      <td>marion county</td>\n",
       "      <td>840160271</td>\n",
       "      <td>930140101</td>\n",
       "      <td>8.997983e+07</td>\n",
       "      <td>marion county</td>\n",
       "      <td>SC</td>\n",
       "      <td>45067</td>\n",
       "      <td>31562</td>\n",
       "      <td>31267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.425765e-03</td>\n",
       "      <td>1.427888</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>4.416962e-08</td>\n",
       "      <td>1.244780e-07</td>\n",
       "      <td>8.929034e-05</td>\n",
       "      <td>1.190249e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>2308</td>\n",
       "      <td>jasper county</td>\n",
       "      <td>1576628935</td>\n",
       "      <td>1696857611</td>\n",
       "      <td>1.202287e+08</td>\n",
       "      <td>jasper county</td>\n",
       "      <td>SC</td>\n",
       "      <td>45053</td>\n",
       "      <td>27900</td>\n",
       "      <td>27618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.612903e-03</td>\n",
       "      <td>1.614803</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>2.697807e-08</td>\n",
       "      <td>5.267147e-08</td>\n",
       "      <td>6.997781e-05</td>\n",
       "      <td>6.342647e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>1175</td>\n",
       "      <td>somerset county</td>\n",
       "      <td>602652488</td>\n",
       "      <td>962673213</td>\n",
       "      <td>3.600207e+08</td>\n",
       "      <td>somerset county</td>\n",
       "      <td>MD</td>\n",
       "      <td>24039</td>\n",
       "      <td>25737</td>\n",
       "      <td>25279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.325096e-04</td>\n",
       "      <td>0.934025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.189677e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.659331e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>1665</td>\n",
       "      <td>hertford county</td>\n",
       "      <td>1866913122</td>\n",
       "      <td>1867796116</td>\n",
       "      <td>8.829940e+05</td>\n",
       "      <td>hertford county</td>\n",
       "      <td>NC</td>\n",
       "      <td>37091</td>\n",
       "      <td>24153</td>\n",
       "      <td>23564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.531901e-03</td>\n",
       "      <td>1.535668</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>7.885254e-08</td>\n",
       "      <td>1.954172e-07</td>\n",
       "      <td>1.026068e-04</td>\n",
       "      <td>5.356436e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>emanuel county</td>\n",
       "      <td>1737779554</td>\n",
       "      <td>1762674054</td>\n",
       "      <td>2.489450e+07</td>\n",
       "      <td>emanuel county</td>\n",
       "      <td>GA</td>\n",
       "      <td>13107</td>\n",
       "      <td>22499</td>\n",
       "      <td>22039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.778035e-04</td>\n",
       "      <td>0.582559</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>4.543614e-08</td>\n",
       "      <td>1.422349e-07</td>\n",
       "      <td>1.391366e-04</td>\n",
       "      <td>5.754470e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>2306</td>\n",
       "      <td>hampton county</td>\n",
       "      <td>1443255140</td>\n",
       "      <td>1450327705</td>\n",
       "      <td>7.072565e+06</td>\n",
       "      <td>hampton county</td>\n",
       "      <td>SC</td>\n",
       "      <td>45049</td>\n",
       "      <td>19807</td>\n",
       "      <td>19597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.271924e-03</td>\n",
       "      <td>2.274398</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>6.882185e-08</td>\n",
       "      <td>8.156664e-08</td>\n",
       "      <td>5.983668e-05</td>\n",
       "      <td>6.928782e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>491</td>\n",
       "      <td>telfair county</td>\n",
       "      <td>1115264697</td>\n",
       "      <td>1132621096</td>\n",
       "      <td>1.735640e+07</td>\n",
       "      <td>telfair county</td>\n",
       "      <td>GA</td>\n",
       "      <td>13271</td>\n",
       "      <td>16115</td>\n",
       "      <td>16006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.067018e-04</td>\n",
       "      <td>0.823518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.078195e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.966481e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>438</td>\n",
       "      <td>jefferson county</td>\n",
       "      <td>1355690255</td>\n",
       "      <td>1363760605</td>\n",
       "      <td>8.070350e+06</td>\n",
       "      <td>jefferson county</td>\n",
       "      <td>GA</td>\n",
       "      <td>13163</td>\n",
       "      <td>15772</td>\n",
       "      <td>15652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.242455e-04</td>\n",
       "      <td>0.834580</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>6.834006e-08</td>\n",
       "      <td>1.487401e-07</td>\n",
       "      <td>1.379959e-04</td>\n",
       "      <td>7.376316e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>1433</td>\n",
       "      <td>mississippi county</td>\n",
       "      <td>1783439696</td>\n",
       "      <td>1807187011</td>\n",
       "      <td>2.374732e+07</td>\n",
       "      <td>mississippi county</td>\n",
       "      <td>MO</td>\n",
       "      <td>29133</td>\n",
       "      <td>13748</td>\n",
       "      <td>13537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.109398e-03</td>\n",
       "      <td>2.119072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.607142e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>chicot county</td>\n",
       "      <td>1509351542</td>\n",
       "      <td>1649764698</td>\n",
       "      <td>1.404132e+08</td>\n",
       "      <td>chicot county</td>\n",
       "      <td>AR</td>\n",
       "      <td>5017</td>\n",
       "      <td>10826</td>\n",
       "      <td>10725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.618511e-04</td>\n",
       "      <td>0.463421</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>8.532258e-08</td>\n",
       "      <td>2.986290e-07</td>\n",
       "      <td>3.232958e-04</td>\n",
       "      <td>6.625362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>2677</td>\n",
       "      <td>presidio county</td>\n",
       "      <td>9983284260</td>\n",
       "      <td>9985057448</td>\n",
       "      <td>1.773188e+06</td>\n",
       "      <td>presidio county</td>\n",
       "      <td>TX</td>\n",
       "      <td>48377</td>\n",
       "      <td>7123</td>\n",
       "      <td>7123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.738734e-03</td>\n",
       "      <td>6.791661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.001674e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>661</td>\n",
       "      <td>alexander county</td>\n",
       "      <td>1312918792</td>\n",
       "      <td>1328792785</td>\n",
       "      <td>1.587399e+07</td>\n",
       "      <td>alexander county</td>\n",
       "      <td>IL</td>\n",
       "      <td>17003</td>\n",
       "      <td>6532</td>\n",
       "      <td>6341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.602572e-03</td>\n",
       "      <td>2.603031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.406238e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.616617e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>2573</td>\n",
       "      <td>garza county</td>\n",
       "      <td>2306715301</td>\n",
       "      <td>2313930832</td>\n",
       "      <td>7.215531e+06</td>\n",
       "      <td>garza county</td>\n",
       "      <td>TX</td>\n",
       "      <td>48169</td>\n",
       "      <td>6288</td>\n",
       "      <td>6169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.633588e-03</td>\n",
       "      <td>7.660464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.587456e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.335169e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1544</td>\n",
       "      <td>sharkey county</td>\n",
       "      <td>1276435128</td>\n",
       "      <td>1315412506</td>\n",
       "      <td>3.897738e+07</td>\n",
       "      <td>sharkey county</td>\n",
       "      <td>MS</td>\n",
       "      <td>28125</td>\n",
       "      <td>4511</td>\n",
       "      <td>4511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.207049e-03</td>\n",
       "      <td>6.234759</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>2.457109e-07</td>\n",
       "      <td>1.425123e-06</td>\n",
       "      <td>1.285746e-03</td>\n",
       "      <td>7.834319e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>263</td>\n",
       "      <td>phillips county</td>\n",
       "      <td>1781423168</td>\n",
       "      <td>1781724976</td>\n",
       "      <td>3.018080e+05</td>\n",
       "      <td>phillips county</td>\n",
       "      <td>CO</td>\n",
       "      <td>8095</td>\n",
       "      <td>4318</td>\n",
       "      <td>4234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.852710e-03</td>\n",
       "      <td>1.874711</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>3.754333e-07</td>\n",
       "      <td>2.145333e-06</td>\n",
       "      <td>1.323364e-03</td>\n",
       "      <td>5.613489e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>2603</td>\n",
       "      <td>hudspeth county</td>\n",
       "      <td>11835415366</td>\n",
       "      <td>11837605309</td>\n",
       "      <td>2.189943e+06</td>\n",
       "      <td>hudspeth county</td>\n",
       "      <td>TX</td>\n",
       "      <td>48229</td>\n",
       "      <td>4098</td>\n",
       "      <td>4027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.171303e-02</td>\n",
       "      <td>11.768912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.449218e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>2636</td>\n",
       "      <td>lipscomb county</td>\n",
       "      <td>2414123904</td>\n",
       "      <td>2414422645</td>\n",
       "      <td>2.987410e+05</td>\n",
       "      <td>lipscomb county</td>\n",
       "      <td>TX</td>\n",
       "      <td>48295</td>\n",
       "      <td>3469</td>\n",
       "      <td>3325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.383684e-02</td>\n",
       "      <td>13.921880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.661963e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.142289e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39 rows × 1699 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_0                county   total_area    land_area    water_area  \\\n",
       "149     149       maricopa county  23766342548  23829656320  6.331377e+07   \n",
       "338     338         orange county   2073171585   2335738262  2.625667e+08   \n",
       "2549   2549         denton county   2085807196   2275298676  1.894915e+08   \n",
       "1897   1897     bernalillo county   1857553267   1874472931  1.691966e+07   \n",
       "354     354        volusia county   1994708722   2852352391  8.576437e+08   \n",
       "347     347       seminole county   2078809884   2622105608  5.432957e+08   \n",
       "2291   2291     charleston county   1237819592   2377478103  1.139659e+09   \n",
       "126     126        pulaski county   1838109640   1964339775  1.262301e+08   \n",
       "339     339        osceola county   2976496907   3438557597  4.620607e+08   \n",
       "2055   2055         lorain county    152700424   1272195481  1.119495e+09   \n",
       "349     349      st. lucie county    707932446    801167897  9.323545e+07   \n",
       "382     382        chatham county    612064386   1121845018  5.097806e+08   \n",
       "1106   1106      lafayette parish    695108460    696257588  1.149128e+06   \n",
       "1498   1498         desoto county   1679934795   1700211892  2.027710e+07   \n",
       "1620   1620       alamance county   1456395158   1458872839  2.477681e+06   \n",
       "433     433        houston county    963963952    973954144  9.990192e+06   \n",
       "334     334         monroe county  -8607822600   2546043464  1.115387e+10   \n",
       "1661   1661        halifax county   1380131426   1433471234  5.333981e+07   \n",
       "2795   2795  charlottesville city   1926486612   1968605129  4.211852e+07   \n",
       "2804   2804         danville city    418436883    473711563  5.527468e+07   \n",
       "1628   1628         bladen county   3153481864   3163296263  9.814399e+06   \n",
       "2865   2865       petersburg city   1218869346   1226420314  7.550968e+06   \n",
       "2314   2314         marion county    840160271    930140101  8.997983e+07   \n",
       "2308   2308         jasper county   1576628935   1696857611  1.202287e+08   \n",
       "1175   1175       somerset county    602652488    962673213  3.600207e+08   \n",
       "1665   1665       hertford county   1866913122   1867796116  8.829940e+05   \n",
       "410     410        emanuel county   1737779554   1762674054  2.489450e+07   \n",
       "2306   2306        hampton county   1443255140   1450327705  7.072565e+06   \n",
       "491     491        telfair county   1115264697   1132621096  1.735640e+07   \n",
       "438     438      jefferson county   1355690255   1363760605  8.070350e+06   \n",
       "1433   1433    mississippi county   1783439696   1807187011  2.374732e+07   \n",
       "75       75         chicot county   1509351542   1649764698  1.404132e+08   \n",
       "2677   2677       presidio county   9983284260   9985057448  1.773188e+06   \n",
       "661     661      alexander county   1312918792   1328792785  1.587399e+07   \n",
       "2573   2573          garza county   2306715301   2313930832  7.215531e+06   \n",
       "1544   1544        sharkey county   1276435128   1315412506  3.897738e+07   \n",
       "263     263       phillips county   1781423168   1781724976  3.018080e+05   \n",
       "2603   2603       hudspeth county  11835415366  11837605309  2.189943e+06   \n",
       "2636   2636       lipscomb county   2414123904   2414422645  2.987410e+05   \n",
       "\n",
       "                  county_x state     id  population  \\\n",
       "149        maricopa county    AZ   4013     4253913   \n",
       "338          orange county    FL  12095     1321194   \n",
       "2549         denton county    TX  48121      807047   \n",
       "1897     bernalillo county    NM  35001      677692   \n",
       "354         volusia county    FL  12127      527634   \n",
       "347        seminole county    FL  12117      455086   \n",
       "2291     charleston county    SC  45019      394708   \n",
       "126         pulaski county    AR   5119      393463   \n",
       "339         osceola county    FL  12097      338619   \n",
       "2055         lorain county    OH  39093      306713   \n",
       "349       st. lucie county    FL  12111      305591   \n",
       "382         chatham county    GA  13051      287049   \n",
       "1106      lafayette parish    LA  22055      240091   \n",
       "1498         desoto county    MS  28033      176132   \n",
       "1620       alamance county    NC  37001      160576   \n",
       "433         houston county    GA  13153      151682   \n",
       "334          monroe county    FL  12087       76325   \n",
       "1661        halifax county    NC  37083       51737   \n",
       "2795  charlottesville city    VA  51540       47042   \n",
       "2804         danville city    VA  51590       41512   \n",
       "1628         bladen county    NC  37017       33778   \n",
       "2865       petersburg city    VA  51730       31827   \n",
       "2314         marion county    SC  45067       31562   \n",
       "2308         jasper county    SC  45053       27900   \n",
       "1175       somerset county    MD  24039       25737   \n",
       "1665       hertford county    NC  37091       24153   \n",
       "410         emanuel county    GA  13107       22499   \n",
       "2306        hampton county    SC  45049       19807   \n",
       "491         telfair county    GA  13271       16115   \n",
       "438       jefferson county    GA  13163       15772   \n",
       "1433    mississippi county    MO  29133       13748   \n",
       "75           chicot county    AR   5017       10826   \n",
       "2677       presidio county    TX  48377        7123   \n",
       "661       alexander county    IL  17003        6532   \n",
       "2573          garza county    TX  48169        6288   \n",
       "1544        sharkey county    MS  28125        4511   \n",
       "263        phillips county    CO   8095        4318   \n",
       "2603       hudspeth county    TX  48229        4098   \n",
       "2636       lipscomb county    TX  48295        3469   \n",
       "\n",
       "      estimate!!race!!total population!!one race  ...  \\\n",
       "149                                      4099917  ...   \n",
       "338                                      1276729  ...   \n",
       "2549                                      778441  ...   \n",
       "1897                                      649178  ...   \n",
       "354                                       517240  ...   \n",
       "347                                       440178  ...   \n",
       "2291                                      386707  ...   \n",
       "126                                       382492  ...   \n",
       "339                                       325112  ...   \n",
       "2055                                      295480  ...   \n",
       "349                                       298502  ...   \n",
       "382                                       278392  ...   \n",
       "1106                                      235792  ...   \n",
       "1498                                      171996  ...   \n",
       "1620                                      156496  ...   \n",
       "433                                       146107  ...   \n",
       "334                                        75190  ...   \n",
       "1661                                       50724  ...   \n",
       "2795                                       45647  ...   \n",
       "2804                                       40227  ...   \n",
       "1628                                       33403  ...   \n",
       "2865                                       31218  ...   \n",
       "2314                                       31267  ...   \n",
       "2308                                       27618  ...   \n",
       "1175                                       25279  ...   \n",
       "1665                                       23564  ...   \n",
       "410                                        22039  ...   \n",
       "2306                                       19597  ...   \n",
       "491                                        16006  ...   \n",
       "438                                        15652  ...   \n",
       "1433                                       13537  ...   \n",
       "75                                         10725  ...   \n",
       "2677                                        7123  ...   \n",
       "661                                         6341  ...   \n",
       "2573                                        6169  ...   \n",
       "1544                                        4511  ...   \n",
       "263                                         4234  ...   \n",
       "2603                                        4027  ...   \n",
       "2636                                        3325  ...   \n",
       "\n",
       "      nursing facilities total beds ratio  nurse practitioners_y ratio  \\\n",
       "149                              0.000000                          0.0   \n",
       "338                              0.000000                          0.0   \n",
       "2549                             0.000000                          0.0   \n",
       "1897                             0.000000                          0.0   \n",
       "354                              0.000000                          0.0   \n",
       "347                              0.000000                          0.0   \n",
       "2291                             0.000000                          0.0   \n",
       "126                              0.000000                          0.0   \n",
       "339                              0.000000                          0.0   \n",
       "2055                             0.000000                          0.0   \n",
       "349                              0.000000                          0.0   \n",
       "382                              0.000000                          0.0   \n",
       "1106                             0.000000                          0.0   \n",
       "1498                             0.000000                          0.0   \n",
       "1620                             0.000000                          0.0   \n",
       "433                              0.000000                          0.0   \n",
       "334                              0.000000                          0.0   \n",
       "1661                             0.000000                          0.0   \n",
       "2795                             0.001233                          0.0   \n",
       "2804                             0.000602                          0.0   \n",
       "1628                             0.000000                          0.0   \n",
       "2865                             0.000000                          0.0   \n",
       "2314                             0.000000                          0.0   \n",
       "2308                             0.000000                          0.0   \n",
       "1175                             0.000000                          0.0   \n",
       "1665                             0.000000                          0.0   \n",
       "410                              0.000000                          0.0   \n",
       "2306                             0.000000                          0.0   \n",
       "491                              0.000000                          0.0   \n",
       "438                              0.000000                          0.0   \n",
       "1433                             0.000000                          0.0   \n",
       "75                               0.000000                          0.0   \n",
       "2677                             0.000000                          0.0   \n",
       "661                              0.000000                          0.0   \n",
       "2573                             0.000000                          0.0   \n",
       "1544                             0.000000                          0.0   \n",
       "263                              0.000000                          0.0   \n",
       "2603                             0.000000                          0.0   \n",
       "2636                             0.000000                          0.0   \n",
       "\n",
       "      advpractnurs midwve,male w/npi ratio  st_num ratio  countyfips ratio  \\\n",
       "149                           0.000000e+00  9.403107e-07          0.000943   \n",
       "338                           0.000000e+00  9.082693e-06          0.009155   \n",
       "2549                          0.000000e+00  5.947609e-05          0.059626   \n",
       "1897                          0.000000e+00  5.164588e-05          0.051647   \n",
       "354                           0.000000e+00  2.274304e-05          0.022984   \n",
       "347                           0.000000e+00  2.636864e-05          0.026626   \n",
       "2291                          0.000000e+00  1.140083e-04          0.114056   \n",
       "126                           0.000000e+00  1.270768e-05          0.013010   \n",
       "339                           0.000000e+00  3.543806e-05          0.035725   \n",
       "2055                          0.000000e+00  1.271547e-04          0.127458   \n",
       "349                           0.000000e+00  3.926817e-05          0.039631   \n",
       "382                           0.000000e+00  4.528844e-05          0.045466   \n",
       "1106                          0.000000e+00  9.163192e-05          0.091861   \n",
       "1498                          0.000000e+00  1.589717e-04          0.159159   \n",
       "1620                          0.000000e+00  2.304205e-04          0.230427   \n",
       "433                           0.000000e+00  8.570562e-05          0.086714   \n",
       "334                           0.000000e+00  1.572224e-04          0.158362   \n",
       "1661                          0.000000e+00  7.151555e-04          0.716760   \n",
       "2795                          4.251520e-07  1.084138e-03          1.095617   \n",
       "2804                          2.433031e-05  1.228560e-03          1.242773   \n",
       "1628                          0.000000e+00  1.095388e-03          1.095891   \n",
       "2865                          0.000000e+00  1.602413e-03          1.625350   \n",
       "2314                          0.000000e+00  1.425765e-03          1.427888   \n",
       "2308                          0.000000e+00  1.612903e-03          1.614803   \n",
       "1175                          0.000000e+00  9.325096e-04          0.934025   \n",
       "1665                          0.000000e+00  1.531901e-03          1.535668   \n",
       "410                           0.000000e+00  5.778035e-04          0.582559   \n",
       "2306                          0.000000e+00  2.271924e-03          2.274398   \n",
       "491                           0.000000e+00  8.067018e-04          0.823518   \n",
       "438                           0.000000e+00  8.242455e-04          0.834580   \n",
       "1433                          0.000000e+00  2.109398e-03          2.119072   \n",
       "75                            0.000000e+00  4.618511e-04          0.463421   \n",
       "2677                          0.000000e+00  6.738734e-03          6.791661   \n",
       "661                           0.000000e+00  2.602572e-03          2.603031   \n",
       "2573                          0.000000e+00  7.633588e-03          7.660464   \n",
       "1544                          0.000000e+00  6.207049e-03          6.234759   \n",
       "263                           0.000000e+00  1.852710e-03          1.874711   \n",
       "2603                          0.000000e+00  1.171303e-02         11.768912   \n",
       "2636                          0.000000e+00  1.383684e-02         13.921880   \n",
       "\n",
       "      beds ratio  case_per_pop ratio  beds_per_pop ratio  beds_per_case ratio  \\\n",
       "149     0.002714        3.053199e-10        6.379389e-10         4.911741e-07   \n",
       "338     0.002405        8.467228e-10        1.820053e-09         1.626957e-06   \n",
       "2549    0.001839        1.338810e-09        2.278433e-09         2.108718e-06   \n",
       "1897    0.002923        2.242707e-09        4.313400e-09         2.838016e-06   \n",
       "354     0.002754        1.928896e-09        5.219153e-09         5.128124e-06   \n",
       "347     0.000758        1.979689e-09        1.665836e-09         1.849021e-06   \n",
       "2291    0.005396        3.087402e-09        1.367186e-08         1.121911e-05   \n",
       "126     0.010990        3.895018e-09        2.793045e-08         1.822487e-05   \n",
       "339     0.001855        4.831557e-09        5.476928e-09         3.347639e-06   \n",
       "2055    0.002892        5.708341e-09        9.428861e-09         5.385390e-06   \n",
       "349     0.002857        2.944771e-09        9.348310e-09         1.038822e-05   \n",
       "382     0.005466        3.531676e-09        1.904193e-08         1.878339e-05   \n",
       "1106    0.005240        8.344365e-09        2.182372e-08         1.089331e-05   \n",
       "1498    0.002918        1.047627e-08        1.656863e-08         8.979280e-06   \n",
       "1620    0.001482        5.778631e-09        9.230297e-09         9.947411e-06   \n",
       "433     0.001820        1.230037e-08        1.199613e-08         6.429669e-06   \n",
       "334     0.001926        1.373271e-08        2.523386e-08         2.407468e-05   \n",
       "1661    0.003943        3.063454e-08        7.621276e-08         4.808560e-05   \n",
       "2795    0.013010        2.982445e-08        2.765540e-07         1.971159e-04   \n",
       "2804    0.007757        2.263171e-08        1.868566e-07         1.988921e-04   \n",
       "1628    0.001717        4.382300e-08        5.083468e-08         3.434188e-05   \n",
       "2865    0.017972        4.146273e-08        5.646829e-07         4.279086e-04   \n",
       "2314    0.003929        4.416962e-08        1.244780e-07         8.929034e-05   \n",
       "2308    0.001470        2.697807e-08        5.267147e-08         6.997781e-05   \n",
       "1175    0.000000        6.189677e-08        0.000000e+00         0.000000e+00   \n",
       "1665    0.004720        7.885254e-08        1.954172e-07         1.026068e-04   \n",
       "410     0.003200        4.543614e-08        1.422349e-07         1.391366e-04   \n",
       "2306    0.001616        6.882185e-08        8.156664e-08         5.983668e-05   \n",
       "491     0.000000        1.078195e-07        0.000000e+00         0.000000e+00   \n",
       "438     0.002346        6.834006e-08        1.487401e-07         1.379959e-04   \n",
       "1433    0.000000        0.000000e+00        0.000000e+00                  NaN   \n",
       "75      0.003233        8.532258e-08        2.986290e-07         3.232958e-04   \n",
       "2677    0.000000        0.000000e+00        0.000000e+00                  NaN   \n",
       "661     0.000000        1.406238e-07        0.000000e+00         0.000000e+00   \n",
       "2573    0.000000        7.587456e-08        0.000000e+00         0.000000e+00   \n",
       "1544    0.006429        2.457109e-07        1.425123e-06         1.285746e-03   \n",
       "263     0.009264        3.754333e-07        2.145333e-06         1.323364e-03   \n",
       "2603    0.000000        0.000000e+00        0.000000e+00                  NaN   \n",
       "2636    0.000000        1.661963e-07        0.000000e+00         0.000000e+00   \n",
       "\n",
       "      pop_density ratio  \n",
       "149        4.207631e-11  \n",
       "338        4.823527e-10  \n",
       "2549       4.794307e-10  \n",
       "1897       5.383426e-10  \n",
       "354        5.013263e-10  \n",
       "347        4.810445e-10  \n",
       "2291       8.078722e-10  \n",
       "126        5.440372e-10  \n",
       "339        3.359654e-10  \n",
       "2055       6.548770e-09  \n",
       "349        1.412564e-09  \n",
       "382        1.633815e-09  \n",
       "1106       1.438624e-09  \n",
       "1498       5.952612e-10  \n",
       "1620       6.866268e-10  \n",
       "433        1.037383e-09  \n",
       "334       -1.161734e-10  \n",
       "1661       7.245687e-10  \n",
       "2795       5.190797e-10  \n",
       "2804       2.389847e-09  \n",
       "1628       3.171098e-10  \n",
       "2865       8.204325e-10  \n",
       "2314       1.190249e-09  \n",
       "2308       6.342647e-10  \n",
       "1175       1.659331e-09  \n",
       "1665       5.356436e-10  \n",
       "410        5.754470e-10  \n",
       "2306       6.928782e-10  \n",
       "491        8.966481e-10  \n",
       "438        7.376316e-10  \n",
       "1433       5.607142e-10  \n",
       "75         6.625362e-10  \n",
       "2677       1.001674e-10  \n",
       "661        7.616617e-10  \n",
       "2573       4.335169e-10  \n",
       "1544       7.834319e-10  \n",
       "263        5.613489e-10  \n",
       "2603       8.449218e-11  \n",
       "2636       4.142289e-10  \n",
       "\n",
       "[39 rows x 1699 columns]"
      ]
     },
     "execution_count": 1983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_df.sort_values(by = 'population', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1990,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp_df.to_csv('~/documents/false_positives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
