{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "import regex as re\n",
    "\n",
    "random_state = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv('~/downloads/new_beds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_x</th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>population</th>\n",
       "      <th>estimate!!race!!total population!!one race</th>\n",
       "      <th>estimate!!race!!total population!!two or more races</th>\n",
       "      <th>estimate!!race!!total population!!one race.1</th>\n",
       "      <th>estimate!!race!!total population!!one race!!white</th>\n",
       "      <th>estimate!!race!!total population!!one race!!black or african american</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native</th>\n",
       "      <th>...</th>\n",
       "      <th>cert nurse midwvs,ft oth emptyp_y</th>\n",
       "      <th>nursing facilities total beds</th>\n",
       "      <th>nurse practitioners_y</th>\n",
       "      <th>advpractnurs midwve,male w/npi</th>\n",
       "      <th>st_num</th>\n",
       "      <th>countyfips</th>\n",
       "      <th>beds</th>\n",
       "      <th>case_per_pop</th>\n",
       "      <th>beds_per_pop</th>\n",
       "      <th>beds_per_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autauga county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>55200</td>\n",
       "      <td>54170</td>\n",
       "      <td>1030</td>\n",
       "      <td>54170</td>\n",
       "      <td>42437</td>\n",
       "      <td>10565</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>1.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baldwin county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1003</td>\n",
       "      <td>208107</td>\n",
       "      <td>204535</td>\n",
       "      <td>3572</td>\n",
       "      <td>204535</td>\n",
       "      <td>179526</td>\n",
       "      <td>19764</td>\n",
       "      <td>1522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>1.855769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barbour county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1005</td>\n",
       "      <td>25782</td>\n",
       "      <td>25429</td>\n",
       "      <td>353</td>\n",
       "      <td>25429</td>\n",
       "      <td>12216</td>\n",
       "      <td>12266</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1005</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>1.396226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bibb county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1007</td>\n",
       "      <td>22527</td>\n",
       "      <td>22340</td>\n",
       "      <td>187</td>\n",
       "      <td>22340</td>\n",
       "      <td>17268</td>\n",
       "      <td>5018</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1007</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.795455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blount county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1009</td>\n",
       "      <td>57645</td>\n",
       "      <td>56710</td>\n",
       "      <td>935</td>\n",
       "      <td>56710</td>\n",
       "      <td>55054</td>\n",
       "      <td>862</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1009</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.568182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 848 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         county_x state    id  population  \\\n",
       "0  autauga county    AL  1001       55200   \n",
       "1  baldwin county    AL  1003      208107   \n",
       "2  barbour county    AL  1005       25782   \n",
       "3     bibb county    AL  1007       22527   \n",
       "4   blount county    AL  1009       57645   \n",
       "\n",
       "   estimate!!race!!total population!!one race  \\\n",
       "0                                       54170   \n",
       "1                                      204535   \n",
       "2                                       25429   \n",
       "3                                       22340   \n",
       "4                                       56710   \n",
       "\n",
       "   estimate!!race!!total population!!two or more races  \\\n",
       "0                                               1030     \n",
       "1                                               3572     \n",
       "2                                                353     \n",
       "3                                                187     \n",
       "4                                                935     \n",
       "\n",
       "   estimate!!race!!total population!!one race.1  \\\n",
       "0                                         54170   \n",
       "1                                        204535   \n",
       "2                                         25429   \n",
       "3                                         22340   \n",
       "4                                         56710   \n",
       "\n",
       "   estimate!!race!!total population!!one race!!white  \\\n",
       "0                                              42437   \n",
       "1                                             179526   \n",
       "2                                              12216   \n",
       "3                                              17268   \n",
       "4                                              55054   \n",
       "\n",
       "   estimate!!race!!total population!!one race!!black or african american  \\\n",
       "0                                              10565                       \n",
       "1                                              19764                       \n",
       "2                                              12266                       \n",
       "3                                               5018                       \n",
       "4                                                862                       \n",
       "\n",
       "   estimate!!race!!total population!!one race!!american indian and alaska native  \\\n",
       "0                                                159                               \n",
       "1                                               1522                               \n",
       "2                                                 72                               \n",
       "3                                                  8                               \n",
       "4                                                141                               \n",
       "\n",
       "   ...  cert nurse midwvs,ft oth emptyp_y  nursing facilities total beds  \\\n",
       "0  ...                                0.0                            0.0   \n",
       "1  ...                                0.0                            0.0   \n",
       "2  ...                                0.0                            0.0   \n",
       "3  ...                                0.0                            0.0   \n",
       "4  ...                                0.0                            0.0   \n",
       "\n",
       "   nurse practitioners_y  advpractnurs midwve,male w/npi  st_num  countyfips  \\\n",
       "0                    0.0                             0.0       1        1001   \n",
       "1                    0.0                             0.0       1        1003   \n",
       "2                    0.0                             0.0       1        1005   \n",
       "3                    0.0                             0.0       1        1007   \n",
       "4                    0.0                             0.0       1        1009   \n",
       "\n",
       "    beds  case_per_pop  beds_per_pop  beds_per_case  \n",
       "0   85.0      0.001214      0.001540       1.268657  \n",
       "1  386.0      0.000999      0.001855       1.855769  \n",
       "2   74.0      0.002056      0.002870       1.396226  \n",
       "3   35.0      0.001953      0.001554       0.795455  \n",
       "4   25.0      0.000763      0.000434       0.568182  \n",
       "\n",
       "[5 rows x 848 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.051e+03, 4.200e+01, 1.100e+01, 1.000e+00, 2.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([0.        , 0.01415439, 0.02830879, 0.04246318, 0.05661757,\n",
       "        0.07077196, 0.08492636, 0.09908075, 0.11323514, 0.12738953,\n",
       "        0.14154393]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(master['case_per_pop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3108.000000\n",
       "mean        0.001994\n",
       "std         0.004738\n",
       "min         0.000000\n",
       "25%         0.000333\n",
       "50%         0.000784\n",
       "75%         0.001943\n",
       "max         0.141544\n",
       "Name: case_per_pop, dtype: float64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['case_per_pop'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2375"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".95/2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "738.15"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape[0] * 0.2375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2369"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape[0] - 739"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310.8"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape[0] * .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "above_std_1 = master.sort_values(by = 'case_per_pop', ascending = False).head(739)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "above_std_1['case_per_pop'] = ((above_std_1['case_per_pop'].values *0) +1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "below = master.sort_values(by = 'case_per_pop', ascending = False).tail(2369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "below['case_per_pop'] = ((below['case_per_pop'].values *0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_x</th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>population</th>\n",
       "      <th>estimate!!race!!total population!!one race</th>\n",
       "      <th>estimate!!race!!total population!!two or more races</th>\n",
       "      <th>estimate!!race!!total population!!one race.1</th>\n",
       "      <th>estimate!!race!!total population!!one race!!white</th>\n",
       "      <th>estimate!!race!!total population!!one race!!black or african american</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native</th>\n",
       "      <th>...</th>\n",
       "      <th>cert nurse midwvs,ft oth emptyp_y</th>\n",
       "      <th>nursing facilities total beds</th>\n",
       "      <th>nurse practitioners_y</th>\n",
       "      <th>advpractnurs midwve,male w/npi</th>\n",
       "      <th>st_num</th>\n",
       "      <th>countyfips</th>\n",
       "      <th>beds</th>\n",
       "      <th>case_per_pop</th>\n",
       "      <th>beds_per_pop</th>\n",
       "      <th>beds_per_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autauga county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>55200</td>\n",
       "      <td>54170</td>\n",
       "      <td>1030</td>\n",
       "      <td>54170</td>\n",
       "      <td>42437</td>\n",
       "      <td>10565</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>1.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baldwin county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1003</td>\n",
       "      <td>208107</td>\n",
       "      <td>204535</td>\n",
       "      <td>3572</td>\n",
       "      <td>204535</td>\n",
       "      <td>179526</td>\n",
       "      <td>19764</td>\n",
       "      <td>1522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>1.855769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barbour county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1005</td>\n",
       "      <td>25782</td>\n",
       "      <td>25429</td>\n",
       "      <td>353</td>\n",
       "      <td>25429</td>\n",
       "      <td>12216</td>\n",
       "      <td>12266</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1005</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>1.396226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bibb county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1007</td>\n",
       "      <td>22527</td>\n",
       "      <td>22340</td>\n",
       "      <td>187</td>\n",
       "      <td>22340</td>\n",
       "      <td>17268</td>\n",
       "      <td>5018</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1007</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.795455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blount county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1009</td>\n",
       "      <td>57645</td>\n",
       "      <td>56710</td>\n",
       "      <td>935</td>\n",
       "      <td>56710</td>\n",
       "      <td>55054</td>\n",
       "      <td>862</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1009</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.568182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 848 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         county_x state    id  population  \\\n",
       "0  autauga county    AL  1001       55200   \n",
       "1  baldwin county    AL  1003      208107   \n",
       "2  barbour county    AL  1005       25782   \n",
       "3     bibb county    AL  1007       22527   \n",
       "4   blount county    AL  1009       57645   \n",
       "\n",
       "   estimate!!race!!total population!!one race  \\\n",
       "0                                       54170   \n",
       "1                                      204535   \n",
       "2                                       25429   \n",
       "3                                       22340   \n",
       "4                                       56710   \n",
       "\n",
       "   estimate!!race!!total population!!two or more races  \\\n",
       "0                                               1030     \n",
       "1                                               3572     \n",
       "2                                                353     \n",
       "3                                                187     \n",
       "4                                                935     \n",
       "\n",
       "   estimate!!race!!total population!!one race.1  \\\n",
       "0                                         54170   \n",
       "1                                        204535   \n",
       "2                                         25429   \n",
       "3                                         22340   \n",
       "4                                         56710   \n",
       "\n",
       "   estimate!!race!!total population!!one race!!white  \\\n",
       "0                                              42437   \n",
       "1                                             179526   \n",
       "2                                              12216   \n",
       "3                                              17268   \n",
       "4                                              55054   \n",
       "\n",
       "   estimate!!race!!total population!!one race!!black or african american  \\\n",
       "0                                              10565                       \n",
       "1                                              19764                       \n",
       "2                                              12266                       \n",
       "3                                               5018                       \n",
       "4                                                862                       \n",
       "\n",
       "   estimate!!race!!total population!!one race!!american indian and alaska native  \\\n",
       "0                                                159                               \n",
       "1                                               1522                               \n",
       "2                                                 72                               \n",
       "3                                                  8                               \n",
       "4                                                141                               \n",
       "\n",
       "   ...  cert nurse midwvs,ft oth emptyp_y  nursing facilities total beds  \\\n",
       "0  ...                                0.0                            0.0   \n",
       "1  ...                                0.0                            0.0   \n",
       "2  ...                                0.0                            0.0   \n",
       "3  ...                                0.0                            0.0   \n",
       "4  ...                                0.0                            0.0   \n",
       "\n",
       "   nurse practitioners_y  advpractnurs midwve,male w/npi  st_num  countyfips  \\\n",
       "0                    0.0                             0.0       1        1001   \n",
       "1                    0.0                             0.0       1        1003   \n",
       "2                    0.0                             0.0       1        1005   \n",
       "3                    0.0                             0.0       1        1007   \n",
       "4                    0.0                             0.0       1        1009   \n",
       "\n",
       "    beds  case_per_pop  beds_per_pop  beds_per_case  \n",
       "0   85.0             0      0.001540       1.268657  \n",
       "1  386.0             0      0.001855       1.855769  \n",
       "2   74.0             1      0.002870       1.396226  \n",
       "3   35.0             0      0.001554       0.795455  \n",
       "4   25.0             0      0.000434       0.568182  \n",
       "\n",
       "[5 rows x 848 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['case_per_pop'] = pd.concat([above_std_1['case_per_pop'],below['case_per_pop']])\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_x</th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>population</th>\n",
       "      <th>estimate!!race!!total population!!one race</th>\n",
       "      <th>estimate!!race!!total population!!two or more races</th>\n",
       "      <th>estimate!!race!!total population!!one race.1</th>\n",
       "      <th>estimate!!race!!total population!!one race!!white</th>\n",
       "      <th>estimate!!race!!total population!!one race!!black or african american</th>\n",
       "      <th>estimate!!race!!total population!!one race!!american indian and alaska native</th>\n",
       "      <th>...</th>\n",
       "      <th>cert nurse midwvs,ft oth emptyp_y</th>\n",
       "      <th>nursing facilities total beds</th>\n",
       "      <th>nurse practitioners_y</th>\n",
       "      <th>advpractnurs midwve,male w/npi</th>\n",
       "      <th>st_num</th>\n",
       "      <th>countyfips</th>\n",
       "      <th>beds</th>\n",
       "      <th>case_per_pop</th>\n",
       "      <th>beds_per_pop</th>\n",
       "      <th>beds_per_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autauga county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>55200</td>\n",
       "      <td>54170</td>\n",
       "      <td>1030</td>\n",
       "      <td>54170</td>\n",
       "      <td>42437</td>\n",
       "      <td>10565</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>1.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baldwin county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1003</td>\n",
       "      <td>208107</td>\n",
       "      <td>204535</td>\n",
       "      <td>3572</td>\n",
       "      <td>204535</td>\n",
       "      <td>179526</td>\n",
       "      <td>19764</td>\n",
       "      <td>1522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>1.855769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barbour county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1005</td>\n",
       "      <td>25782</td>\n",
       "      <td>25429</td>\n",
       "      <td>353</td>\n",
       "      <td>25429</td>\n",
       "      <td>12216</td>\n",
       "      <td>12266</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1005</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>1.396226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bibb county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1007</td>\n",
       "      <td>22527</td>\n",
       "      <td>22340</td>\n",
       "      <td>187</td>\n",
       "      <td>22340</td>\n",
       "      <td>17268</td>\n",
       "      <td>5018</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1007</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.795455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blount county</td>\n",
       "      <td>AL</td>\n",
       "      <td>1009</td>\n",
       "      <td>57645</td>\n",
       "      <td>56710</td>\n",
       "      <td>935</td>\n",
       "      <td>56710</td>\n",
       "      <td>55054</td>\n",
       "      <td>862</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1009</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.568182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 848 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         county_x state    id  population  \\\n",
       "0  autauga county    AL  1001       55200   \n",
       "1  baldwin county    AL  1003      208107   \n",
       "2  barbour county    AL  1005       25782   \n",
       "3     bibb county    AL  1007       22527   \n",
       "4   blount county    AL  1009       57645   \n",
       "\n",
       "   estimate!!race!!total population!!one race  \\\n",
       "0                                       54170   \n",
       "1                                      204535   \n",
       "2                                       25429   \n",
       "3                                       22340   \n",
       "4                                       56710   \n",
       "\n",
       "   estimate!!race!!total population!!two or more races  \\\n",
       "0                                               1030     \n",
       "1                                               3572     \n",
       "2                                                353     \n",
       "3                                                187     \n",
       "4                                                935     \n",
       "\n",
       "   estimate!!race!!total population!!one race.1  \\\n",
       "0                                         54170   \n",
       "1                                        204535   \n",
       "2                                         25429   \n",
       "3                                         22340   \n",
       "4                                         56710   \n",
       "\n",
       "   estimate!!race!!total population!!one race!!white  \\\n",
       "0                                              42437   \n",
       "1                                             179526   \n",
       "2                                              12216   \n",
       "3                                              17268   \n",
       "4                                              55054   \n",
       "\n",
       "   estimate!!race!!total population!!one race!!black or african american  \\\n",
       "0                                              10565                       \n",
       "1                                              19764                       \n",
       "2                                              12266                       \n",
       "3                                               5018                       \n",
       "4                                                862                       \n",
       "\n",
       "   estimate!!race!!total population!!one race!!american indian and alaska native  \\\n",
       "0                                                159                               \n",
       "1                                               1522                               \n",
       "2                                                 72                               \n",
       "3                                                  8                               \n",
       "4                                                141                               \n",
       "\n",
       "   ...  cert nurse midwvs,ft oth emptyp_y  nursing facilities total beds  \\\n",
       "0  ...                                0.0                            0.0   \n",
       "1  ...                                0.0                            0.0   \n",
       "2  ...                                0.0                            0.0   \n",
       "3  ...                                0.0                            0.0   \n",
       "4  ...                                0.0                            0.0   \n",
       "\n",
       "   nurse practitioners_y  advpractnurs midwve,male w/npi  st_num  countyfips  \\\n",
       "0                    0.0                             0.0       1        1001   \n",
       "1                    0.0                             0.0       1        1003   \n",
       "2                    0.0                             0.0       1        1005   \n",
       "3                    0.0                             0.0       1        1007   \n",
       "4                    0.0                             0.0       1        1009   \n",
       "\n",
       "    beds  case_per_pop  beds_per_pop  beds_per_case  \n",
       "0   85.0             0      0.001540       1.268657  \n",
       "1  386.0             0      0.001855       1.855769  \n",
       "2   74.0             1      0.002870       1.396226  \n",
       "3   35.0             0      0.001554       0.795455  \n",
       "4   25.0             0      0.000434       0.568182  \n",
       "\n",
       "[5 rows x 848 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    652\n",
       "0.002416      2\n",
       "0.005938      2\n",
       "0.001425      2\n",
       "0.002451      2\n",
       "           ... \n",
       "0.011798      1\n",
       "0.002766      1\n",
       "0.006134      1\n",
       "0.010653      1\n",
       "0.016191      1\n",
       "Name: beds_per_pop, Length: 2449, dtype: int64"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['beds_per_pop'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master.to_csv('~/documents/case_per_pop_dummied_std_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.762227\n",
       "1    0.237773\n",
       "Name: case_per_pop, dtype: float64"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['case_per_pop'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.762227\n",
       "1    0.237773\n",
       "Name: case_per_pop, dtype: float64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['case_per_pop'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using accuracy as our metric, our baseline is a score of .76227, which would occur if our model predicted an area to not be a coronavirus hotspot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = master.drop(columns = ['total_covid', 'deaths', 'county_x', 'county_y', 'state', 'id', 'population', \n",
    "                           'case_per_pop', 'beds_per_case'])\n",
    "y = master['case_per_pop']\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ss, y, random_state = 11, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([ #instantiate transformers and model\n",
    "    ('lr', LogisticRegression(random_state = 11))\n",
    "])\n",
    "\n",
    "# set hyperparameters\n",
    "\n",
    "pipe_params = {'lr__dual' : [True, False],\n",
    "               'lr__class_weight' : ['dict', 'balanced', None],\n",
    "              'lr__solver': ['liblinear', 'lbfgs', None],\n",
    "              'lr__penalty': ['l1', 'l2', 'none'] # running this with the lasso and ridge techniques by applying a penalty, also running with no penalty\n",
    "              }\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid = pipe_params,\n",
    "                 cv = 5,\n",
    "                 scoring = 'accuracy',\n",
    "                 verbose = 2   \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.7s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.7s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.6s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.6s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.6s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.5s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.6s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.4s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.4s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   1.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   1.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   1.7s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   1.5s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   1.8s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.7s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.6s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.9s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   1.1s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.7s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.4s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.8s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.4s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.6s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   1.6s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   1.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   1.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   1.2s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   1.5s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.4s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.5s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.5s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.5s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.4s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.4s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done 270 out of 270 | elapsed:   36.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "logreg_model = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg_train_score = logreg_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_test_score = logreg_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__class_weight': None,\n",
       " 'lr__dual': False,\n",
       " 'lr__penalty': 'l1',\n",
       " 'lr__solver': 'liblinear'}"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7532431354883473"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logreg_model.best_estimator_, X, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = logreg_model.best_estimator_.steps[0][1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame(coefs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df['coefficients'] = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.rename(columns=({0: 'coefficient',\n",
    "                        'coefficients': 'feature'}), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-2.329513</td>\n",
       "      <td>estimate!!sex and age!!total population!!75 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-1.454859</td>\n",
       "      <td>estimate!!sex and age!!total population!!20 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.044095</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.795239</td>\n",
       "      <td>estimate!!race!!total population!!two or more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.757097</td>\n",
       "      <td>estimate!!hispanic or latino and race!!total p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.730177</td>\n",
       "      <td>estimate!!sex and age!!total population!!85 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.885237</td>\n",
       "      <td>estimate!!hispanic or latino and race!!total p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.188350</td>\n",
       "      <td>estimate!!sex and age!!total population!!45 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.595458</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2.457124</td>\n",
       "      <td>estimate!!sex and age!!total population!!55 to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>839 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    coefficient                                            feature\n",
       "71    -2.329513  estimate!!sex and age!!total population!!75 to...\n",
       "64    -1.454859  estimate!!sex and age!!total population!!20 to...\n",
       "16    -1.044095  estimate!!race!!total population!!one race!!as...\n",
       "26    -0.795239  estimate!!race!!total population!!two or more ...\n",
       "38    -0.757097  estimate!!hispanic or latino and race!!total p...\n",
       "..          ...                                                ...\n",
       "72     0.730177  estimate!!sex and age!!total population!!85 ye...\n",
       "41     0.885237  estimate!!hispanic or latino and race!!total p...\n",
       "67     1.188350  estimate!!sex and age!!total population!!45 to...\n",
       "15     1.595458  estimate!!race!!total population!!one race!!as...\n",
       "68     2.457124  estimate!!sex and age!!total population!!55 to...\n",
       "\n",
       "[839 rows x 2 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.sort_values(by = 'coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('lr',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l1', random_state=11,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7936507936507936"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7824967824967825"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df['abs'] = abs(coef_df['coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "lose_these = coef_df.loc[coef_df['abs'] < 0.0000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lose_these.to_csv('~/documents/bad_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estimate!!race!!total population!!one race',\n",
       " 'estimate!!race!!total population!!two or more races',\n",
       " 'estimate!!race!!total population!!one race.1',\n",
       " 'estimate!!race!!total population!!one race!!white',\n",
       " 'estimate!!race!!total population!!one race!!asian',\n",
       " 'estimate!!race!!total population!!one race!!asian!!chinese',\n",
       " 'estimate!!race!!total population!!one race!!native hawaiian and other pacific islander',\n",
       " 'estimate!!race!!total population!!one race!!native hawaiian and other pacific islander!!native hawaiian',\n",
       " 'estimate!!race!!total population!!one race!!some other race',\n",
       " 'estimate!!race!!total population!!two or more races.1',\n",
       " 'estimate!!race!!total population!!two or more races!!white and black or african american',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!white',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!black or african american',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!american indian and alaska native',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!asian',\n",
       " 'estimate!!race alone or in combination with one or more other races!!total population!!some other race',\n",
       " 'estimate!!hispanic or latino and race!!total population',\n",
       " 'estimate!!hispanic or latino and race!!total population!!hispanic or latino (of any race)',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!white alone',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!american indian and alaska native alone',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!asian alone',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!native hawaiian and other pacific islander alone',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!some other race alone',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!two or more races',\n",
       " 'estimate!!hispanic or latino and race!!total population!!not hispanic or latino!!two or more races!!two races including some other race',\n",
       " 'estimate!!total housing units',\n",
       " 'estimate!!citizen, voting age population!!citizen, 18 and over population',\n",
       " 'estimate!!citizen, voting age population!!citizen, 18 and over population!!male',\n",
       " 'estimate!!citizen, voting age population!!citizen, 18 and over population!!female',\n",
       " 'estimate!!sex and age!!total population',\n",
       " 'estimate!!sex and age!!total population!!male',\n",
       " 'estimate!!sex and age!!total population!!female',\n",
       " 'estimate!!sex and age!!total population!!under 5 years',\n",
       " 'estimate!!sex and age!!total population!!5 to 9 years',\n",
       " 'estimate!!sex and age!!total population!!10 to 14 years',\n",
       " 'estimate!!sex and age!!total population!!15 to 19 years',\n",
       " 'estimate!!sex and age!!total population!!25 to 34 years',\n",
       " 'estimate!!sex and age!!total population!!35 to 44 years',\n",
       " 'estimate!!sex and age!!total population!!65 to 74 years',\n",
       " 'estimate!!sex and age!!total population!!under 18 years',\n",
       " 'estimate!!sex and age!!total population!!16 years and over',\n",
       " 'estimate!!sex and age!!total population!!18 years and over',\n",
       " 'estimate!!sex and age!!total population!!21 years and over',\n",
       " 'estimate!!sex and age!!total population!!62 years and over',\n",
       " 'estimate!!sex and age!!total population!!65 years and over',\n",
       " 'estimate!!sex and age!!total population!!18 years and over.1',\n",
       " 'estimate!!sex and age!!total population!!18 years and over!!male',\n",
       " 'estimate!!sex and age!!total population!!18 years and over!!female',\n",
       " 'estimate!!sex and age!!total population!!65 years and over.1',\n",
       " 'estimate!!sex and age!!total population!!65 years and over!!male',\n",
       " 'estimate!!sex and age!!total population!!65 years and over!!female',\n",
       " 'colon/rectal srg, total ptn cr',\n",
       " 'ophthalmolgy, total patn care',\n",
       " \"m.d.'s, total other_x\",\n",
       " 'aerospace med, total',\n",
       " 'forensic path, total',\n",
       " \"m.d.'s, total ptn care non-fed_x\",\n",
       " 'public health, total patnt care',\n",
       " 'child psych, total patn care',\n",
       " 'medical genetics, total',\n",
       " 'surgical specs, total, 35-44',\n",
       " \"total d.o.'s, total non-fed\",\n",
       " \"total m.d.'s, female_x\",\n",
       " \"total d.o.'s, total federal\",\n",
       " 'nursing home beds, total hosp_x',\n",
       " \"do's, orthopedic surg, total_x\",\n",
       " 'medical specs, total, 35-44',\n",
       " 'other specs, total, < 35',\n",
       " 'dent, total male, priv pract',\n",
       " \"total d.o.'s, male\",\n",
       " 'dentists, total, priv pract, ft',\n",
       " 'gnrl int med, total patn care',\n",
       " \"total d.o.'s, 55-64\",\n",
       " 'path,anat/clinic,total',\n",
       " 'transplant surg, total',\n",
       " 'ped subspecs, total',\n",
       " \"do's, emergency med, total_x\",\n",
       " 'psychiatry, total patient care_x',\n",
       " \"total rep facility exp (1000's)\",\n",
       " \"md's, gen pract, total\",\n",
       " 'psychiatry, total_x',\n",
       " 'other specs, total patnt care',\n",
       " 'dentists, total, priv pract, pt',\n",
       " 'total inpatient, beds set up_x',\n",
       " 'gastroenterology, total',\n",
       " 'urology, total patient care',\n",
       " \"do's, ped subspecs, total_x\",\n",
       " 'plastic surg, total',\n",
       " \"do's inactive, total_x\",\n",
       " 'total medicare inpatient days',\n",
       " 'ped subspecs, total patn care',\n",
       " \"md's, fam med subspec, total\",\n",
       " 'public health, total',\n",
       " \"do's, anesthesiolgy, total_x\",\n",
       " 'surg specs tot, total',\n",
       " \"total m.d.'s, 45-54_x\",\n",
       " 'medical specs, total, 55-64',\n",
       " 'dermatology, total',\n",
       " 'cardiovas dis, total patn care',\n",
       " 'dentists, total priv practice',\n",
       " 'urology, total',\n",
       " \"do's, gnrl int med, total_x\",\n",
       " 'diag radiolgy, total',\n",
       " 'int med subspecs, total',\n",
       " \"do's, ob-gyn, general, total_x\",\n",
       " \"md's, gen pract, total ptn care\",\n",
       " \"total d.o.'s, 75 +\",\n",
       " \"total m.d.'s, 55-64_x\",\n",
       " 'radiology, total',\n",
       " 'phys med/rehab, total patnt cr',\n",
       " \"d.o.'s, total ptn care non-fed\",\n",
       " 'vascular med, total',\n",
       " 'emergency med, total',\n",
       " 'medical specs, total, 65-74',\n",
       " '# surgical operations, total',\n",
       " 'gen prev med, total patnt care',\n",
       " \"do's, gen pract, total ptn care_x\",\n",
       " \"total d.o.'s, < 35\",\n",
       " 'neurology, total',\n",
       " 'radiology, total patient care',\n",
       " \"do's, fam med subspec, total_x\",\n",
       " 'vascular med, total patn care',\n",
       " 'other specs, total, 45-54',\n",
       " 'genrl surg, total patient care',\n",
       " \"total m.d.'s, < 35_x\",\n",
       " 'other specs, total, 75 +',\n",
       " 'other specs, total, 35-44',\n",
       " \"total d.o.'s, 65-74\",\n",
       " \"total d.o.'s, 35-44\",\n",
       " \"total m.d.'s, total non-fed_x\",\n",
       " \"total d.o.'s, female\",\n",
       " 'surgical specs, total, 55-64',\n",
       " 'ophthalmolgy, total',\n",
       " 'medical specs, total, 75 +',\n",
       " 'cardiovas dis, total',\n",
       " 'licensed beds, total hospital_x',\n",
       " \"md's, fam med gen, total\",\n",
       " 'surgical specs, total, 65-74',\n",
       " \"d.o.'s, total pc, hosp ft staff_x\",\n",
       " 'ob-gyn, general, total',\n",
       " 'total active d.o.s non-federal',\n",
       " 'nuclear med, total patient care',\n",
       " \"total m.d.'s, 75 +_x\",\n",
       " \"do's, genrl surg, total_x\",\n",
       " 'phys med/rehab, total',\n",
       " 'colon/rectal srg, total',\n",
       " 'pediatrics, general, total',\n",
       " 'plastic surg, total patn care',\n",
       " 'dent, total female, priv pract',\n",
       " 'surgical specs, total, 75 +',\n",
       " 'other spec, tot, total ptn care',\n",
       " 'rad oncology, total',\n",
       " 'gen prev med, total',\n",
       " \"m.d.'s, total oth prof activity_x\",\n",
       " 'dentists, total prof active',\n",
       " 'other specs, total, 65-74',\n",
       " \"do's, ob-gyn subspecs, total_x\",\n",
       " \"total m.d.'s, male_x\",\n",
       " 'med spec tot, total',\n",
       " \"do's, phys med/rehab, total_x\",\n",
       " \"total m.d.'s, 65-74_x\",\n",
       " \"md's inactive, total\",\n",
       " 'rad oncology, total patnt care',\n",
       " 'child psych, total',\n",
       " '# nhsc total active sites',\n",
       " 'thoracic surg, total patn care',\n",
       " \"do's, psychiatry, total_x\",\n",
       " \"total m.d.'s, tot non-fed & fed_x\",\n",
       " \"do's, other specs, total_x\",\n",
       " \"md's not classified, total\",\n",
       " 'skilled nurs fac total beds_x',\n",
       " 'allergy & immunology, total',\n",
       " 'med spec tot, total patn care',\n",
       " 'nuclear med, total',\n",
       " 'orthopedic surg, total',\n",
       " 'aerospace med, total patn care',\n",
       " 'total deaths',\n",
       " 'thoracic surg, total',\n",
       " \"total d.o.'s, tot non-fed & fed\",\n",
       " 'surg specs tot, total patn care',\n",
       " \"m.d.'s, total pc, hosp ft staff_x\",\n",
       " 'anesthesiolgy, total',\n",
       " 'ped cardiolgy, total patn care',\n",
       " 'neurolgcal surg, total',\n",
       " 'ob-gyn, gen, total patient care',\n",
       " 'anesthesiolgy, total patn care',\n",
       " 'ob-gyn subspecs, total',\n",
       " 'surgical specs, total, < 35',\n",
       " 'otolaryngolgy, total ptn care',\n",
       " 'forensic path, total patn care',\n",
       " 'genrl surg, total',\n",
       " 'gastroenterology, total ptn cr',\n",
       " 'general internal med, total',\n",
       " 'occupat med, total',\n",
       " 'occupat med, total patnt care',\n",
       " \"d.o.'s, total oth prof activity\",\n",
       " 'medical specs, total, < 35',\n",
       " 'medical specs, total, 45-54',\n",
       " \"m.d.'s, total, inactive_x\",\n",
       " 'dermatology, total patnt care',\n",
       " 'emergency med, total patn care',\n",
       " \"total d.o.'s, 45-54\",\n",
       " 'ped cardiolgy, total',\n",
       " 'orthopedic surg, total ptn care',\n",
       " \"do's not classified, total_x\",\n",
       " 'neurolgcal surg, total ptn care',\n",
       " \"md's, total gen pract, total\",\n",
       " 'pulmonary dis, total patn care',\n",
       " 'other specs, total, 55-64',\n",
       " 'other specs, total',\n",
       " 'diag radiolgy, total patn care',\n",
       " 'total active m.d.s non-federal_x',\n",
       " 'other spec, tot, total',\n",
       " 'surgical specs, total, 45-54',\n",
       " \"do's, int med subspecs, total_x\",\n",
       " 'total active d.o.s federal',\n",
       " 'pulmonary dis, total',\n",
       " 'nursing facilities total beds_x',\n",
       " 'otolaryngolgy, total',\n",
       " \"total m.d.'s, 35-44_x\",\n",
       " 'neurology, total patient care',\n",
       " \"do's, fam med gen, total_x\",\n",
       " 'short term non-gen hosp beds_x',\n",
       " 'oth special care, beds set up',\n",
       " 'psychiatric care, beds set up',\n",
       " \"veterans' hospital beds_x\",\n",
       " 'nursing home beds, st gen hosp_x',\n",
       " 'nursing facilities cert beds_x',\n",
       " 'intermediate care, beds set up',\n",
       " 'hospital beds_x',\n",
       " 'gen med/surg, ped, beds set up',\n",
       " 'licensed beds, long term hosp_x',\n",
       " 'nursing home beds, total hosp_y',\n",
       " 'nursing home beds, stng hosp_x',\n",
       " 'long term hosp beds_x',\n",
       " '# veteran hosp, 200-299 beds_x',\n",
       " 'skilled nurs fac certified beds_x',\n",
       " '# stng/lt hosps,050-099 beds_x',\n",
       " 'total inpatient, beds set up_y',\n",
       " 'neonatal intens cr, beds set up',\n",
       " '# stng/lt hosps,006-049 beds_x',\n",
       " 'licensed nurs home beds, stng_x',\n",
       " 'other care, beds set up',\n",
       " '# veteran hosp, 100-199 beds_x',\n",
       " '# veteran hosp, 050-099 beds_x',\n",
       " '# st gen hosp, 006-049 beds_x',\n",
       " 'cardiac intens cr, beds set up',\n",
       " 'neonat intermed cr, beds set up',\n",
       " '# stng/lt hosps,200-299 beds_x',\n",
       " 'licensed beds, total hospital_y',\n",
       " '# st gen hosp, 200-299 beds_x',\n",
       " '# st gen hosp, 100-199 beds_x',\n",
       " 'med/surg intens cr, beds set up',\n",
       " 'short term general hosp beds_x',\n",
       " 'acute lt care, beds set up',\n",
       " 'licensed beds, short term hosp_x',\n",
       " 'obstetrics care, beds set up',\n",
       " 'licensed nurs home beds, lt_x',\n",
       " 'skilled nurs fac total beds_y',\n",
       " '# stng/lt hosps,300+ beds_x',\n",
       " 'licensed nursing home beds_x',\n",
       " 'licensed nurs home beds, stgen_x',\n",
       " '# stng/lt hosps,100-199 beds_x',\n",
       " '# st gen hosp, 300+ beds_x',\n",
       " '# st gen hosp, 050-099 beds_x',\n",
       " 'skilled nurs care, beds set up_x',\n",
       " '# veteran hosp, 006-049 beds_x',\n",
       " '# veteran hosp, 300+ beds_x',\n",
       " 'burn care, beds set up',\n",
       " 'nursing facilities total beds_y',\n",
       " 'other lt care, beds set up',\n",
       " 'short term community hosp beds_x',\n",
       " \"m.d.'s, total other_y\",\n",
       " \"m.d.'s, total ptn care non-fed_y\",\n",
       " \"total m.d.'s, female_y\",\n",
       " 'tot active m.d.s non-fed & fed',\n",
       " \"total m.d.'s, 45-54_y\",\n",
       " \"total m.d.'s, 55-64_y\",\n",
       " \"total m.d.'s, < 35_y\",\n",
       " \"total m.d.'s, total non-fed_y\",\n",
       " \"total m.d.'s, 75 +_y\",\n",
       " \"m.d.'s, total oth prof activity_y\",\n",
       " \"total m.d.'s, male_y\",\n",
       " \"total m.d.'s, 65-74_y\",\n",
       " \"total m.d.'s, tot non-fed & fed_y\",\n",
       " \"m.d.'s, total pc, hosp ft staff_y\",\n",
       " \"m.d.'s, total, inactive_y\",\n",
       " 'total active m.d.s non-federal_y',\n",
       " \"total m.d.'s, 35-44_y\",\n",
       " 'public health, pc, hosp ft stf',\n",
       " '# hosp w/assistv technology ctr',\n",
       " '# hosp w/meals on wheels',\n",
       " 'short term non-gen hosp beds_y',\n",
       " '# hosp w/ambulance services',\n",
       " \"veterans' hospital beds_y\",\n",
       " 'preventable hospital stays rate',\n",
       " 'other specs, pc, hosp ft staff',\n",
       " '# hosp w/residency training',\n",
       " 'nursing home beds, st gen hosp_y',\n",
       " '# hosp w/medicare certification',\n",
       " '# hosp participating in network',\n",
       " '# hosp w/psych outpatient serv',\n",
       " 'dist hosp by 05 - 14 services',\n",
       " 'int med subspecs, pc, hosp res',\n",
       " 'ophthalmolgy, pc, hosp resdnts',\n",
       " 'radiology, pc, hosp ft staff',\n",
       " '# critical access hospitals',\n",
       " '# hosp w/indigent care clinic',\n",
       " 'nurs home admissions,stgen hosp_x',\n",
       " '# hosp w/heart transplant',\n",
       " 'hospital beds_y',\n",
       " 'ob-gyn subspecs,pc,hosp resdnt',\n",
       " '# hosp w/patient repr services',\n",
       " 'pulmonary dis, pc, hosp resdnt',\n",
       " 'licensed beds, long term hosp_y',\n",
       " 'thoracic surg, pc, hosp resdnt',\n",
       " '# hosp w/medical/surg intens cr',\n",
       " 'ob-gyn subspecs,pc,hosp ft stf',\n",
       " '# hosp w/shaped beam rad system',\n",
       " '# hosp w/dental services',\n",
       " '# rehabilitation lt hosps',\n",
       " 'nursing home beds, stng hosp_y',\n",
       " 'dermatology, pc, hosp ft staff',\n",
       " 'occupat med, pc, hosp ft staff',\n",
       " '# hosp w/lung transplant',\n",
       " '# hosp w/child wellness program',\n",
       " '# hosp w/blood donor center',\n",
       " 'gen int med, pc, hosp ft staff',\n",
       " '# psychiatric lt hosps',\n",
       " '# hosp w/tobacco treatment serv',\n",
       " 'outpat visits in long term hosp',\n",
       " 'allergy&immunlgy,pc,hosp ft stf',\n",
       " 'int med subspecs,pc,hosp ft stf',\n",
       " 'other med, pc, hosp ft staff',\n",
       " '# short term general hosps',\n",
       " '# hosp w/arthritis treatmt cntr',\n",
       " 'long term hosp beds_y',\n",
       " '# veteran hosp, 200-299 beds_y',\n",
       " '# hosp w/adult day care program',\n",
       " '# hosp w/optical colonoscopy',\n",
       " 'oth oth spec, pc, hosp ft staff',\n",
       " 'cert nurse midwvs,ft hosp/med_x',\n",
       " 'cardiovas dis, pc, hosp resdnt',\n",
       " '# hosp w/support groups',\n",
       " '# hosp w/home health services',\n",
       " '# hosp w/esoph impedance study',\n",
       " '# hosp w/assisted living',\n",
       " '# hosp w/magnetoencephalography',\n",
       " '# hosp w/burn care',\n",
       " 'orthopedic surg, pc, hosp res',\n",
       " '# hosp w/geriatric services',\n",
       " '# hosp w/aprn/physician assist',\n",
       " '# stng/lt hosps,050-099 beds_y',\n",
       " '# hosp w/pain management pgm',\n",
       " 'emergency med, pc, hosp ft stf',\n",
       " 'phys med/rehab, pc, hosp ft stf',\n",
       " 'otolaryngolgy, pc, hosp ft stf',\n",
       " '# hosp w/pediatric intens care',\n",
       " 'ped subspecs, pc, hosp ft staff',\n",
       " '# hosp w/alc/chem depdnt op ser',\n",
       " 'dist hosp by 25+ services',\n",
       " 'psychiatry, pc, hosp ft staff_x',\n",
       " '# hosp w/physical rehab op serv',\n",
       " 'rad oncology, pc, hosp ft staff',\n",
       " 'dist hosp by 15 - 24 services',\n",
       " '# hosp w/pediatric emerg depart',\n",
       " \"# children's psych lt hosps\",\n",
       " '# hosp w/rural health clinic',\n",
       " '# hosp w/primary care aprn/pas',\n",
       " '# hosp w/orthopedic services',\n",
       " 'pulmonary dis, pc, hosp ft stf',\n",
       " '# hosp w/teen outreach services',\n",
       " 'ped cardiolgy, pc, hosp resdnt',\n",
       " 'gastroenterology, pc, hosp res',\n",
       " 'inpatient days in va hosps',\n",
       " '# hosp w/anesth svc aprn/pas',\n",
       " \"# veterans' hospitals\",\n",
       " 'nuclear med, pc, hosp residnts',\n",
       " '# hosp w/nutrition programs',\n",
       " '# hosp w/volunteer serv dept',\n",
       " '# hosp w/gen med/surg care, ped',\n",
       " 'ophthalmolgy, pc, hosp ft staff',\n",
       " \"md's,tot gen prac,pc,hosp res\",\n",
       " 'genrl surg, pc, hosp ft staff',\n",
       " 'dist hosp by 00 - 04 services',\n",
       " '# hosp w/auxiliary services',\n",
       " '# short term community hosps',\n",
       " 'phys med/rehab, pc, hosp resdnt',\n",
       " '# hosp w/patient education cntr',\n",
       " '# hosp w/neonatal intens care',\n",
       " 'transplant surg, pc,hosp ft stf',\n",
       " 'other surg, pc, hosp ft staff',\n",
       " 'anesthesiolgy, pc, hosp ft stf',\n",
       " 'medical genetics,pc,hosp ft stf',\n",
       " '# hosp w/chiropractic services',\n",
       " '# stng/lt hosps,006-049 beds_y',\n",
       " '# hosp w/hiv-aids services',\n",
       " '# hosp w/psychiatric care',\n",
       " '# hosp w/robot-asst walk therap',\n",
       " 'path,anat/clinic,pc,hosp resdnt',\n",
       " '# hosp w/emergency department',\n",
       " '# veteran hosp, 100-199 beds_y',\n",
       " '# hosp w/physical rehab care',\n",
       " '# hosp w/hemodialysis',\n",
       " '# veteran hosp, 050-099 beds_y',\n",
       " '# hosp w/mobile health services',\n",
       " '# st gen hosp, 006-049 beds_y',\n",
       " 'inpatient days in st gen hosp',\n",
       " '# hosp w/virtual colonoscopy',\n",
       " '# hosp w/ip palliative cre unit',\n",
       " 'thoracic surg, pc, hosp ft stf',\n",
       " '# hosp w/intermediate nurs care_x',\n",
       " '# hosp w/sleep center',\n",
       " '# gen medical/surgical lt hosps',\n",
       " '# hosp w/obstetric care',\n",
       " 'short term community hosp admis',\n",
       " '# hosp w/intraoperative mri',\n",
       " 'inptn days in stng/lt hosp',\n",
       " '# hosp w/skilled nursing care_x',\n",
       " '# hosp w/case management',\n",
       " '# hosp w/hospice',\n",
       " '# hosp w/alc/drug abuse ip care',\n",
       " '# hosp w/medical school affiln',\n",
       " '# hosp w/wound mngmnt services',\n",
       " '# stng/lt hosps,200-299 beds_y',\n",
       " '# hosp w/fertility clinic',\n",
       " '# hosp w/patient ctrl analgesia',\n",
       " 'cardiovas dis, pc, hosp ft stf',\n",
       " '# hosp w/immunization program',\n",
       " 'aerospace med, pc, hosp resdnt',\n",
       " 'licensed beds, total hospital',\n",
       " '# hosp w/psych consl/liaisn ser',\n",
       " 'short term gen hosp admissions',\n",
       " \"d.o.'s, total pc, hosp ft staff_y\",\n",
       " '# hosp w/neurological services',\n",
       " 'transplant surg, pc,hosp resdnt',\n",
       " 'neurology, pc, hosp ft staff',\n",
       " '# hosp w/health fair',\n",
       " 'allergy&immunology,hosp resdnt',\n",
       " '# hosp w/adult diagnostic cath',\n",
       " '# hosp w/cardiac intensive care',\n",
       " '# hosp w/psych resdntl ped trmt',\n",
       " '# st gen hosp, 200-299 beds_y',\n",
       " '# chronic disease lt hosps',\n",
       " 'otolaryngolgy, pc, hosp resdnt',\n",
       " '# st gen hosp, 100-199 beds_y',\n",
       " 'dist hosp by 00 - 39% util rate',\n",
       " 'short term general hosp beds_y',\n",
       " '# hosp w/adult cardiology serv',\n",
       " 'surg specs tot, pc, hosp resdnt',\n",
       " 'anesthesiolgy, pc, hosp resdnt',\n",
       " 'ped cardiolgy, pc, hosp ft stf',\n",
       " '# hosp w/breast cancer scrn/mam',\n",
       " '# hosp w/extracorporeal shock',\n",
       " 'medcre benef hosp readmiss rate',\n",
       " '# hosp w/telehealth stroke care',\n",
       " 'vascular med, pc, hosp ft stf',\n",
       " 'forensic path, pc, hosp resdnt',\n",
       " '# hosp w/ambulatory surgery ctr_x',\n",
       " '# hosp w/ercp',\n",
       " '# hosp w/kidney transplant',\n",
       " 'licensed beds, short term hosp_y',\n",
       " '# hosp w/psych pediatric serv',\n",
       " '# hosp w/positron emiss tom/ct',\n",
       " '# hosp w/palliative care pgm',\n",
       " '# hosp w/telehealth eicu',\n",
       " '# hosp w/community outreach',\n",
       " 'vascular med, pc, hosp resdnt',\n",
       " '# hosp w/ped cardiac surgery_x',\n",
       " '# hosp w/cardiac rehabilitation',\n",
       " '# psychiatric short term hosps',\n",
       " '# hosp w/community health educ',\n",
       " 'diag radiolgy, pc, hosp ft stf',\n",
       " '# hosp w/stereotactic radiosurg',\n",
       " '# hosp w/bariart/wgt cntrl serv',\n",
       " '# hosp w/image-guided rad ther',\n",
       " '# hosp w/oncology services',\n",
       " '# hosp w/fitness center',\n",
       " '# acute long-term care st hosps',\n",
       " 'outpat visits in st gen hosp',\n",
       " \"m.d.'s, total pc, hosp ft staff\",\n",
       " '# hosp w/freestandng outpat ctr',\n",
       " 'colon/rectal srg, pc, hosp res',\n",
       " '# hosp w/outpatient surgery_x',\n",
       " 'stng/lt, hosp admissions',\n",
       " 'medical genetics,pc,hosp resdnt',\n",
       " '# hosp w/liver transplant',\n",
       " '#hosp w/genetic test/counseling',\n",
       " '# hosp w/chemotherapy',\n",
       " '# hosp w/psych intensive op ser',\n",
       " '# hosp w/oth transplant service',\n",
       " '# stng/lt hosps,300+ beds_y',\n",
       " 'path,anat/clinic,pc,hosp ft stf',\n",
       " 'nurs home admissions, tot hosp_x',\n",
       " \"# children's psych st hosps\",\n",
       " \"veterans' hospital admissions\",\n",
       " '# hosp w/ling/translation serv',\n",
       " '# hosp w/proton therapy',\n",
       " '# hosp w/certified trauma cntr',\n",
       " '# hosp w/endoscopic ultrasound',\n",
       " '# hosp w/tissue transplant',\n",
       " 'child psych, pc, hosp ft staff',\n",
       " '# long term hospitals',\n",
       " '# hosp w/urgent care center',\n",
       " '# hosp w/c.t. scanner',\n",
       " 'nuclear med, pc, hosp ft staff',\n",
       " '# hosp w/swing bed services',\n",
       " '# hosp w/diag radioisotope fac',\n",
       " 'other spec, tot, pc, hosp res',\n",
       " 'forensic path, pc, hosp ft stf',\n",
       " '# stng/lt hosps,100-199 beds_y',\n",
       " '# hosp w/acute long-term care',\n",
       " '# st gen hosp, 300+ beds_y',\n",
       " '# hosp w/gen med/surg cr, adult',\n",
       " '# st gen hosp, 050-099 beds_y',\n",
       " '# hosp w/other long-term care',\n",
       " 'emergency med, pc, hosp resdnt',\n",
       " '# hosp w/electrodiagnostic serv',\n",
       " 'gnrl int med, pc, hosp ft staff',\n",
       " '# critical access st gen hosps',\n",
       " '# hosp w/psych geriatric serv',\n",
       " 'hospital admissions',\n",
       " 'plastic surg, pc, hosp ft staff',\n",
       " 'aerospace med, pc, hosp ft stf',\n",
       " '# hosp w/other care',\n",
       " 'dist hosp by 80+% util rate',\n",
       " '# rehabilitation st hosps',\n",
       " '# hosp w/sports medicine',\n",
       " 'surg specs tot, pc, hosp ft stf',\n",
       " '# hosp w/computer asst orth srg',\n",
       " 'dist hosp by 40 - 59% util rate',\n",
       " '# hosp w/other intensive care',\n",
       " '# hosp w/primary care dept',\n",
       " '# hosp w/occupational hlth serv',\n",
       " 'ob-gyn subspecs,pc,hosp residnt',\n",
       " 'pediatrics,gen,pc,hosp ft staff',\n",
       " 'ob-gyn, gen, pc, hosp ft staff',\n",
       " '# hosp w/psych emergency serv',\n",
       " 'outpatient visits in va hosp',\n",
       " '# veteran hosp, 006-049 beds_y',\n",
       " '# hosp w/simulated rehab enviro',\n",
       " '# hosp w/chapl/pastor care serv',\n",
       " '# hosp w/other special care',\n",
       " \"# hosp w/women's hlth cntr/serv\",\n",
       " '# hosp w/hospitalists care',\n",
       " '# veteran hosp, 300+ beds_y',\n",
       " '# hosp w/alc/chem depdnt ped sv',\n",
       " '# hosp w/transport to hlth serv',\n",
       " '# hosp w/psych education serv',\n",
       " '# hosp w/ablat of barrets esoph',\n",
       " 'diag radiolgy, pc, hosp resdnt',\n",
       " '# hosp w/adult cardiac surgery_x',\n",
       " '# hosp w/neonatal intermed care',\n",
       " '# hosp w/health screenings',\n",
       " 'gen prev med, pc, hosp ft staff',\n",
       " 'dist hosp by 60 - 79% util rate',\n",
       " '# hosp w/ped diagnostic cath',\n",
       " 'public health, pc, hosp residnt',\n",
       " '# acute long-term care lt hosps',\n",
       " '# short term non-general hosps',\n",
       " '# hospices',\n",
       " '# hosp w/mag resonance imaging',\n",
       " 'med spec tot, pc, hosp ft staff',\n",
       " '# hosp w/robotic surgery_x',\n",
       " '# hosp w/ped cardiac electrophy',\n",
       " '# hosp w/enabling services',\n",
       " 'short term community hosp beds_y',\n",
       " '# hosp w/alzheimer center',\n",
       " '# hosp w/crisis prevention',\n",
       " 'physician assistants, < 35',\n",
       " 'physician assistants,other spec',\n",
       " 'aprn/physician assistants, pt',\n",
       " 'aprn/physician assistants, ft',\n",
       " 'physician assistants, inactive',\n",
       " 'physician assistants',\n",
       " 'physician assistants, 35-44',\n",
       " 'physician assistants, 45-54',\n",
       " 'physician assistants, active',\n",
       " 'physician assistants, 65 +',\n",
       " 'physician assistants, unk spec',\n",
       " 'physician assistants, female',\n",
       " 'physician assistants, pt',\n",
       " 'physician assistants, surg spec',\n",
       " 'physician assistants, male',\n",
       " 'physician assistants, ft',\n",
       " 'physician assistants w/npi',\n",
       " 'physician assistants, 55-64',\n",
       " 'advanced practice reg nurses,ft_x',\n",
       " 'advanced practice reg nurses,pt_x',\n",
       " 'registered nurses, part-time_x',\n",
       " 'registered nurses, vacancies_x',\n",
       " 'registered nurses, full-time_x',\n",
       " 'cert nurse midwvs,ft hosp/med_y',\n",
       " 'cert regist nurse anesth, 45-54_x',\n",
       " 'cert nurse midwvs,retrd/not emp_x',\n",
       " 'cert regist nurse anesth, male_x',\n",
       " 'cert nurse midwvs,ft mid/physpr_x',\n",
       " 'cert regist nurse anesth, < 35_x',\n",
       " 'advanced practice reg nurses,ft_y',\n",
       " 'cert nurse midwvs,ft unk emptyp_x',\n",
       " 'advanced practice reg nurses,pt_y',\n",
       " 'adv practice regist nurse w/npi_x',\n",
       " 'cert regist nurse anesth, 65 +_x',\n",
       " 'registered nurses, part-time_y',\n",
       " 'certified nurse midwives_x',\n",
       " 'registered nurses, vacancies_y',\n",
       " 'registered nurses, full-time_y',\n",
       " 'adv pract nurse midwives w/npi_x',\n",
       " 'cert regist nurse anesth, 35-44_x',\n",
       " 'cert regist nurse anesth,female_x',\n",
       " 'cert regist nurse anesth, 55-64_x',\n",
       " 'certified nurse midwives, pt_x',\n",
       " 'cert regist nurse anesthetists_x',\n",
       " 'nurse practitioners, male w/npi_x',\n",
       " 'certified nurse midwives, ft_x',\n",
       " 'clinical nurse specialist w/npi_x',\n",
       " 'nurse practitioners w/npi_x',\n",
       " 'nurse practitioners, fmle w/npi_x',\n",
       " 'nurse practitioners_x',\n",
       " \"do's, other specs, tot patnt cr\",\n",
       " \"do's, genrl surg, tot ptnt care\",\n",
       " \"do's, emergency med, tot ptn cr\",\n",
       " \"do's, orthopedic surg, total_y\",\n",
       " \"do's, pediatrics,gen,tot ptn cr\",\n",
       " \"do's, psychiatry, tot patnt cr_x\",\n",
       " \"do's, intmed subspcs,tot ptn cr\",\n",
       " \"do's, emergency med, total_y\",\n",
       " \"do's, orthopedic srg,tot ptn cr\",\n",
       " \"do's, ped subspecs, total_y\",\n",
       " \"do's inactive, total_y\",\n",
       " \"do's,primary care, patient care\",\n",
       " \"do's, anesthesiolgy, total_y\",\n",
       " \"do's, inactive, 45-54\",\n",
       " \"do's, pediatrics, general, tot\",\n",
       " \"do's, gnrl int med, total_y\",\n",
       " \"do's, ped subspecs, tot patn cr\",\n",
       " \"do's, ob-gyn, general, total_y\",\n",
       " \"do's, anesthesiolgy, tot ptn cr\",\n",
       " \"do's, phys med/rehab,tot ptn cr\",\n",
       " \"do's, ob-gyn, gen, tot patn cr\",\n",
       " \"do's, fam med gen, tot ptn cr\",\n",
       " \"do's, gen pract, total ptn care_y\",\n",
       " \"do's, fam med subspec, total_y\",\n",
       " \"do's, inactive, 65-74\",\n",
       " \"do's, inactive, male\",\n",
       " \"do's, genrl surg, total_y\",\n",
       " \"do's, inactive, 55-64\",\n",
       " \"do's, ob-gyn subspecs, total_y\",\n",
       " \"do's, phys med/rehab, total_y\",\n",
       " \"do's, ob-gyn subspcs,tot ptn cr\",\n",
       " \"do's, psychiatry, total_y\",\n",
       " \"do's, other specs, total_y\",\n",
       " \"do's, inactive, < 35\",\n",
       " \"do's, inactive, 75 +\",\n",
       " \"do's, inactive, female\",\n",
       " \"do's not classified, total_y\",\n",
       " \"do's, gnrl int med, tot ptn cr\",\n",
       " \"do's, inactive, 35-44\",\n",
       " \"do's, int med subspecs, total_y\",\n",
       " \"do's, fam med subsp,tot ptn cr\",\n",
       " \"do's, fam med gen, total_y\",\n",
       " 'plastic surgery, 55-64',\n",
       " 'orthopedic surgery, 35-44',\n",
       " 'general surgery, 35-44',\n",
       " 'thoracic surgery, 55-64',\n",
       " 'colon & rectal surgery, < 35',\n",
       " 'colon & rectal surgery, 75 +',\n",
       " 'general surgery, 75 +',\n",
       " 'orthopedic surgery, 45-54',\n",
       " 'colon & rectal surgery, 45-54',\n",
       " 'thoracic surgery, 75 +',\n",
       " 'orthopedic surgery, 75 +',\n",
       " 'plastic surgery, 75 +',\n",
       " 'plastic surgery, 35-44',\n",
       " 'thoracic surgery, < 35',\n",
       " 'colon & rectal surgery, 55-64',\n",
       " 'orthopedic surgery, 65-74',\n",
       " 'neurological surgery, 65-74',\n",
       " 'thoracic surgery, 45-54',\n",
       " 'transplantation surgery, 55-64',\n",
       " 'plastic surgery, 65-74',\n",
       " 'transplantation surgery, 35-44',\n",
       " 'plastic surgery, 45-54',\n",
       " '# hosp w/ambulatory surgery ctr_y',\n",
       " '# ambulatory surgery centers',\n",
       " 'transplantation surgery, 45-54',\n",
       " 'transplantation surgery, < 35',\n",
       " '# hosp w/ped cardiac surgery_y',\n",
       " 'neurological surgery, 45-54',\n",
       " 'neurological surgery, < 35',\n",
       " 'general surgery, 65-74',\n",
       " 'colon & rectal surgery, 35-44',\n",
       " 'colon & rectal surgery, 65-74',\n",
       " 'thoracic surgery, 35-44',\n",
       " '# hosp w/outpatient surgery_y',\n",
       " 'general surgery, 55-64',\n",
       " 'general surgery, < 35',\n",
       " 'neurological surgery, 75 +',\n",
       " 'general surgery, 45-54',\n",
       " 'orthopedic surgery, < 35',\n",
       " 'orthopedic surgery, 55-64',\n",
       " 'plastic surgery, < 35',\n",
       " 'neurological surgery, 55-64',\n",
       " 'thoracic surgery, 65-74',\n",
       " 'transplantation surgery, 75 +',\n",
       " '# hosp w/adult cardiac surgery_y',\n",
       " 'neurological surgery, 35-44',\n",
       " 'transplantation surgery, 65-74',\n",
       " '# hosp w/robotic surgery_y',\n",
       " 'respiratory therapists, ft',\n",
       " 'respiratory therapists, pt',\n",
       " 'psychiatry, 45-54',\n",
       " \"do's, psychiatry, tot patnt cr_y\",\n",
       " 'psychiatry, total patient care_y',\n",
       " 'child psychiatry, 35-44',\n",
       " 'psychiatry, total_y',\n",
       " 'child psychiatry, 75 +',\n",
       " 'child psychiatry, < 35',\n",
       " 'psychiatry, pc, hosp ft staff_y',\n",
       " 'psychiatry, 65-74',\n",
       " 'psychiatry, 55-64',\n",
       " 'child psychiatry, 55-64',\n",
       " 'psychiatry, < 35',\n",
       " 'child psychiatry, 45-54',\n",
       " 'psychiatry, 75 +',\n",
       " 'psychiatry, other prof activity',\n",
       " \"do's, psychiatry, total\",\n",
       " 'psychiatry, 35-44',\n",
       " 'child psychiatry, 65-74',\n",
       " 'psychiatry, other',\n",
       " 'nursing home beds, st gen hosp',\n",
       " 'nursing facilities cert beds_y',\n",
       " 'nurs home admissions,stgen hosp_y',\n",
       " 'clin nurs specialist,fmle w/npi',\n",
       " 'nursing home beds, stng hosp',\n",
       " 'nurs home inptn days, stng/lt',\n",
       " 'skilled nurs fac certified beds_y',\n",
       " 'cert nurse midwvs,ft hosp/med',\n",
       " 'nurs home admissions, stng/lt',\n",
       " 'advpractnurs midwve,fmle w/npi',\n",
       " 'cert regist nurse anesth, 45-54_y',\n",
       " 'certregistnursanesth,male w/npi',\n",
       " 'cert nurse midwvs,retrd/not emp_y',\n",
       " 'cert regist nurse anesth, male_y',\n",
       " 'cert nurse midwvs,ft mid/physpr_y',\n",
       " 'cert regist nurse anesth, < 35_y',\n",
       " 'advanced practice reg nurses,ft',\n",
       " 'nurs home inpatient days',\n",
       " 'cert nurse midwvs,ft unk emptyp_y',\n",
       " 'licensed nurs home beds, stng_y',\n",
       " 'advanced practice reg nurses,pt',\n",
       " 'adv practice regist nurse w/npi_y',\n",
       " '# hosp w/intermediate nurs care_y',\n",
       " 'cert regist nurse anesth, 65 +_y',\n",
       " '# hosp w/skilled nursing care_y',\n",
       " 'registered nurses, part-time',\n",
       " 'certified nurse midwives_y',\n",
       " 'registered nurses, vacancies',\n",
       " 'registered nurses, full-time',\n",
       " 'adv pract nurse midwives w/npi_y',\n",
       " '# skilled nursing facilities',\n",
       " 'certregistnursanesth,fmle w/npi',\n",
       " 'licensed nurs home beds, lt_y',\n",
       " 'cert regist nurse anesth, 35-44_y',\n",
       " 'skilled nurs fac total beds',\n",
       " 'cert regist nurse anesth,female_y',\n",
       " 'cert regist nurse anesth, 55-64_y',\n",
       " 'certified nurse midwives, pt_y',\n",
       " 'nurs home inpatient days, stgen',\n",
       " 'cert regist nurse anesthetists_y',\n",
       " 'nurs home admissions, tot hosp_y',\n",
       " 'nurse practitioners, male w/npi_y',\n",
       " 'certified nurse midwives, ft_y',\n",
       " 'licensed nursing home beds_y',\n",
       " 'licensed nurs home beds, stgen_y',\n",
       " 'adv prct regist nurs,fmle w/npi',\n",
       " 'adv prct regist nurs,male w/npi',\n",
       " 'clinical nurse specialist w/npi_y',\n",
       " 'nurse practitioners w/npi_y',\n",
       " 'skilled nurs care, beds set up_y',\n",
       " 'nurse practitioners, fmle w/npi_y',\n",
       " 'clin nurs specialist,male w/npi',\n",
       " '# nursing facilities',\n",
       " 'nursing facilities total beds',\n",
       " 'nurse practitioners_y',\n",
       " 'advpractnurs midwve,male w/npi',\n",
       " 'countyfips']"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lose_these['feature'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_master = master.drop(columns = list(lose_these['feature'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = better_master.drop(columns = ['total_covid', 'deaths', 'county_x', 'county_y', 'state', 'id', 'population', \n",
    "                           'case_per_pop', 'beds_per_case'])\n",
    "y = better_master['case_per_pop']\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ss, y, random_state = 11, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([ #instantiate transformers and model\n",
    "    ('lr', LogisticRegression(random_state = 11))\n",
    "])\n",
    "\n",
    "# set hyperparameters\n",
    "\n",
    "pipe_params = {'lr__dual' : [True, False],\n",
    "               'lr__class_weight' : ['dict', 'balanced', None],\n",
    "              'lr__solver': ['liblinear', 'lbfgs', None],\n",
    "              'lr__penalty': ['l1', 'l2', 'none'] # running this with the lasso and ridge techniques by applying a penalty, also running with no penalty\n",
    "              }\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid = pipe_params,\n",
    "                 cv = 5,\n",
    "                 scoring = 'accuracy',\n",
    "                 verbose = 2   \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: class_weight must be dict, 'balanced', or None, got: 'dict'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.2s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=dict, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.8s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.6s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.5s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.9s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.6s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=balanced, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.2s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=True, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.9s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   1.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.9s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.7s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=liblinear, total=   0.6s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l1, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=liblinear, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=l2, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=liblinear, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.1s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done 270 out of 270 | elapsed:   12.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=lbfgs, total=   0.3s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n",
      "[CV] lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None \n",
      "[CV]  lr__class_weight=None, lr__dual=False, lr__penalty=none, lr__solver=None, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "logreg_2 = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg_2_train_score = logreg_2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_2_test_score = logreg_2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__class_weight': None,\n",
       " 'lr__dual': False,\n",
       " 'lr__penalty': 'l1',\n",
       " 'lr__solver': 'liblinear'}"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brandongreenspan/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7580631799141515"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logreg_2.best_estimator_, X, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coefs = logreg_2.best_estimator_.steps[0][1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef_df = pd.DataFrame(new_coefs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.575303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.322294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.052873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.156719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.220983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.185935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.359047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.315501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.715899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.574037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.043965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.264338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.272305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.338607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.802888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.609410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.309184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.580097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.754960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.256241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.542546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.891075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.246400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.179305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.449515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.929197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.987236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.363491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-2.299993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.701661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.465196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.117316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.292968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.287896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.065598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.009927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.060668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.023189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.067750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.200790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.087383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.033494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.071568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.079234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.050145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.021665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.005024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.575303\n",
       "1   0.322294\n",
       "2  -0.052873\n",
       "3  -0.156719\n",
       "4   0.220983\n",
       "5  -0.185935\n",
       "6  -0.359047\n",
       "7  -0.315501\n",
       "8   0.715899\n",
       "9   1.574037\n",
       "10 -1.043965\n",
       "11  0.264338\n",
       "12 -0.363636\n",
       "13  0.272305\n",
       "14 -0.338607\n",
       "15 -0.802888\n",
       "16 -0.609410\n",
       "17 -0.309184\n",
       "18  0.580097\n",
       "19 -0.754960\n",
       "20  0.256241\n",
       "21 -0.542546\n",
       "22  0.891075\n",
       "23  0.000000\n",
       "24 -0.246400\n",
       "25 -0.179305\n",
       "26 -1.449515\n",
       "27  0.929197\n",
       "28  2.987236\n",
       "29  0.363491\n",
       "30 -2.299993\n",
       "31  0.701661\n",
       "32 -0.465196\n",
       "33  0.117316\n",
       "34 -0.292968\n",
       "35  0.287896\n",
       "36 -0.065598\n",
       "37  0.009927\n",
       "38  0.060668\n",
       "39  0.023189\n",
       "40 -0.067750\n",
       "41  0.200790\n",
       "42 -0.087383\n",
       "43 -0.033494\n",
       "44  0.000266\n",
       "45 -0.071568\n",
       "46 -0.079234\n",
       "47 -0.050145\n",
       "48 -0.021665\n",
       "49 -0.005024"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef_df['coefficients'] = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef_df.rename(columns=({0: 'coefficient',\n",
    "                        'coefficients': 'feature'}), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-2.299993</td>\n",
       "      <td>estimate!!sex and age!!total population!!75 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.449515</td>\n",
       "      <td>estimate!!sex and age!!total population!!20 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.043965</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.802888</td>\n",
       "      <td>estimate!!race!!total population!!two or more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.754960</td>\n",
       "      <td>estimate!!hispanic or latino and race!!total p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.609410</td>\n",
       "      <td>estimate!!race!!total population!!two or more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.542546</td>\n",
       "      <td>estimate!!hispanic or latino and race!!total p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.465196</td>\n",
       "      <td>estimate!!sex and age!!total population!!media...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.363636</td>\n",
       "      <td>estimate!!race!!total population!!one race!!na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.359047</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.338607</td>\n",
       "      <td>estimate!!race!!total population!!one race!!na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.315501</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.309184</td>\n",
       "      <td>estimate!!race!!total population!!two or more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.292968</td>\n",
       "      <td>unnamed: 0_y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.246400</td>\n",
       "      <td>estimate!!hispanic or latino and race!!total p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.185935</td>\n",
       "      <td>estimate!!race!!total population!!one race!!am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.179305</td>\n",
       "      <td>estimate!!sex and age!!total population!!sex r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.156719</td>\n",
       "      <td>estimate!!race!!total population!!one race!!am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.087383</td>\n",
       "      <td>physician assistants, prim care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.079234</td>\n",
       "      <td>cert nurse midwvs,ft oth emptyp_y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.071568</td>\n",
       "      <td>cert regist nurs anesthet w/npi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.067750</td>\n",
       "      <td>urology, pc, hosp ft staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.065598</td>\n",
       "      <td>hospital_beds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.052873</td>\n",
       "      <td>estimate!!race!!total population!!one race!!am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.050145</td>\n",
       "      <td>st_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.033494</td>\n",
       "      <td>cert nurse midwvs,ft oth emptyp_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.021665</td>\n",
       "      <td>beds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.005024</td>\n",
       "      <td>beds_per_pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>estimate!!hispanic or latino and race!!total p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000266</td>\n",
       "      <td>do's, gen pract, total_y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.009927</td>\n",
       "      <td># hospitals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.023189</td>\n",
       "      <td>neurolgcal surg, pc, hosp res</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.060668</td>\n",
       "      <td>do's, gen pract, total_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.117316</td>\n",
       "      <td>estimate!!sex and age!!total population!!18 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.200790</td>\n",
       "      <td># hosp w/ultrasound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.220983</td>\n",
       "      <td>estimate!!race!!total population!!one race!!am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.256241</td>\n",
       "      <td>estimate!!hispanic or latino and race!!total p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.264338</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.272305</td>\n",
       "      <td>estimate!!race!!total population!!one race!!na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.287896</td>\n",
       "      <td>cases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.322294</td>\n",
       "      <td>estimate!!race!!total population!!one race!!am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.363491</td>\n",
       "      <td>estimate!!sex and age!!total population!!60 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.575303</td>\n",
       "      <td>estimate!!race!!total population!!one race!!bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.580097</td>\n",
       "      <td>estimate!!race alone or in combination with on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.701661</td>\n",
       "      <td>estimate!!sex and age!!total population!!85 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.715899</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.891075</td>\n",
       "      <td>estimate!!hispanic or latino and race!!total p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.929197</td>\n",
       "      <td>estimate!!sex and age!!total population!!45 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.574037</td>\n",
       "      <td>estimate!!race!!total population!!one race!!as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.987236</td>\n",
       "      <td>estimate!!sex and age!!total population!!55 to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    coefficient                                            feature\n",
       "30    -2.299993  estimate!!sex and age!!total population!!75 to...\n",
       "26    -1.449515  estimate!!sex and age!!total population!!20 to...\n",
       "10    -1.043965  estimate!!race!!total population!!one race!!as...\n",
       "15    -0.802888  estimate!!race!!total population!!two or more ...\n",
       "19    -0.754960  estimate!!hispanic or latino and race!!total p...\n",
       "16    -0.609410  estimate!!race!!total population!!two or more ...\n",
       "21    -0.542546  estimate!!hispanic or latino and race!!total p...\n",
       "32    -0.465196  estimate!!sex and age!!total population!!media...\n",
       "12    -0.363636  estimate!!race!!total population!!one race!!na...\n",
       "6     -0.359047  estimate!!race!!total population!!one race!!as...\n",
       "14    -0.338607  estimate!!race!!total population!!one race!!na...\n",
       "7     -0.315501  estimate!!race!!total population!!one race!!as...\n",
       "17    -0.309184  estimate!!race!!total population!!two or more ...\n",
       "34    -0.292968                                       unnamed: 0_y\n",
       "24    -0.246400  estimate!!hispanic or latino and race!!total p...\n",
       "5     -0.185935  estimate!!race!!total population!!one race!!am...\n",
       "25    -0.179305  estimate!!sex and age!!total population!!sex r...\n",
       "3     -0.156719  estimate!!race!!total population!!one race!!am...\n",
       "42    -0.087383                    physician assistants, prim care\n",
       "46    -0.079234                  cert nurse midwvs,ft oth emptyp_y\n",
       "45    -0.071568                    cert regist nurs anesthet w/npi\n",
       "40    -0.067750                         urology, pc, hosp ft staff\n",
       "36    -0.065598                                      hospital_beds\n",
       "2     -0.052873  estimate!!race!!total population!!one race!!am...\n",
       "47    -0.050145                                             st_num\n",
       "43    -0.033494                  cert nurse midwvs,ft oth emptyp_x\n",
       "48    -0.021665                                               beds\n",
       "49    -0.005024                                       beds_per_pop\n",
       "23     0.000000  estimate!!hispanic or latino and race!!total p...\n",
       "44     0.000266                           do's, gen pract, total_y\n",
       "37     0.009927                                        # hospitals\n",
       "39     0.023189                      neurolgcal surg, pc, hosp res\n",
       "38     0.060668                           do's, gen pract, total_x\n",
       "33     0.117316  estimate!!sex and age!!total population!!18 ye...\n",
       "41     0.200790                                # hosp w/ultrasound\n",
       "4      0.220983  estimate!!race!!total population!!one race!!am...\n",
       "20     0.256241  estimate!!hispanic or latino and race!!total p...\n",
       "11     0.264338  estimate!!race!!total population!!one race!!as...\n",
       "13     0.272305  estimate!!race!!total population!!one race!!na...\n",
       "35     0.287896                                              cases\n",
       "1      0.322294  estimate!!race!!total population!!one race!!am...\n",
       "29     0.363491  estimate!!sex and age!!total population!!60 to...\n",
       "0      0.575303  estimate!!race!!total population!!one race!!bl...\n",
       "18     0.580097  estimate!!race alone or in combination with on...\n",
       "31     0.701661  estimate!!sex and age!!total population!!85 ye...\n",
       "8      0.715899  estimate!!race!!total population!!one race!!as...\n",
       "22     0.891075  estimate!!hispanic or latino and race!!total p...\n",
       "27     0.929197  estimate!!sex and age!!total population!!45 to...\n",
       "9      1.574037  estimate!!race!!total population!!one race!!as...\n",
       "28     2.987236  estimate!!sex and age!!total population!!55 to..."
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coef_df.sort_values(by = 'coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('lr',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l1', random_state=11,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Score: 0.7932217932217932\n",
      " Testing Score: 0.7824967824967825\n"
     ]
    }
   ],
   "source": [
    "print(f' Training Score: {logreg_2_train_score}')\n",
    "print(f' Testing Score: {logreg_2_test_score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
